{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import custom script CNN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(device(type='cuda'), True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "import random\n",
    "import sys\n",
    "import gc\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit.Chem.AtomPairs import Pairs\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "\n",
    "# custom functions\n",
    "sys.path.append('/scratch-shared/akshai/Publication/supp_scripts/')\n",
    "import supp_utils as su\n",
    "\n",
    "# set gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device,torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove rdkit warning\n",
    "from rdkit import RDLogger\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_filename = \"parameters.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_file = open(parameter_filename)\n",
    "parameters = json.load(parameter_file)\n",
    "parameter_file.close()\n",
    "\n",
    "# User inputs\n",
    "input_file = parameters[\"input_file\"] # input file\n",
    "\n",
    "trial = parameters[\"trial\"] # setting False saves the output files else not saved\n",
    "\n",
    "fingerprint_type = parameters[\"fingerprint\"][\"fingerprint_type\"]\n",
    "fingerprint_size = int(parameters[\"fingerprint\"][\"fingerprint_size\"])\n",
    "if fingerprint_type == \"morgan\":\n",
    "    fp_radius = int(parameters[\"fingerprint\"][\"radius\"])\n",
    "\n",
    "# Removing data with lower distribution\n",
    "enable_label_cutoff = parameters[\"label_cutoff\"][\"enable_label_cutoff\"]\n",
    "lower_label_count_cutoff = int(parameters[\"label_cutoff\"][\"lower_label_count_cutoff\"])\n",
    "upper_label_count_cutoff = int(parameters[\"label_cutoff\"][\"upper_label_count_cutoff\"])\n",
    "\n",
    "k_fold_value = int(parameters[\"k_fold_value\"]) # Number of folds\n",
    "\n",
    "test_set_percentage = float(parameters[\"test_set_percentage\"])\n",
    "\n",
    "epochs = int(parameters[\"network_parameters\"][\"epochs\"])\n",
    "learning_rate = float(parameters[\"network_parameters\"][\"learning_rate\"])\n",
    "batch_size = int(parameters[\"network_parameters\"][\"batch_size\"])\n",
    "enable_class_weight = parameters[\"network_parameters\"][\"enable_class_weight\"]\n",
    "\n",
    "os.system(\"mkdir run_files\")\n",
    "\n",
    "if not trial:\n",
    "    network_parameter_output = open(\"run_files/network_parameters.txt\",\"w\",1)\n",
    "    for parameter in parameters:\n",
    "        network_parameter_output.write(str(parameter) + \" = \" + str(parameters[parameter]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading input file\n",
    "ML_input = input_file\n",
    "with open(ML_input) as f:\n",
    "    f_readlines = f.readlines()\n",
    "    \n",
    "\n",
    "# Finding cluster distribution\n",
    "num_classes = set([label.strip().split(\" \")[1] for label in f_readlines])\n",
    "class_distriution = su.DNN.get_cluster_count_from_label([label.strip().split(\" \")[1] for label in f_readlines])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,p1=0.0,p2=0.0):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1024, 4096)\n",
    "        self.drop1 = nn.Dropout(p=p1)\n",
    "        self.bn1 = nn.BatchNorm1d(4096)\n",
    "        \n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.drop2 = nn.Dropout(p=p2)\n",
    "        self.bn2 = nn.BatchNorm1d(4096)\n",
    "        \n",
    "        self.fc3 = nn.Linear(4096, 1024)\n",
    "        self.drop3 = nn.Dropout(p=p2)\n",
    "\n",
    "        self.fc9 = nn.Linear(1024, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop1(self.relu(self.bn1(self.fc1(x))))\n",
    "        \n",
    "        x = self.drop2(self.relu(self.bn2(self.fc2(x))))\n",
    "        \n",
    "        x = self.drop3(self.relu((self.fc3(x))))\n",
    "        \n",
    "        x = self.fc9(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/4982 data points obtained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "smiles_label,label_count = su.get_data_within_cutoff(input_file,lower_label_count_cutoff,upper_label_count_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_df,test_df,_ = su.split_data_with_label(smiles_label,train_percentage=1-test_set_percentage,valid_percentage=test_set_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model\n",
      "LOSS train: 0.1463745396870833  val: 0.5085014849901199 \tACCU train: 0.9759615384615384  val: 0.7760416666666667\n",
      "Final model\n",
      "LOSS train: 0.009119413255785521  val: 0.6657680571079254 \tACCU train: 1.0  val: 0.7760416666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model\n",
      "LOSS train: 0.044641172155164756  val: 0.26392295211553574 \tACCU train: 0.9903846153846154  val: 0.921875\n",
      "Final model\n",
      "LOSS train: 0.011046997141630318  val: 0.2751004882156849 \tACCU train: 1.0  val: 0.921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model\n",
      "LOSS train: 0.14497914623755676  val: 0.3754299432039261 \tACCU train: 0.9711538461538461  val: 0.8229166666666667\n",
      "Final model\n",
      "LOSS train: 0.017963060500243537  val: 0.49424220621585846 \tACCU train: 1.0  val: 0.8385416666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model\n",
      "LOSS train: 0.043529732152819633  val: 0.13944368064403534 \tACCU train: 0.9975961538461539  val: 0.9114583333333333\n",
      "Final model\n",
      "LOSS train: 0.01160396821796894  val: 0.15275359898805618 \tACCU train: 1.0  val: 0.9114583333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2a00cf92c1b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_accu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch-shared/akshai/Publication/supp_scripts/DNN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_dl, device)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bert/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bert/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold in range(k_fold_value):\n",
    "    \n",
    "    if not trial:\n",
    "        log_file = open(\"run_files/model_\" + str(fold) + \".txt\",\"w\")\n",
    "        model_output_name = \"run_files/model_\" + str(fold) + \".pth\"\n",
    "        \n",
    "    piece_count = fold + 1\n",
    "    \n",
    "    train,valid,piece_count = su.CV.get_K_fold_cv_data(train_valid_df,k_fold_value,piece_count,shuffle_output=True)\n",
    "\n",
    "    x_train_fp,y_train_fp = su.DNN.smiles_to_fp(train,fingerprint_type,fp_radius,fingerprint_size)\n",
    "    x_valid_fp,y_valid_fp = su.DNN.smiles_to_fp(valid,fingerprint_type,fp_radius,fingerprint_size)\n",
    "    if fold == 0:\n",
    "        x_test_fp,y_test_fp = su.DNN.smiles_to_fp(test_df,fingerprint_type,fp_radius,fingerprint_size)\n",
    "    \n",
    "    \n",
    "    train_loader = su.CV.get_dataloader(x_train_fp,y_train_fp,batch_size)\n",
    "    valid_loader = su.CV.get_dataloader(x_valid_fp,y_valid_fp,batch_size)\n",
    "    if fold == 0:\n",
    "        test_loader = su.CV.get_dataloader(x_test_fp,y_test_fp,batch_size)\n",
    "\n",
    "    if not trial:\n",
    "        train_class_distriution = su.DNN.get_cluster_count_from_label(y_train_fp)\n",
    "        valid_class_distriution = su.DNN.get_cluster_count_from_label(y_valid_fp)\n",
    "        test_class_distriution = su.DNN.get_cluster_count_from_label(y_test_fp)\n",
    "        log_file.write(\"Training : Class distribution = \" + str(train_class_distriution) + \"\\n\")\n",
    "        log_file.write(\"Valid : Class distribution = \" + str(valid_class_distriution) + \"\\n\")\n",
    "        log_file.write(\"Test : Class distribution = \" + str(test_class_distriution) + \"\\n\")\n",
    "    \n",
    "    # calculate class_weight\n",
    "    if enable_class_weight:\n",
    "        class_weight = torch.FloatTensor(su.get_class_weight(train)).cuda()\n",
    "        if not trial:\n",
    "            log_file.write(\"Class weight for loss (balancing weights)= \" + str(class_weight) + \"\\n\")\n",
    "    \n",
    "    # Build model\n",
    "    model = Net(p1=0.4,p2=0.4)\n",
    "    model.cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    if enable_class_weight:\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weight)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    \n",
    "    # List to store values\n",
    "    train_loss_list = []\n",
    "    train_accu_list = []\n",
    "\n",
    "    val_loss_list = []\n",
    "    val_accu_list = []\n",
    "    \n",
    "    \n",
    "    # model training\n",
    "    loop = tqdm.tqdm(range(epochs), total=epochs,leave=False)\n",
    "    for epoch in loop:\n",
    "\n",
    "        train_loss, train_accu = su.DNN.train(model,criterion,optimizer,train_loader,device)\n",
    "        val_loss,val_accu = su.DNN.validate(model,criterion,valid_loader,device)\n",
    "        \n",
    "        if epoch == 0: # For callback\n",
    "            torch.save(model.state_dict(), model_output_name)\n",
    "            saved_model_id = epoch + 1\n",
    "        else:\n",
    "            current_epoch_values = [train_loss, train_accu,val_loss,val_accu]\n",
    "            previous_epoch_values = [train_loss_list,train_accu_list,val_loss_list,val_accu_list]\n",
    "            if su.callback(current_epoch_values,previous_epoch_values,model,model_output_name):\n",
    "                saved_model_id = epoch + 1\n",
    "        \n",
    "        train_loss_list.append(train_loss)\n",
    "        train_accu_list.append(train_accu)\n",
    "        val_loss_list.append(val_loss)\n",
    "        val_accu_list.append(val_accu)\n",
    "        \n",
    "        if not trial:\n",
    "            log_file.write(str(epoch+1) + \"\\t\" + str(train_loss) + \"\\t\" + str(val_loss) + \"\\t\" + str(train_accu) + \"\\t\" + str(val_accu)  + \"\\n\")\n",
    "        loop.set_description(\"LOSS train:\" + str(train_loss) + \" val:\" + str(val_loss) + \" \\tACCU train:\" + str(train_accu) + \" val:\" + str(val_accu))\n",
    "    \n",
    "    log_file.write(\"\\nChosen model = epoch number \" + str(saved_model_id))\n",
    "    \n",
    "    model = Net(p1=0.4,p2=0.4)\n",
    "    model.load_state_dict(torch.load(model_output_name), strict=True)\n",
    "    model.to(device)\n",
    "    \n",
    "    \n",
    "    if not trial: # classification report and confusion matrix plot\n",
    "        loss,accuracy,prediction_list = su.DNN.test(model,criterion,train_loader,device)\n",
    "        image_name = \"run_files/train_\" + str(fold) + \".png\"\n",
    "        report = su.confustion_matrix(prediction_list,image_name)\n",
    "        log_file.write(\"\\n\\n\\nTrain data : Accu-\" + str(accuracy) + \"\\tLoss-\" + str(loss) + \"\\n\")\n",
    "        log_file.write(\"Train data report \\n-\" + str(report) + \"\\n\\n\\n\\n\\n\")\n",
    "    \n",
    "        loss,accuracy,prediction_list = su.DNN.test(model,criterion,valid_loader,device)\n",
    "        image_name = \"run_files/valid_\" + str(fold) + \".png\"\n",
    "        report = su.confustion_matrix(prediction_list,image_name)\n",
    "        log_file.write(\"\\n\\n\\nValid data : Accu-\" + str(accuracy) + \"\\tLoss-\" + str(loss) + \"\\n\")\n",
    "        log_file.write(\"Valid data report \\n-\" + str(report) + \"\\n\\n\\n\\n\\n\")\n",
    "        \n",
    "        loss,accuracy,prediction_list = su.DNN.test(model,criterion,test_loader,device)\n",
    "        image_name = \"run_files/test_\" + str(fold) + \".png\"\n",
    "        report = su.confustion_matrix(prediction_list,image_name)\n",
    "        log_file.write(\"\\n\\n\\nTest data : Accu-\" + str(accuracy) + \"\\tLoss-\" + str(loss) + \"\\n\")\n",
    "        log_file.write(\"Test data report \\n-\" + str(report) + \"\\n\\n\\n\\n\\n\")\n",
    "    \n",
    "    log_file.close()\n",
    "    \n",
    "    if fold == 0 and not trial:\n",
    "        network_parameter_output.write(\"model = \" + str(model) + \"\\n\")\n",
    "        network_parameter_output.close()\n",
    "    \n",
    "    # best validation loss\n",
    "    index = val_loss_list.index(sorted(val_loss_list)[0]) # index of least loss\n",
    "    print (\"Best model\")\n",
    "    print (\"LOSS train:\",train_loss_list[index],\" val:\",val_loss_list[index], \"\\tACCU train:\",train_accu_list[index],\" val:\",val_accu_list[index])\n",
    "    print (\"Final model\")    \n",
    "    print (\"LOSS train:\",train_loss,\" val:\",val_loss, \"\\tACCU train:\",train_accu,\" val:\",val_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_weight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-117fd6f0a6ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclass_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'class_weight' is not defined"
     ]
    }
   ],
   "source": [
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
