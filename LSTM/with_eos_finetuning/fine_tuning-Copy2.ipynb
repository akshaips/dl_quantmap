{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda'), True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "\n",
    "from SmilesPE.pretokenizer import atomwise_tokenizer\n",
    "from SmilesPE.pretokenizer import kmer_tokenizer\n",
    "\n",
    "import string\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device,torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = False # setting False saves the output files else not saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Output log file\n",
    "if not trial:\n",
    "    try:\n",
    "        os.system(\"mkdir output_files\")\n",
    "    except:\n",
    "        print (\"Folder output_files already present\")\n",
    "\n",
    "    present_files = glob.glob(\"output_files/log_output_*.txt\")\n",
    "    log_file_name = \"output_files/log_output_\" + str(len(present_files) + 1) + \".txt\"\n",
    "    log_file = open(log_file_name,\"w\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_files = True\n",
    "\n",
    "if multi_files:\n",
    "    input_file = [\"first_5000.txt\",\"ML_input_5338.txt\"]\n",
    "else:\n",
    "    input_file = \"first_5000.txt\" # Input data containing smiles and label\n",
    "\n",
    "log_file.write(\"Used files \" + str(input_file) + \"\\n\")\n",
    "number_of_augmentation = 1 # Data augmentation multiplier\n",
    "train_percentage = 0.9 # Fraction to use for training (valida and test would be half of remaining data)\n",
    "Number_of_workers = 8 # Number of CPU threads to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove rdkit warnings (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove rdkit warning\n",
    "from rdkit import RDLogger\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_canonical_smiles(molecule):\n",
    "    try:\n",
    "        canonical_smile = Chem.MolToSmiles(Chem.MolFromSmiles(molecule))\n",
    "    except:\n",
    "        canonical_smile = False\n",
    "    return canonical_smile\n",
    "\n",
    "def get_cluster_count(y_count):\n",
    "    cluster_count = {}\n",
    "    for y in y_count:\n",
    "        if y not in cluster_count:\n",
    "            cluster_count[y] = 1\n",
    "        else:\n",
    "            cluster_count[y] +=1\n",
    "    return (cluster_count)\n",
    "\n",
    "def randomize_smiles(smiles,random_smiles=[],iteration=5):\n",
    "    try:\n",
    "        m = Chem.MolFromSmiles(smiles)\n",
    "        ans = list(range(m.GetNumAtoms()))\n",
    "        np.random.shuffle(ans)\n",
    "        nm = Chem.RenumberAtoms(m,ans)\n",
    "        out_smiles = (Chem.MolToSmiles(nm, canonical=False, isomericSmiles=True, kekuleSmiles=False))\n",
    "    except:\n",
    "        return (False)\n",
    "    \n",
    "    if out_smiles not in random_smiles:\n",
    "        return out_smiles\n",
    "    else:\n",
    "        iteration -= 1\n",
    "        if iteration > 0:\n",
    "            out_smiles = randomize_smiles(smiles,random_smiles,iteration)\n",
    "            return out_smiles\n",
    "        return (False)\n",
    "    \n",
    "def augment_smiles(count,iteration,smiles):\n",
    "    random_smiles = []\n",
    "    for i in range(count):\n",
    "        if smiles != None:\n",
    "            out_smiles = randomize_smiles(smiles,random_smiles,iteration=iteration)\n",
    "            if out_smiles:\n",
    "                random_smiles.append(out_smiles)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "    return random_smiles\n",
    "\n",
    "def unpack_and_write_list(smiles,label,filename):\n",
    "    for entry in smiles:\n",
    "        if type(entry) == list:\n",
    "            unpack_and_write_list(entry,label,filename)\n",
    "        else:\n",
    "            filename.write(entry + \",\" + str(label) + \"\\n\")\n",
    "    \n",
    "def smiles_augmentation(df, N_rounds=1,iteration=5,data_set_type=\"train\"):\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(\"data\")\n",
    "        os.mkdir(\"data/classification\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    filename = \"data/classification/\" + str(data_set_type) + \"_aug_canonical_smiles.csv\"\n",
    "\n",
    "    aug_out = open(filename,\"w\")\n",
    "\n",
    "    aug_out.write(\"Smiles,Label\\n\")\n",
    "        \n",
    "    labels = []\n",
    "    for label in df.groupby('Label'):\n",
    "        labels.append(label[0])\n",
    "    \n",
    "    augmentation_list = []\n",
    "    if type(N_rounds) == list:\n",
    "        assert(len(N_rounds) == len(labels))\n",
    "        augmentation_list = N_rounds\n",
    "    else:\n",
    "        for i in range(len(labels)):\n",
    "            augmentation_list.append(N_rounds)\n",
    "        \n",
    "    for label,augmentation in zip(labels,augmentation_list):\n",
    "    \n",
    "        canonical_smiles = df[df['Label'] == label]['Smiles'].to_list()\n",
    "\n",
    "        p = Pool(Number_of_workers)\n",
    "        func = partial(augment_smiles, augmentation, iteration)\n",
    "        augmented_smiles = list(tqdm.tqdm(p.imap(func, canonical_smiles), total=len(canonical_smiles),leave=False))\n",
    "        p.close()\n",
    "    \n",
    "        print (\"Saving data for label = \" + str(label))\n",
    "\n",
    "        unpack_and_write_list(augmented_smiles,label,filename=aug_out)\n",
    "\n",
    "        unpack_and_write_list(canonical_smiles,label,filename=aug_out)\n",
    "        \n",
    "        print (\"Saved data for label = \" + str(label))\n",
    "        \n",
    "    aug_out.close()\n",
    "    \n",
    "    return (pd.read_csv(filename, header=0).sample(frac=1).reset_index(drop=True))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: (9854, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C(C1C(C(C(C(O1)O)O)OC2C(C(C(C(O2)COC3C(C(C(C(O...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCCCCC1=CC2=C(C(=C1)O)C3=C(C=CC(=C3)C)C(O2)(C)C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C(CSCC(C(=O)O)N)[NH3+].[Cl-]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC1=CC2=C(C=C1)OC(=O)C(=C2)C(=O)O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C1=CC(=CC=C1CCN)O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Smiles  Label\n",
       "0  C(C1C(C(C(C(O1)O)O)OC2C(C(C(C(O2)COC3C(C(C(C(O...      1\n",
       "1    CCCCCC1=CC2=C(C(=C1)O)C3=C(C=CC(=C3)C)C(O2)(C)C      0\n",
       "2                       C(CSCC(C(=O)O)N)[NH3+].[Cl-]      1\n",
       "3                  CC1=CC2=C(C=C1)OC(=O)C(=C2)C(=O)O      1\n",
       "4                                  C1=CC(=CC=C1CCN)O      1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if multi_files:\n",
    "    for i,input_filename in enumerate(input_file):\n",
    "        if i != 0:\n",
    "            quantmap_data2 = pd.read_csv(input_filename,sep=\" \",names=[\"Smiles\", \"Label\"]).sample(frac=1).reset_index(drop=True) #,header=None)\n",
    "            quantmap_data = pd.concat([quantmap_data,quantmap_data2])\n",
    "        else:\n",
    "            quantmap_data = pd.read_csv(input_filename,sep=\" \",names=[\"Smiles\", \"Label\"]).sample(frac=1).reset_index(drop=True) #,header=None)\n",
    "    del quantmap_data2\n",
    "else:\n",
    "    quantmap_data = pd.read_csv(input_file,sep=\" \",names=[\"Smiles\", \"Label\"]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "print('Dataset:', quantmap_data.shape)\n",
    "quantmap_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Smiles\n",
      "Label        \n",
      "0        1919\n",
      "1        4662\n",
      "2        2508\n",
      "3         390\n",
      "4         375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Smiles\n",
       "Label        \n",
       "0        1919\n",
       "1        4662\n",
       "2        2508\n",
       "3         390\n",
       "4         375"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (quantmap_data.groupby('Label').count())\n",
    "if not trial:\n",
    "    log_file.write(\"Class distribution before augmentation\\n\")\n",
    "    log_file.write(str(quantmap_data.groupby('Label').count()) + \"\\n\")\n",
    "    \n",
    "quantmap_data.groupby('Label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count_df = quantmap_data.groupby('Label').count()\n",
    "label_count_list = []\n",
    "for entry in range(len(label_count_df)):\n",
    "    label_count_list.append(label_count_df.iloc[entry][0])\n",
    "\n",
    "augmentation_list = []\n",
    "max_value = max(label_count_list)\n",
    "for entry in label_count_list:\n",
    "    augmentation_list.append(int(max_value/entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data for label = 0\n",
      "Saved data for label = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data for label = 1\n",
      "Saved data for label = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data for label = 2\n",
      "Saved data for label = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data for label = 3\n",
      "Saved data for label = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data for label = 4\n",
      "Saved data for label = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "###\n",
    "augmentation_list = [entry*number_of_augmentation for entry in augmentation_list]\n",
    "iteration = 10000\n",
    "# Augmentation for training data\n",
    "quantmap_data = smiles_augmentation(quantmap_data,N_rounds=augmentation_list,iteration=iteration,data_set_type=\"all_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Smiles\n",
      "Label        \n",
      "0        5749\n",
      "1        9323\n",
      "2        5016\n",
      "3        4569\n",
      "4        4680\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Smiles\n",
       "Label        \n",
       "0        5749\n",
       "1        9323\n",
       "2        5016\n",
       "3        4569\n",
       "4        4680"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (quantmap_data.groupby('Label').count())\n",
    "if not trial:\n",
    "    log_file.write(\"number of augmentation = \" + str(number_of_augmentation) + \"\\n\")\n",
    "    log_file.write(\"Class distribution after augmentation\\n\")\n",
    "    log_file.write(str(quantmap_data.groupby('Label').count()) + \"\\n\")\n",
    "    log_file.write(\"Train/valid split ratio = \" + str(train_percentage) + \"\\n\")\n",
    "    \n",
    "quantmap_data.groupby('Label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_label = \"None\" #\"fingerprint\"\n",
    "class MolTokenizer():\n",
    "    def __init__(self, lang = 'en'):\n",
    "        self.lang = lang\n",
    "        \n",
    "    def tokenizer(self, output_label=None,smiles=None):\n",
    "        tokens = atomwise_tokenizer(smiles)\n",
    "        tokens.insert(0, \"<SOS>\") \n",
    "        tokens.append(\"<EOS>\") \n",
    "        if output_label != \"fingerprint\":\n",
    "            return tokens\n",
    "        else:\n",
    "            try:\n",
    "                fingerprint = smiles_fingerprint(smiles,\"morgan\", radius=2,bits=1024)\n",
    "                return tokens,fingerprint\n",
    "            except:\n",
    "                return None,None\n",
    "        \n",
    "    def add_special_cases(self, toks):\n",
    "        pass\n",
    "\n",
    "tok = MolTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make vocabulary\n",
    "\n",
    "def unpack_vocab_list(vocab_list,vocab_unpacked):\n",
    "    for entry in vocab_list:\n",
    "        if type(entry) == list:\n",
    "            unpack_vocab_list(entry,vocab_unpacked)\n",
    "        else:\n",
    "            vocab_unpacked.append(entry)\n",
    "            \n",
    "    return (vocab_unpacked)\n",
    "            \n",
    "def make_vocabulary(input_list):\n",
    "    p = Pool(Number_of_workers)\n",
    "    func = partial(tok.tokenizer, None)\n",
    "    vocab_list = list(tqdm.tqdm(p.imap(func, input_list), total=len(input_list),leave=False))\n",
    "    p.close()\n",
    "    vocab_unpacked = []\n",
    "    return (list(set(unpack_vocab_list(vocab_list,vocab_unpacked))))\n",
    "\n",
    "def make_word_index(vocab):\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "    for i,entry in enumerate(vocab):\n",
    "        word_index[entry] = i\n",
    "        index_word[i] = entry\n",
    "    return (word_index,index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_vocab_file = True\n",
    "\n",
    "if use_vocab_file:\n",
    "    en_vocab = open(\"en_vocab_.txt\",\"r\").read().strip(\"[]\").replace(\"'\", \"\").replace(\" \", \"\").split(\",\")\n",
    "    en_word_index,en_index_word = make_word_index(en_vocab)\n",
    "    \n",
    "else:\n",
    "    all_smiles = quantmap_data[\"Smiles\"].to_list()\n",
    "\n",
    "    en_vocab = [\"<PAD>\",\"<UNK>\"]\n",
    "    en_vocab.extend(make_vocabulary(all_smiles))\n",
    "    del all_smiles\n",
    "\n",
    "    ###\n",
    "    en_word_index,en_index_word = make_word_index(en_vocab)\n",
    "\n",
    "    vocab_output = open(\"en_vocab_.txt\",\"w\")\n",
    "    vocab_output.write(str(en_vocab))\n",
    "    vocab_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/anaconda3/envs/molpmofit/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "/home/jovyan/anaconda3/envs/molpmofit/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Smiles\n",
       "Label        \n",
       "0        4569\n",
       "1        4680"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing unbalanced data and shuffling\n",
    "balanced_data = quantmap_data [quantmap_data.Label != 0][quantmap_data.Label != 1][quantmap_data.Label != 2]\n",
    "balanced_data = balanced_data.sample(frac=1).reset_index(drop=True)\n",
    "balanced_data[\"Label\"].replace({3: 0,4:1}, inplace=True)\n",
    "balanced_data.groupby('Label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not trial:\n",
    "    log_file.write(\"Class distribution after balanced dataset\\n\")\n",
    "    log_file.write(str(balanced_data.groupby('Label').count()) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count_list = np.array([entry for entry in balanced_data.groupby('Label').count()[\"Smiles\"]])\n",
    "class_weight = np.max(class_count_list)/class_count_list\n",
    "class_weight = torch.FloatTensor(class_weight).cuda()\n",
    "\n",
    "if not trial:\n",
    "    log_file.write(\"Class weight for loss (balancing weights)= \" + str(class_weight) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_smiles_to_tokens(df):\n",
    "    \n",
    "    if output_label != \"fingerprint\": # Maintain the y from the data as label\n",
    "        labels = []\n",
    "        for label in df.groupby('Label'):\n",
    "            labels.append(label[0])\n",
    "            \n",
    "        x = []\n",
    "        y = []\n",
    "        p = Pool(Number_of_workers)\n",
    "        for label in labels:\n",
    "            smiles_list = df[df['Label'] == label]['Smiles'].to_list()\n",
    "            \n",
    "            \n",
    "            func = partial(tok.tokenizer, None)\n",
    "            tokens = list(tqdm.tqdm(p.imap(func, smiles_list), total=len(smiles_list),leave=False))\n",
    "            \n",
    "            #p = Pool(Number_of_workers)\n",
    "            #tokens = list(tqdm.tqdm(p.imap(tok.tokenizer, smiles_list), total=len(smiles_list),leave=False))\n",
    "            #p.close()\n",
    "            #if len(tokens) < 100:\n",
    "            for entry in tokens:\n",
    "                if  5 < len(entry) <= 150:\n",
    "                #break\n",
    "                    x.append(entry)\n",
    "                    y.append(label)\n",
    "            #x.extend(tokens)\n",
    "            #y.extend([label for i in range(len(tokens))])\n",
    "        p.close()\n",
    "            \n",
    "    else: # Return fingerprint as label for each object\n",
    "        x = []\n",
    "        y = []\n",
    "        smiles_list = df['Smiles'].to_list()\n",
    "        \n",
    "        func = partial(tok.tokenizer, output_label)\n",
    "        \n",
    "        for entry in smiles_list:\n",
    "            xout,yout = (func(entry))\n",
    "            if xout != None:\n",
    "                x.append(xout)\n",
    "                y.append([int(entry) for entry in yout])\n",
    "        \n",
    "        print (str(len(smiles_list)-len(x)) + \" incorrect smiles detected and deleted\"  )\n",
    "        \n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    }
   ],
   "source": [
    "x,y= convert_smiles_to_tokens(balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenthwise_x = [len(entry) for entry in x if len(entry)]\n",
    "if not trial:\n",
    "    log_file.write(\"Data point with (5 < len(sequence) <= 150) = \" + str(len(lenthwise_x)) +\"/\"+ str(sum(class_count_list)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(lenthwise_x, density=True, bins=30)  # density=False would make counts\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Data');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_token_to_index(molecule):\n",
    "    idxs = []\n",
    "    for ch in molecule:\n",
    "        if ch in en_word_index:\n",
    "            idxs.append(en_word_index[ch])\n",
    "        else:\n",
    "            idxs.append(en_word_index[\"<UNK>\"])\n",
    "    return torch.tensor(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    }
   ],
   "source": [
    "x_indexed_token = []\n",
    "loop = tqdm.tqdm(x, total=len(x),leave=False)\n",
    "for entry in loop:\n",
    "    x_indexed_token.append(convert_token_to_index(entry))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_test_percentage = (1 - train_percentage)/2\n",
    "\n",
    "data_to_use = balanced_data\n",
    "# Ratios\n",
    "train_ratio = int (len(data_to_use) * train_percentage)\n",
    "valid_ratio = train_ratio + int(len(data_to_use)*valid_test_percentage)\n",
    "test_ratio = valid_ratio + int(len(data_to_use)*valid_test_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make index to split into train and val set\n",
    "def make_index(len_data,train_ratio,valid_ratio,test_ratio):\n",
    "    \n",
    "    index = np.random.permutation(len_data)\n",
    "    \n",
    "    # Train index and val index\n",
    "    return (index[:train_ratio],index[train_ratio:valid_ratio],index[valid_ratio:test_ratio])\n",
    "\n",
    "train_index ,valid_index,test_index = make_index(len(data_to_use),train_ratio,valid_ratio,test_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders by padding the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_padded = pad_sequence(x_indexed_token,batch_first=True, padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, TensorDataset, SubsetRandomSampler\n",
    "\n",
    "train_sample = SubsetRandomSampler(train_index)\n",
    "valid_sample = SubsetRandomSampler(valid_index)\n",
    "test_sample = SubsetRandomSampler(test_index)\n",
    "batch_size = 512\n",
    "\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(x_padded,torch.tensor(y))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                        sampler=train_sample)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                        sampler=valid_sample)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                        sampler=test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data without padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(data):\n",
    "    \n",
    "    index = np.random.permutation(len(data))\n",
    "    \n",
    "    output_shuffled = []\n",
    "    for i in index:\n",
    "        output_shuffled.append(data[i])\n",
    "        \n",
    "    return (output_shuffled)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = shuffle_data([(entry,y[i]) for i,entry in enumerate(x_indexed_token) if i in train_index])\n",
    "valid_data = shuffle_data([(entry,y[i]) for i,entry in enumerate(x_indexed_token) if i in valid_index])\n",
    "test_data = shuffle_data([(entry,y[i]) for i,entry in enumerate(x_indexed_token) if i in test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset class for loading data.\n",
    "      This is where the data parsing happens.\n",
    "      This class is built with reusability in mind.\n",
    "      Arguments:\n",
    "      path (:obj:`str`):\n",
    "      Path to the data partition.\n",
    "      \"\"\"\n",
    "    \n",
    "    def __init__(self, data_tuple):\n",
    "\n",
    "        # Check if path exists.\n",
    "        #if not os.path.isdir(path):\n",
    "          # Raise error if path is invalid.\n",
    "          #raise ValueError('Invalid `path` variable! Needs to be a directory')\n",
    "    \n",
    "        self.texts = []\n",
    "        self.labels = []\n",
    "        # Since the labels are defined by folders with data we loop \n",
    "        # through each label.\n",
    "        '''for label  in ['pos', 'neg']:\n",
    "            sentiment_path = os.path.join(path, label)\n",
    "\n",
    "            # Get all files from path.\n",
    "            files_names = os.listdir(sentiment_path)#[:10] # Sample for debugging.\n",
    "            # Go through each file and read its content.\n",
    "            for file_name in tqdm(files_names, desc=f'{label} Files'):\n",
    "                file_path = os.path.join(sentiment_path, file_name)\n",
    "\n",
    "                # Read content.\n",
    "                content = io.open(file_path, mode='r', encoding='utf-8').read()\n",
    "                # Fix any unicode issues.\n",
    "                content = fix_text(content)\n",
    "                # Save content.\n",
    "                self.texts.append(content)\n",
    "                # Save labels.\n",
    "                self.labels.append(label)'''\n",
    "        for entry in data_tuple:\n",
    "            self.texts.append(entry[0])\n",
    "            self.labels.append(entry[1])\n",
    "        # Number of examples.\n",
    "        self.n_examples = len(self.labels)\n",
    "        return\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"When used `len` return the number of examples.\"\"\"\n",
    "        return self.n_examples\n",
    "\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \"\"\"Given an index return an example from the position.\n",
    "        Arguments:\n",
    "          item (:obj:`int`):\n",
    "              Index position to pick an example to return.\n",
    "        Returns:\n",
    "          :obj:`Dict[str, str]`: Dictionary of inputs that are used to feed \n",
    "          to a model.\n",
    "        \"\"\"\n",
    "        return {'text':self.texts[item], 'label':self.labels[item]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MakeDataset(train_data)\n",
    "valid_dataset = MakeDataset(valid_data)\n",
    "test_dataset = MakeDataset(test_data)\n",
    "\n",
    "from torchtext import data\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_iterator = data.BucketIterator(\n",
    "    train_dataset,\n",
    "    sort = False,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x['text']),\n",
    "    batch_size = batch_size,\n",
    "    device = device)\n",
    "\n",
    "valid_iterator = data.BucketIterator(\n",
    "    valid_dataset,\n",
    "    sort = False,\n",
    "    shuffle=True,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x['text']),\n",
    "    batch_size = batch_size,\n",
    "    device = device)\n",
    "\n",
    "test_iterator = data.BucketIterator(\n",
    "    test_dataset,\n",
    "    sort = False,\n",
    "    shuffle=True,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x['text']),\n",
    "    batch_size = batch_size,\n",
    "    device = device)\n",
    "\n",
    "if not trial:\n",
    "    log_file.write(\"Batch size = \" + str(batch_size) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size) #,padding_idx=0)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p,batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (N,seq_length) where N is batch size\n",
    "        \n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (N,seq_length, embedding_size)\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (N,seq_length, hidden_size)\n",
    "        \n",
    "        #cat = torch.cat(hidden[0],hidden[1],hidden[2],dim=2)\n",
    "        #print (hidden.view(1,-1).shape)\n",
    "        #print (hidden[2].shape)\n",
    "        return hidden[2]\n",
    "        #return hidden.view(-1,hidden[2].shape[1]*3)\n",
    "\n",
    "\n",
    "class FC_layer(nn.Module):\n",
    "    def __init__(\n",
    "        self, hidden_size, output_size,p):\n",
    "        super(FC_layer, self).__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size, 1024)\n",
    "        #self.bn1 = nn.BatchNorm1d(1024)\n",
    "        \n",
    "        #self.fc2 = nn.Linear(1024, 512)\n",
    "        #self.bn2 = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.fc3 = nn.Linear(1024, output_size)\n",
    "\n",
    "    def forward(self, hidden):\n",
    "        fc_out = self.relu(self.dropout(self.fc1(hidden)))\n",
    "        #fc_out = self.relu(self.dropout(self.fc2(fc_out)))\n",
    "        #fc_out = self.dropout(self.fc2(fc_out))\n",
    "        fc_out = self.fc3(fc_out)\n",
    "        \n",
    "        return fc_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs to be the same for both RNN's\n",
    "hidden_size = 1024  \n",
    "num_layers = 3\n",
    "\n",
    "\n",
    "\n",
    "input_size_encoder = len(en_vocab)\n",
    "en_embedding_size = 400\n",
    "en_dropout = 0.4\n",
    "\n",
    "encoder_net = Encoder(\n",
    "    input_size_encoder, \n",
    "    en_embedding_size, \n",
    "    hidden_size, \n",
    "    num_layers, \n",
    "    en_dropout).to(device)\n",
    "\n",
    "de_dropout = 0.4\n",
    "\n",
    "output_size = len(set(y))\n",
    "\n",
    "FC_layer = FC_layer(hidden_size, \n",
    "                   output_size,\n",
    "                   de_dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, FC_layer):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.FC_layer = FC_layer\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[0]\n",
    "\n",
    "        hidden = self.encoder(source)\n",
    "        outputs = self.FC_layer(hidden)\n",
    "        \n",
    "        #outputs = self.softmax(outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "# Training hyperparameters\n",
    "#epochs = 10\n",
    "#learning_rate = 0.00005\n",
    "\n",
    "model = Seq2Seq(encoder_net, FC_layer).to(device)\n",
    "model.load_state_dict(torch.load(\"test_model.pth\"), strict=False)\n",
    "model.to(device)\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched = False\n",
    "\n",
    "def validate(val_dl):\n",
    "    model.eval()\n",
    "    total_loss = []\n",
    "    accuracy = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        val_dl.create_batches()\n",
    "        loop = tqdm.tqdm(enumerate(val_dl.batches), total=len(val_dl),leave=False)\n",
    "        for i,batch in loop:\n",
    "            batch_text = [example[\"text\"] for example in batch]\n",
    "            batch_label = torch.tensor([example[\"label\"] for example in batch])\n",
    "            x_padded = pad_sequence(batch_text,batch_first=True, padding_value=0)\n",
    "            xvalc = x_padded.to(device)\n",
    "            yvalc = batch_label.to(device)\n",
    "            \n",
    "            '''loop = tqdm.tqdm(enumerate(val_dl), total=len(val_dl),leave=False)\n",
    "            for i, (xval,yval) in loop:\n",
    "            xval = xval.view(1,-1)\n",
    "            yval = yval.view(1,-1)\n",
    "            xvalc = xval.to(device)\n",
    "            yvalc = yval.to(device)'''\n",
    "\n",
    "            # Forward prop\n",
    "            output_val = model(xvalc.long(),yvalc)\n",
    "\n",
    "            #print (output_train.shape,ybc.shape)\n",
    "\n",
    "            accuracy.append(get_accuracy(output_val,yvalc))\n",
    "\n",
    "            loss_val = criterion(output_val, yvalc)\n",
    "            #loss_val = criterion(output_val, yvalc)\n",
    "\n",
    "            total_loss.append(loss_val.item())\n",
    "            \n",
    "            loop.set_postfix(loss = sum(total_loss)/(i+1),acc = sum(accuracy)/(len(accuracy)))\n",
    "    return (sum(total_loss)/(i+1),sum(accuracy)/(len(accuracy)))\n",
    "    \n",
    "def train(train_dl):\n",
    "    model.train()\n",
    "    total_loss = []\n",
    "    accuracy = []\n",
    "    \n",
    "    \n",
    "    train_dl.create_batches()\n",
    "    loop = tqdm.tqdm(enumerate(train_dl.batches), total=len(train_dl),leave=False)\n",
    "    \n",
    "    for i,batch in loop:\n",
    "        batch_text = [example[\"text\"] for example in batch]\n",
    "        batch_label = torch.tensor([example[\"label\"] for example in batch])\n",
    "        \n",
    "        x_padded = pad_sequence(batch_text,batch_first=True, padding_value=0)\n",
    "        \n",
    "        xbc = x_padded.to(device)\n",
    "        ybc = batch_label.to(device)\n",
    "        \n",
    "        '''loop = tqdm.tqdm(enumerate(train_dl), total=len(train_dl),leave=False)\n",
    "        for i, (xb,yb) in loop:\n",
    "    \n",
    "        xb = xb.view(1,-1)\n",
    "        yb = yb.view(1,-1)\n",
    "        xbc = xb.to(device)\n",
    "        ybc = yb.to(device)'''\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward prop\n",
    "        output_train = model(xbc.long(),ybc)\n",
    "\n",
    "        accuracy.append(get_accuracy(output_train,ybc))\n",
    "        \n",
    "        \n",
    "        loss_train = criterion(output_train, ybc)\n",
    "        \n",
    "        # Back prop\n",
    "        loss_train.backward()\n",
    "        \n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss.append(loss_train.item())\n",
    "        loop.set_postfix(loss = sum(total_loss)/(i+1),acc = sum(accuracy)/(len(accuracy)))\n",
    "        #if i % 1000 == 0:\n",
    "        #    print (\"Batch \" + str(i) + \" train loss = \" + str(sum(total_loss)/(i+1)) )\n",
    "\n",
    "        gc.collect()\n",
    "    return (sum(total_loss)/(i+1),sum(accuracy)/(len(accuracy)))\n",
    "\n",
    "\n",
    "def get_accuracy(yhat,y): #  FOR BCE ERROR\n",
    "    \n",
    "    if batched:\n",
    "        batch_accuracy = []\n",
    "        for batch in range(yhat.shape[0]):\n",
    "            accuracy_list = []\n",
    "            \n",
    "            for i,entry in enumerate(yhat[batch]):\n",
    "                softmax = torch.exp(entry.float())\n",
    "                prob = list(softmax.cpu().detach().numpy())\n",
    "                predictions = np.argmax(prob, axis=0)\n",
    "                accuracy_list.append(np.argmax(y[batch][i].cpu().detach().numpy(), axis=0) == predictions != 0)\n",
    "            batch_accuracy.append((np.sum(np.array(accuracy_list))*1.0)/len(accuracy_list))\n",
    "            \n",
    "        return np.sum(batch_accuracy)/len(batch_accuracy)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        accuracy_list = []\n",
    "        #print (yhat.shape[0])\n",
    "        for i,entry in enumerate(yhat):\n",
    "            #if y[i].cpu().detach().numpy() != 0:\n",
    "                #print (entry.shape)\n",
    "            softmax = torch.exp(entry.float())\n",
    "            prob = list(softmax.cpu().detach().numpy())\n",
    "            predictions = np.argmax(prob, axis=0)\n",
    "                #if random.random() > 0.99:\n",
    "                #    print (predictions,y[i],y[i].cpu().detach().numpy())\n",
    "            #print (yhat,predictions,y[i].cpu().detach().numpy())\n",
    "            accuracy_list.append(y[i].cpu().detach().numpy() == predictions)\n",
    "            \n",
    "        return (np.sum(np.array(accuracy_list))*1.0)/len(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Seq2Seq(\n",
       "   (encoder): Encoder(\n",
       "     (dropout): Dropout(p=0.4, inplace=False)\n",
       "     (embedding): Embedding(153, 400)\n",
       "     (rnn): LSTM(400, 1024, num_layers=3, batch_first=True, dropout=0.4)\n",
       "   )\n",
       "   (FC_layer): FC_layer(\n",
       "     (dropout): Dropout(p=0.4, inplace=False)\n",
       "     (relu): ReLU()\n",
       "     (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "     (fc3): Linear(in_features=1024, out_features=2, bias=True)\n",
       "   )\n",
       "   (softmax): Softmax(dim=None)\n",
       " ),\n",
       " odict_keys(['encoder.embedding.weight', 'encoder.rnn.weight_ih_l0', 'encoder.rnn.weight_hh_l0', 'encoder.rnn.bias_ih_l0', 'encoder.rnn.bias_hh_l0', 'encoder.rnn.weight_ih_l1', 'encoder.rnn.weight_hh_l1', 'encoder.rnn.bias_ih_l1', 'encoder.rnn.bias_hh_l1', 'encoder.rnn.weight_ih_l2', 'encoder.rnn.weight_hh_l2', 'encoder.rnn.bias_ih_l2', 'encoder.rnn.bias_hh_l2', 'FC_layer.fc1.weight', 'FC_layer.fc1.bias', 'FC_layer.fc3.weight', 'FC_layer.fc3.bias']))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = model.state_dict()\n",
    "model,params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing layers except FC\n",
    "model.encoder.embedding.weight.requires_grad = False\n",
    "\n",
    "'''\n",
    "lstm_list = [model.encoder.rnn.parameters()]\n",
    "\n",
    "for entry in lstm_list:\n",
    "    for param in entry:\n",
    "        param.requires_grad = False'''\n",
    "\n",
    "model.encoder.rnn.bias_hh_l2.requires_grad = False\n",
    "model.encoder.rnn.bias_ih_l2.requires_grad = False\n",
    "model.encoder.rnn.weight_hh_l2.requires_grad = False\n",
    "model.encoder.rnn.weight_ih_l2.requires_grad = False\n",
    "\n",
    "model.encoder.rnn.bias_hh_l1.requires_grad = False\n",
    "model.encoder.rnn.bias_ih_l1.requires_grad = False\n",
    "model.encoder.rnn.weight_hh_l1.requires_grad = False\n",
    "model.encoder.rnn.weight_ih_l1.requires_grad = False\n",
    "\n",
    "model.encoder.rnn.bias_hh_l0.requires_grad = False\n",
    "model.encoder.rnn.bias_ih_l0.requires_grad = False\n",
    "model.encoder.rnn.weight_hh_l0.requires_grad = False\n",
    "model.encoder.rnn.weight_ih_l0.requires_grad = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store values\n",
    "train_loss_list = []\n",
    "train_accu_list = []\n",
    "val_loss_list = []\n",
    "val_accu_list = []\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:27,  5.94it/s, acc=0.5, loss=0.67]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 \t LOSS train: 0.6847146088687274  val: 0.6689971192129727 \tACCU train: 0.5613942307692308  val: 0.5962643678160918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:42,  5.06it/s, acc=0.5, loss=0.635]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 \t LOSS train: 0.6688263922356642  val: 0.6793999240316194 \tACCU train: 0.5808653846153846  val: 0.5524425287356323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:24,  6.15it/s, acc=0.688, loss=0.593]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 \t LOSS train: 0.668701201906571  val: 0.67783850225909 \tACCU train: 0.5863461538461539  val: 0.5545977011494254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:30,  5.72it/s, acc=0.5, loss=0.729]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4 \t LOSS train: 0.6604055265394541  val: 0.6696738374644312 \tACCU train: 0.5996153846153847  val: 0.5725574712643677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/520 [00:00<00:58,  8.91it/s, acc=0.594, loss=0.68]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5 \t LOSS train: 0.6580033152149274  val: 0.6689938882301594 \tACCU train: 0.6036778846153846  val: 0.5962643678160918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:04,  8.03it/s, acc=0.531, loss=0.67]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6 \t LOSS train: 0.6544417283855952  val: 0.6785868694042337 \tACCU train: 0.6048076923076923  val: 0.5567528735632185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:30,  5.75it/s, acc=0.688, loss=0.607]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7 \t LOSS train: 0.6500399762048171  val: 0.6628701316899267 \tACCU train: 0.6047596153846154  val: 0.5632183908045977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/520 [00:00<?, ?it/s, acc=0.625, loss=0.682]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8 \t LOSS train: 0.6529816659024128  val: 0.6637819964310219 \tACCU train: 0.6048798076923078  val: 0.5818965517241379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:19,  6.49it/s, acc=0.688, loss=0.611]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9 \t LOSS train: 0.654660230416518  val: 0.6618087846657326 \tACCU train: 0.6075240384615385  val: 0.5775862068965517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:31,  5.68it/s, acc=0.562, loss=0.602]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10 \t LOSS train: 0.6479097658051894  val: 0.6573749492908346 \tACCU train: 0.6108413461538461  val: 0.6091954022988505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:09,  7.44it/s, acc=0.656, loss=0.608]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 11 \t LOSS train: 0.6461480975724183  val: 0.6596709798122274 \tACCU train: 0.6155048076923076  val: 0.5955459770114943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:42,  5.08it/s, acc=0.625, loss=0.676]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 12 \t LOSS train: 0.6443156091066508  val: 0.6766595593814192 \tACCU train: 0.6191586538461538  val: 0.5955459770114944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/520 [00:00<01:10,  7.35it/s, acc=0.688, loss=0.6]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 13 \t LOSS train: 0.6400068285946663  val: 0.6628197513777634 \tACCU train: 0.6235336538461539  val: 0.5689655172413793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:23,  6.22it/s, acc=0.5, loss=0.767]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 14 \t LOSS train: 0.6376628140990551  val: 0.6568971954543015 \tACCU train: 0.6211298076923077  val: 0.6027298850574712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:05,  7.93it/s, acc=0.625, loss=0.701]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 15 \t LOSS train: 0.6413021871676812  val: 0.6597229129281538 \tACCU train: 0.6188701923076924  val: 0.5818965517241379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:01,  8.45it/s, acc=0.75, loss=0.635]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 16 \t LOSS train: 0.6374330318891085  val: 0.6482943769158989 \tACCU train: 0.6186298076923077  val: 0.5783045977011495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:15,  6.89it/s, acc=0.812, loss=0.514]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 17 \t LOSS train: 0.6369038605346129  val: 0.6459937897221796 \tACCU train: 0.6202163461538461  val: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/520 [00:00<00:54,  9.43it/s, acc=0.531, loss=0.733]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 18 \t LOSS train: 0.6338660661990826  val: 0.6512321542049276 \tACCU train: 0.6258894230769231  val: 0.6091954022988505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:22,  6.32it/s, acc=0.5, loss=0.656]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 19 \t LOSS train: 0.6367859579622746  val: 0.669158228512468 \tACCU train: 0.6253125  val: 0.567528735632184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 20 \t LOSS train: 0.6350169279827521  val: 0.6546549714844803 \tACCU train: 0.6293269230769231  val: 0.5876436781609194\n"
     ]
    }
   ],
   "source": [
    "#loop = tqdm.tqdm(range(epochs), total=epochs,leave=False)\n",
    "epochs = 20\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "\n",
    "if not trial:\n",
    "    log_file.write(\"model = \" + str(model) + \"\\n\")\n",
    "    log_file.write(\"\\nEmbedding layer and LSTM frozen\\n\")\n",
    "    log_file.write(\"learning_rate = \" + str(learning_rate) + \"\\n\")\n",
    "    log_file.write(\"epochs = \" + str(epochs) + \"\\n\")\n",
    "    log_file.write(\"Epoch\\tLOSStrain\\tLOSSval\\tACCUtrain\\tACCUval\\n\") \n",
    "    \n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #print (\"EPOCH \" + str(epoch))\n",
    "    \n",
    "    train_loss, train_accu = train(train_iterator)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accu_list.append(train_accu)\n",
    "    \n",
    "    val_loss,val_accu = validate(valid_iterator)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_accu_list.append(val_accu)\n",
    "    \n",
    "    if not trial:\n",
    "        log_file.write(str(epoch+1) + \"\\t\" + str(train_loss) + \"\\t\" + str(val_loss) + \"\\t\" + str(train_accu) + \"\\t\" + str(val_accu)  + \"\\n\")\n",
    "        torch.save(model.state_dict(), \"pretrained_model_epoch\" + str(epoch) + \".pth\")\n",
    "    print (\"Epoch :\",epoch+1,\"\\t\",\"LOSS train:\",train_loss,\" val:\",val_loss, \"\\tACCU train:\",train_accu,\" val:\",val_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing layers except FC and lstm last layer\n",
    "model.encoder.rnn.bias_hh_l2.requires_grad = True\n",
    "model.encoder.rnn.bias_ih_l2.requires_grad = True\n",
    "model.encoder.rnn.weight_hh_l2.requires_grad = True\n",
    "model.encoder.rnn.weight_ih_l2.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:42,  5.08it/s, acc=0.625, loss=0.781]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 \t LOSS train: 0.6225529505656315  val: 0.6495182771107246 \tACCU train: 0.6360817307692308  val: 0.5977011494252873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:28,  5.85it/s, acc=0.812, loss=0.482]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 \t LOSS train: 0.6166448837289443  val: 0.6485425336607571 \tACCU train: 0.6444471153846154  val: 0.6192528735632185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 \t LOSS train: 0.6139047446732337  val: 0.6529821445202005 \tACCU train: 0.6536778846153847  val: 0.5933908045977011\n"
     ]
    }
   ],
   "source": [
    "#loop = tqdm.tqdm(range(epochs), total=epochs,leave=False)\n",
    "epochs = 3\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "\n",
    "if not trial:\n",
    "    log_file.write(\"\\nEmbedding layer and LSTM frozen (except last layer)\\n\")\n",
    "    log_file.write(\"learning_rate = \" + str(learning_rate) + \"\\n\")\n",
    "    log_file.write(\"epochs = \" + str(epochs) + \"\\n\")\n",
    "    log_file.write(\"Epoch\\tLOSStrain\\tLOSSval\\tACCUtrain\\tACCUval\\n\") \n",
    "    \n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #print (\"EPOCH \" + str(epoch))\n",
    "    \n",
    "    train_loss, train_accu = train(train_iterator)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accu_list.append(train_accu)\n",
    "    \n",
    "    val_loss,val_accu = validate(valid_iterator)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_accu_list.append(val_accu)\n",
    "    \n",
    "    if not trial:\n",
    "        log_file.write(str(epoch+1) + \"\\t\" + str(train_loss) + \"\\t\" + str(val_loss) + \"\\t\" + str(train_accu) + \"\\t\" + str(val_accu)  + \"\\n\")\n",
    "        torch.save(model.state_dict(), \"pretrained_model_epoch\" + str(epoch) + \".pth\")\n",
    "    print (\"Epoch :\",epoch+1,\"\\t\",\"LOSS train:\",train_loss,\" val:\",val_loss, \"\\tACCU train:\",train_accu,\" val:\",val_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing layers except FC and lstm last layer\n",
    "model.encoder.rnn.bias_hh_l1.requires_grad = True\n",
    "model.encoder.rnn.bias_ih_l1.requires_grad = True\n",
    "model.encoder.rnn.weight_hh_l1.requires_grad = True\n",
    "model.encoder.rnn.weight_ih_l1.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<02:33,  3.38it/s, acc=0.812, loss=0.586]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 \t LOSS train: 0.6072910618323546  val: 0.6425119751486285 \tACCU train: 0.6594230769230769  val: 0.6192528735632185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:15,  6.83it/s, acc=0.562, loss=0.591]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 \t LOSS train: 0.6017998102765817  val: 0.6326729398349236 \tACCU train: 0.664375  val: 0.6163793103448276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 \t LOSS train: 0.596564650363647  val: 0.6256465058902214 \tACCU train: 0.6646394230769231  val: 0.6271551724137931\n"
     ]
    }
   ],
   "source": [
    "#loop = tqdm.tqdm(range(epochs), total=epochs,leave=False)\n",
    "epochs = 3\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "\n",
    "if not trial:\n",
    "    log_file.write(\"\\nEmbedding layer and LSTM frozen (except last two layers)\\n\")\n",
    "    log_file.write(\"learning_rate = \" + str(learning_rate) + \"\\n\")\n",
    "    log_file.write(\"epochs = \" + str(epochs) + \"\\n\")\n",
    "    log_file.write(\"Epoch\\tLOSStrain\\tLOSSval\\tACCUtrain\\tACCUval\\n\") \n",
    "    \n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #print (\"EPOCH \" + str(epoch))\n",
    "    \n",
    "    train_loss, train_accu = train(train_iterator)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accu_list.append(train_accu)\n",
    "    \n",
    "    val_loss,val_accu = validate(valid_iterator)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_accu_list.append(val_accu)\n",
    "    \n",
    "    if not trial:\n",
    "        log_file.write(str(epoch+1) + \"\\t\" + str(train_loss) + \"\\t\" + str(val_loss) + \"\\t\" + str(train_accu) + \"\\t\" + str(val_accu)  + \"\\n\")\n",
    "        torch.save(model.state_dict(), \"pretrained_model_epoch\" + str(epoch) + \".pth\")\n",
    "    print (\"Epoch :\",epoch+1,\"\\t\",\"LOSS train:\",train_loss,\" val:\",val_loss, \"\\tACCU train:\",train_accu,\" val:\",val_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing layers except FC and lstm last layer\n",
    "model.encoder.rnn.bias_hh_l0.requires_grad = True\n",
    "model.encoder.rnn.bias_ih_l0.requires_grad = True\n",
    "model.encoder.rnn.weight_hh_l0.requires_grad = True\n",
    "model.encoder.rnn.weight_ih_l0.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:01,  8.38it/s, acc=0.875, loss=0.404]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 \t LOSS train: 0.3067046393103038  val: 0.553429489505702 \tACCU train: 0.8461778846153846  val: 0.7787356321839082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:26,  6.02it/s, acc=0.688, loss=0.59]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 \t LOSS train: 0.276562154182018  val: 0.5707759572000339 \tACCU train: 0.8591105769230769  val: 0.778735632183908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:16,  6.83it/s, acc=0.938, loss=0.306]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 \t LOSS train: 0.2699229726496224  val: 0.5877067189792107 \tACCU train: 0.8608653846153845  val: 0.776580459770115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:39,  5.20it/s, acc=0.938, loss=0.151]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4 \t LOSS train: 0.2581252283676384  val: 0.5950849965728563 \tACCU train: 0.8699278846153846  val: 0.7744252873563218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:18,  6.59it/s, acc=0.875, loss=0.249]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5 \t LOSS train: 0.2547635109647392  val: 0.5948334965726425 \tACCU train: 0.8708173076923077  val: 0.7722701149425288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/520 [00:00<?, ?it/s, acc=1, loss=0.117]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6 \t LOSS train: 0.24716682671390186  val: 0.6343058175567923 \tACCU train: 0.8756009615384616  val: 0.7744252873563219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:02,  8.30it/s, acc=0.938, loss=0.206]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7 \t LOSS train: 0.23801098458845024  val: 0.6320955118742483 \tACCU train: 0.8791826923076923  val: 0.7808908045977012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:19,  6.51it/s, acc=0.75, loss=0.298]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8 \t LOSS train: 0.2337915192770127  val: 0.621766621696538 \tACCU train: 0.8845432692307692  val: 0.7701149425287356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:30,  5.73it/s, acc=0.812, loss=0.191]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9 \t LOSS train: 0.23443097790273337  val: 0.6021364721758612 \tACCU train: 0.8815144230769231  val: 0.7722701149425287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:58,  4.39it/s, acc=0.938, loss=0.204]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10 \t LOSS train: 0.22491135105239943  val: 0.6484726320566803 \tACCU train: 0.887860576923077  val: 0.7701149425287357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/520 [00:00<?, ?it/s, acc=0.875, loss=0.243]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 11 \t LOSS train: 0.2165391484731047  val: 0.6770344407394014 \tACCU train: 0.8901923076923076  val: 0.7679597701149427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:29,  5.78it/s, acc=0.875, loss=0.234]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 12 \t LOSS train: 0.2133345408002452  val: 0.6941364818605883 \tACCU train: 0.8905528846153846  val: 0.7787356321839082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:25,  6.04it/s, acc=0.688, loss=0.471]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 13 \t LOSS train: 0.20840182958837922  val: 0.6899240073458902 \tACCU train: 0.8943990384615385  val: 0.7765804597701149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:09,  7.50it/s, acc=0.875, loss=0.259]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 14 \t LOSS train: 0.20910001737692466  val: 0.6675336057769841 \tACCU train: 0.8905769230769232  val: 0.7722701149425287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:23,  6.20it/s, acc=0.812, loss=0.203]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 15 \t LOSS train: 0.20439422445443386  val: 0.6841609984122473 \tACCU train: 0.8942307692307693  val: 0.7830459770114944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:36,  5.37it/s, acc=0.938, loss=0.11]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 16 \t LOSS train: 0.19957903911988698  val: 0.7068184187378863 \tACCU train: 0.8968028846153846  val: 0.7679597701149427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<02:05,  4.14it/s, acc=0.938, loss=0.16]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 17 \t LOSS train: 0.19796773770985265  val: 0.719215475536626 \tACCU train: 0.9004086538461538  val: 0.7722701149425287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:19,  6.56it/s, acc=1, loss=0.00896]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 18 \t LOSS train: 0.19148737721574993  val: 0.7711745739496988 \tACCU train: 0.9031730769230769  val: 0.7650862068965517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/520 [00:00<?, ?it/s]                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 19 \t LOSS train: 0.19014420138577967  val: 0.7065609775740525 \tACCU train: 0.903485576923077  val: 0.7895114942528735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 20 \t LOSS train: 0.18808674813716117  val: 0.7334196246389685 \tACCU train: 0.9030528846153846  val: 0.776580459770115\n"
     ]
    }
   ],
   "source": [
    "#loop = tqdm.tqdm(range(epochs), total=epochs,leave=False)\n",
    "epochs = 20\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "\n",
    "if not trial:\n",
    "    log_file.write(\"\\nOnly embedding layer frozen\\n\")\n",
    "    log_file.write(\"learning_rate = \" + str(learning_rate) + \"\\n\")\n",
    "    log_file.write(\"epochs = \" + str(epochs) + \"\\n\")\n",
    "    log_file.write(\"Epoch\\tLOSStrain\\tLOSSval\\tACCUtrain\\tACCUval\\n\") \n",
    "    \n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #print (\"EPOCH \" + str(epoch))\n",
    "    \n",
    "    train_loss, train_accu = train(train_iterator)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accu_list.append(train_accu)\n",
    "    \n",
    "    val_loss,val_accu = validate(valid_iterator)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_accu_list.append(val_accu)\n",
    "    \n",
    "    if not trial:\n",
    "        log_file.write(str(epoch+1) + \"\\t\" + str(train_loss) + \"\\t\" + str(val_loss) + \"\\t\" + str(train_accu) + \"\\t\" + str(val_accu)  + \"\\n\")\n",
    "        torch.save(model.state_dict(), \"pretrained_model_epoch\" + str(epoch) + \".pth\")\n",
    "    print (\"Epoch :\",epoch+1,\"\\t\",\"LOSS train:\",train_loss,\" val:\",val_loss, \"\\tACCU train:\",train_accu,\" val:\",val_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_list, label='Training loss')\n",
    "plt.plot(val_loss_list, label='Validation loss')\n",
    "plt.legend()\n",
    "if not trial:\n",
    "    plt.savefig(log_file_name[:-4] + \".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched = False\n",
    "\n",
    "def validate(val_dl):\n",
    "    model.eval()\n",
    "    total_loss = []\n",
    "    accuracy = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        val_dl.create_batches()\n",
    "        loop = tqdm.tqdm(enumerate(val_dl.batches), total=len(val_dl),leave=False)\n",
    "        for i,batch in loop:\n",
    "            batch_text = [example[\"text\"] for example in batch]\n",
    "            batch_label = torch.tensor([example[\"label\"] for example in batch])\n",
    "            x_padded = pad_sequence(batch_text,batch_first=True, padding_value=0)\n",
    "            xvalc = x_padded.to(device)\n",
    "            yvalc = batch_label.to(device)\n",
    "            \n",
    "            '''loop = tqdm.tqdm(enumerate(val_dl), total=len(val_dl),leave=False)\n",
    "            for i, (xval,yval) in loop:\n",
    "            xval = xval.view(1,-1)\n",
    "            yval = yval.view(1,-1)\n",
    "            xvalc = xval.to(device)\n",
    "            yvalc = yval.to(device)'''\n",
    "\n",
    "            # Forward prop\n",
    "            output_val = model(xvalc.long(),yvalc)\n",
    "\n",
    "            #print (output_train.shape,ybc.shape)\n",
    "\n",
    "            accuracy.append(get_accuracy(output_val,yvalc))\n",
    "\n",
    "            loss_val = criterion(output_val, yvalc)\n",
    "            #loss_val = criterion(output_val, yvalc)\n",
    "\n",
    "            total_loss.append(loss_val.item())\n",
    "            \n",
    "            loop.set_postfix(loss = sum(total_loss)/(i+1),acc = sum(accuracy)/(len(accuracy)))\n",
    "    return (sum(total_loss)/(i+1),sum(accuracy)/(len(accuracy)))\n",
    "    \n",
    "def train(train_dl):\n",
    "    model.train()\n",
    "    total_loss = []\n",
    "    accuracy = []\n",
    "    \n",
    "    \n",
    "    train_dl.create_batches()\n",
    "    loop = tqdm.tqdm(enumerate(train_dl.batches), total=len(train_dl),leave=False)\n",
    "    \n",
    "    for i,batch in loop:\n",
    "        batch_text = [example[\"text\"] for example in batch]\n",
    "        batch_label = torch.tensor([example[\"label\"] for example in batch])\n",
    "        \n",
    "        x_padded = pad_sequence(batch_text,batch_first=True, padding_value=0)\n",
    "        \n",
    "        xbc = x_padded.to(device)\n",
    "        ybc = batch_label.to(device)\n",
    "        \n",
    "        '''loop = tqdm.tqdm(enumerate(train_dl), total=len(train_dl),leave=False)\n",
    "        for i, (xb,yb) in loop:\n",
    "    \n",
    "        xb = xb.view(1,-1)\n",
    "        yb = yb.view(1,-1)\n",
    "        xbc = xb.to(device)\n",
    "        ybc = yb.to(device)'''\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward prop\n",
    "        output_train = model(xbc.long(),ybc)\n",
    "\n",
    "        accuracy.append(get_accuracy(output_train,ybc))\n",
    "        \n",
    "        \n",
    "        loss_train = criterion(output_train, ybc)\n",
    "        \n",
    "        # Back prop\n",
    "        loss_train.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss.append(loss_train.item())\n",
    "        loop.set_postfix(loss = sum(total_loss)/(i+1),acc = sum(accuracy)/(len(accuracy)))\n",
    "        #if i % 1000 == 0:\n",
    "        #    print (\"Batch \" + str(i) + \" train loss = \" + str(sum(total_loss)/(i+1)) )\n",
    "\n",
    "        gc.collect()\n",
    "    return (sum(total_loss)/(i+1),sum(accuracy)/(len(accuracy)))\n",
    "\n",
    "\n",
    "def get_accuracy(yhat,y): #  FOR BCE ERROR\n",
    "    \n",
    "    if batched:\n",
    "        batch_accuracy = []\n",
    "        \n",
    "        for batch in range(yhat.shape[0]):\n",
    "            accuracy_list = []\n",
    "            \n",
    "            for i,entry in enumerate(yhat[batch]):\n",
    "                softmax = torch.exp(entry.float())\n",
    "                prob = list(softmax.cpu().detach().numpy())\n",
    "                predictions = np.argmax(prob, axis=0)\n",
    "                accuracy_list.append(np.argmax(y[batch][i].cpu().detach().numpy(), axis=0) == predictions != 0)\n",
    "            batch_accuracy.append((np.sum(np.array(accuracy_list))*1.0)/len(accuracy_list))\n",
    "            \n",
    "        return np.sum(batch_accuracy)/len(batch_accuracy)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        accuracy_list = []\n",
    "        for i,entry in enumerate(yhat):\n",
    "            #if y[i].cpu().detach().numpy() != 0:\n",
    "                #print (entry.shape)\n",
    "            softmax = torch.exp(entry.float())\n",
    "            prob = list(softmax.cpu().detach().numpy())\n",
    "            predictions = np.argmax(prob, axis=0)\n",
    "                #if random.random() > 0.99:\n",
    "                #    print (predictions,y[i],y[i].cpu().detach().numpy())\n",
    "            accuracy_list.append(y[i].cpu().detach().numpy() == predictions)\n",
    "            \n",
    "        return (np.sum(np.array(accuracy_list))*1.0)/len(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop = tqdm.tqdm(range(epochs), total=epochs,leave=False)\n",
    "epochs = 1\n",
    "\n",
    "if not trial:\n",
    "    log_file.write(\"model = \" + str(model) + \"\\n\")\n",
    "    log_file.write(\"learning_rate = \" + str(learning_rate) + \"\\n\")\n",
    "    log_file.write(\"epochs = \" + str(epochs) + \"\\n\")\n",
    "    log_file.write(\"Epoch\\tLOSStrain\\tLOSSval\\tACCUtrain\\tACCUval\\n\") \n",
    "    \n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #print (\"EPOCH \" + str(epoch))\n",
    "    \n",
    "    train_loss, train_accu = train(train_iterator)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accu_list.append(train_accu)\n",
    "    \n",
    "    val_loss,val_accu = validate(valid_iterator)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_accu_list.append(val_accu)\n",
    "    \n",
    "    if not trial:\n",
    "        log_file.write(str(epoch+1) + \"\\t\" + str(train_loss) + \"\\t\" + str(val_loss) + \"\\t\" + str(train_accu) + \"\\t\" + str(val_accu)  + \"\\n\")\n",
    "        torch.save(model.state_dict(), \"pretrained_model_epoch\" + str(epoch) + \".pth\")\n",
    "    print (\"Epoch :\",epoch+1,\"\\t\",\"LOSS train:\",train_loss,\" val:\",val_loss, \"\\tACCU train:\",train_accu,\" val:\",val_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_dl,show_predictions=False):\n",
    "    real_and_predictions = []\n",
    "    model.eval()\n",
    "    total_loss = []\n",
    "    accuracy = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        val_dl.create_batches()\n",
    "        loop = tqdm.tqdm(enumerate(val_dl.batches), total=len(val_dl),leave=False)\n",
    "        for i,batch in loop:\n",
    "            batch_text = [example[\"text\"] for example in batch]\n",
    "            batch_label = torch.tensor([example[\"label\"] for example in batch])\n",
    "            x_padded = pad_sequence(batch_text,batch_first=True, padding_value=0)\n",
    "            #y_padded = pad_sequence(batch_label,batch_first=True, padding_value=0)\n",
    "            xvalc = x_padded.to(device)\n",
    "            yvalc = batch_label.to(device)\n",
    "            \n",
    "            '''loop = tqdm.tqdm(enumerate(val_dl), total=len(val_dl),leave=False)\n",
    "            for i, (xval,yval) in loop:\n",
    "            xval = xval.view(1,-1)\n",
    "            yval = yval.view(1,-1)\n",
    "            xvalc = xval.to(device)\n",
    "            yvalc = yval.to(device)'''\n",
    "\n",
    "            # Forward prop\n",
    "            output_val = model(xvalc.long(),yvalc)\n",
    "\n",
    "\n",
    "            accuracy.append(get_accuracy(output_val,yvalc))\n",
    "\n",
    "            loss_val = criterion(output_val, yvalc)\n",
    "            total_loss.append(loss_val.item())\n",
    "            \n",
    "            #print (one_hot_to_index(yvalc)[0],one_hot_to_index(output_val)[0])\n",
    "            if show_predictions:\n",
    "                if batched:\n",
    "                    compound_list_original = index_to_word(yval_reshapedc.cpu().detach().numpy())\n",
    "                    \n",
    "                    compound_list_predicted = []\n",
    "                    for i,entry in enumerate(output_val.view(len(yval_reshaped),-1,len(vocab))):\n",
    "                        softmax = torch.exp(entry.float())\n",
    "                        prob = list(softmax.cpu().detach().numpy())\n",
    "                        predictions = np.argmax(prob, axis=1)\n",
    "                        #print (predictions.shape,output_val.shape,len(compound_list_original[i]))\n",
    "                        pred = \"\"\n",
    "                        for i,entry in enumerate(predictions):\n",
    "                            pred += index_word[entry]\n",
    "                        compound_list_predicted.append(pred) \n",
    "                        \n",
    "                    for i in range(len(compound_list_original)):\n",
    "                        real_and_predictions.append((compound_list_original[i],compound_list_predicted[i]))\n",
    "                else:\n",
    "                    pred = \"\"\n",
    "                    real = \"\"\n",
    "                    softmax = torch.exp(output_val.float())\n",
    "                    prob = list(softmax.cpu().detach().numpy())\n",
    "                    predictions = np.argmax(prob, axis=1)\n",
    "                    for i,entry in enumerate(predictions):\n",
    "                        pred += en_index_word[entry]\n",
    "                        #print (i)\n",
    "                        real += en_index_word[yvalc.cpu().detach().numpy()[i]]\n",
    "                    real_and_predictions.append((real,pred))\n",
    "    return (sum(total_loss)/(i+1),sum(accuracy)/(len(accuracy)),real_and_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    }
   ],
   "source": [
    "loss,accuracy,prediction_list = test(test_iterator,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.803559277827541, 0.7708333333333334)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.803559277827541, 0.7708333333333334)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molpmofit",
   "language": "python",
   "name": "molpmofit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
