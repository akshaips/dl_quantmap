{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda'), True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "\n",
    "from SmilesPE.pretokenizer import atomwise_tokenizer\n",
    "from SmilesPE.pretokenizer import kmer_tokenizer\n",
    "\n",
    "import string\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device,torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = True # setting False saves the output files else not saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Output log file\n",
    "if not trial:\n",
    "    try:\n",
    "        os.system(\"mkdir output_files\")\n",
    "    except:\n",
    "        print (\"Folder output_files already present\")\n",
    "\n",
    "    present_files = glob.glob(\"output_files/log_output_*.txt\")\n",
    "    log_file_name = \"output_files/log_output_\" + str(len(present_files) + 1) + \".txt\"\n",
    "    log_file = open(log_file_name,\"w\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_files = True\n",
    "\n",
    "if multi_files:\n",
    "    input_file = [\"first_5000.txt\",\"ML_input_5338.txt\"]\n",
    "else:\n",
    "    input_file = \"first_5000.txt\" # Input data containing smiles and label\n",
    "\n",
    "if not trial:\n",
    "    log_file.write(\"Used files \" + str(input_file) + \"\\n\")\n",
    "    \n",
    "number_of_augmentation = 1 # Data augmentation multiplier\n",
    "train_percentage = 0.9 # Fraction to use for training (valida and test would be half of remaining data)\n",
    "Number_of_workers = 8 # Number of CPU threads to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove rdkit warnings (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove rdkit warning\n",
    "from rdkit import RDLogger\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_canonical_smiles(molecule):\n",
    "    try:\n",
    "        canonical_smile = Chem.MolToSmiles(Chem.MolFromSmiles(molecule))\n",
    "    except:\n",
    "        canonical_smile = False\n",
    "    return canonical_smile\n",
    "\n",
    "def get_cluster_count(y_count):\n",
    "    cluster_count = {}\n",
    "    for y in y_count:\n",
    "        if y not in cluster_count:\n",
    "            cluster_count[y] = 1\n",
    "        else:\n",
    "            cluster_count[y] +=1\n",
    "    return (cluster_count)\n",
    "\n",
    "def randomize_smiles(smiles,random_smiles=[],iteration=5):\n",
    "    try:\n",
    "        m = Chem.MolFromSmiles(smiles)\n",
    "        ans = list(range(m.GetNumAtoms()))\n",
    "        np.random.shuffle(ans)\n",
    "        nm = Chem.RenumberAtoms(m,ans)\n",
    "        out_smiles = (Chem.MolToSmiles(nm, canonical=False, isomericSmiles=True, kekuleSmiles=False))\n",
    "    except:\n",
    "        return (False)\n",
    "    \n",
    "    if out_smiles not in random_smiles:\n",
    "        return out_smiles\n",
    "    else:\n",
    "        iteration -= 1\n",
    "        if iteration > 0:\n",
    "            out_smiles = randomize_smiles(smiles,random_smiles,iteration)\n",
    "            return out_smiles\n",
    "        return (False)\n",
    "    \n",
    "def augment_smiles(count,iteration,smiles):\n",
    "    random_smiles = []\n",
    "    for i in range(count):\n",
    "        if smiles != None:\n",
    "            out_smiles = randomize_smiles(smiles,random_smiles,iteration=iteration)\n",
    "            if out_smiles:\n",
    "                random_smiles.append(out_smiles)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "    return random_smiles\n",
    "\n",
    "def unpack_and_write_list(smiles,label,filename):\n",
    "    for entry in smiles:\n",
    "        if type(entry) == list:\n",
    "            unpack_and_write_list(entry,label,filename)\n",
    "        else:\n",
    "            filename.write(entry + \",\" + str(label) + \"\\n\")\n",
    "    \n",
    "def smiles_augmentation(df, N_rounds=1,iteration=5,data_set_type=\"train\"):\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(\"data\")\n",
    "        os.mkdir(\"data/classification\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    filename = \"data/classification/\" + str(data_set_type) + \"_aug_canonical_smiles.csv\"\n",
    "\n",
    "    aug_out = open(filename,\"w\")\n",
    "\n",
    "    aug_out.write(\"Smiles,Label\\n\")\n",
    "        \n",
    "    labels = []\n",
    "    for label in df.groupby('Label'):\n",
    "        labels.append(label[0])\n",
    "    \n",
    "    augmentation_list = []\n",
    "    if type(N_rounds) == list:\n",
    "        assert(len(N_rounds) == len(labels))\n",
    "        augmentation_list = N_rounds\n",
    "    else:\n",
    "        for i in range(len(labels)):\n",
    "            augmentation_list.append(N_rounds)\n",
    "        \n",
    "    for label,augmentation in zip(labels,augmentation_list):\n",
    "    \n",
    "        canonical_smiles = df[df['Label'] == label]['Smiles'].to_list()\n",
    "\n",
    "        p = Pool(Number_of_workers)\n",
    "        func = partial(augment_smiles, augmentation, iteration)\n",
    "        augmented_smiles = list(tqdm.tqdm(p.imap(func, canonical_smiles), total=len(canonical_smiles),leave=False))\n",
    "        p.close()\n",
    "    \n",
    "        print (\"Saving data for label = \" + str(label))\n",
    "\n",
    "        unpack_and_write_list(augmented_smiles,label,filename=aug_out)\n",
    "\n",
    "        unpack_and_write_list(canonical_smiles,label,filename=aug_out)\n",
    "        \n",
    "        print (\"Saved data for label = \" + str(label))\n",
    "        \n",
    "    aug_out.close()\n",
    "    \n",
    "    return (pd.read_csv(filename, header=0).sample(frac=1).reset_index(drop=True))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: (9854, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCCCCCC(CC=CCCCCCCCC(=O)O)O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C(=CC=O)C=C(C(=O)O)N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC1=C(SC=C1)C(=CCCN2CCCC(C2)C(=O)O)C3=C(C=CS3)C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1CN(CC[NH+]1CCO)CCS(=O)(=O)[O-]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC1=C(C=C(C=C1)N=C=O)N=C=O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Smiles  Label\n",
       "0                      CCCCCCC(CC=CCCCCCCCC(=O)O)O      0\n",
       "1                             C(=CC=O)C=C(C(=O)O)N      1\n",
       "2  CC1=C(SC=C1)C(=CCCN2CCCC(C2)C(=O)O)C3=C(C=CS3)C      2\n",
       "3                 C1CN(CC[NH+]1CCO)CCS(=O)(=O)[O-]      1\n",
       "4                       CC1=C(C=C(C=C1)N=C=O)N=C=O      0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if multi_files:\n",
    "    for i,input_filename in enumerate(input_file):\n",
    "        if i != 0:\n",
    "            quantmap_data2 = pd.read_csv(input_filename,sep=\" \",names=[\"Smiles\", \"Label\"]).sample(frac=1).reset_index(drop=True) #,header=None)\n",
    "            quantmap_data = pd.concat([quantmap_data,quantmap_data2])\n",
    "        else:\n",
    "            quantmap_data = pd.read_csv(input_filename,sep=\" \",names=[\"Smiles\", \"Label\"]).sample(frac=1).reset_index(drop=True) #,header=None)\n",
    "    del quantmap_data2\n",
    "else:\n",
    "    quantmap_data = pd.read_csv(input_file,sep=\" \",names=[\"Smiles\", \"Label\"]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "print('Dataset:', quantmap_data.shape)\n",
    "quantmap_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Smiles\n",
      "Label        \n",
      "0        1919\n",
      "1        4662\n",
      "2        2508\n",
      "3         390\n",
      "4         375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Smiles\n",
       "Label        \n",
       "0        1919\n",
       "1        4662\n",
       "2        2508\n",
       "3         390\n",
       "4         375"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (quantmap_data.groupby('Label').count())\n",
    "if not trial:\n",
    "    log_file.write(\"Class distribution before augmentation\\n\")\n",
    "    log_file.write(str(quantmap_data.groupby('Label').count()) + \"\\n\")\n",
    "    \n",
    "quantmap_data.groupby('Label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count_df = quantmap_data.groupby('Label').count()\n",
    "label_count_list = []\n",
    "for entry in range(len(label_count_df)):\n",
    "    label_count_list.append(label_count_df.iloc[entry][0])\n",
    "\n",
    "augmentation_list = []\n",
    "max_value = max(label_count_list)\n",
    "for entry in label_count_list:\n",
    "    augmentation_list.append(int(max_value/entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data for label = 0\n",
      "Saved data for label = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data for label = 1\n",
      "Saved data for label = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data for label = 2\n",
      "Saved data for label = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data for label = 3\n",
      "Saved data for label = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data for label = 4\n",
      "Saved data for label = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "###\n",
    "augmentation_list = [entry*number_of_augmentation for entry in augmentation_list]\n",
    "iteration = 10000\n",
    "# Augmentation for training data\n",
    "quantmap_data = smiles_augmentation(quantmap_data,N_rounds=augmentation_list,iteration=iteration,data_set_type=\"all_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Smiles\n",
      "Label        \n",
      "0        5749\n",
      "1        9323\n",
      "2        5016\n",
      "3        4569\n",
      "4        4680\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Smiles\n",
       "Label        \n",
       "0        5749\n",
       "1        9323\n",
       "2        5016\n",
       "3        4569\n",
       "4        4680"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (quantmap_data.groupby('Label').count())\n",
    "if not trial:\n",
    "    log_file.write(\"number of augmentation = \" + str(number_of_augmentation) + \"\\n\")\n",
    "    log_file.write(\"Class distribution after augmentation\\n\")\n",
    "    log_file.write(str(quantmap_data.groupby('Label').count()) + \"\\n\")\n",
    "    log_file.write(\"Train/valid split ratio = \" + str(train_percentage) + \"\\n\")\n",
    "    \n",
    "quantmap_data.groupby('Label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_label = \"None\" #\"fingerprint\"\n",
    "class MolTokenizer():\n",
    "    def __init__(self, lang = 'en'):\n",
    "        self.lang = lang\n",
    "        \n",
    "    def tokenizer(self, output_label=None,smiles=None):\n",
    "        tokens = atomwise_tokenizer(smiles)\n",
    "        tokens.insert(0, \"<SOS>\") \n",
    "        tokens.append(\"<EOS>\") \n",
    "        if output_label != \"fingerprint\":\n",
    "            return tokens\n",
    "        else:\n",
    "            try:\n",
    "                fingerprint = smiles_fingerprint(smiles,\"morgan\", radius=2,bits=1024)\n",
    "                return tokens,fingerprint\n",
    "            except:\n",
    "                return None,None\n",
    "        \n",
    "    def add_special_cases(self, toks):\n",
    "        pass\n",
    "\n",
    "tok = MolTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make vocabulary\n",
    "\n",
    "def unpack_vocab_list(vocab_list,vocab_unpacked):\n",
    "    for entry in vocab_list:\n",
    "        if type(entry) == list:\n",
    "            unpack_vocab_list(entry,vocab_unpacked)\n",
    "        else:\n",
    "            vocab_unpacked.append(entry)\n",
    "            \n",
    "    return (vocab_unpacked)\n",
    "            \n",
    "def make_vocabulary(input_list):\n",
    "    p = Pool(Number_of_workers)\n",
    "    func = partial(tok.tokenizer, None)\n",
    "    vocab_list = list(tqdm.tqdm(p.imap(func, input_list), total=len(input_list),leave=False))\n",
    "    p.close()\n",
    "    vocab_unpacked = []\n",
    "    return (list(set(unpack_vocab_list(vocab_list,vocab_unpacked))))\n",
    "\n",
    "def make_word_index(vocab):\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "    for i,entry in enumerate(vocab):\n",
    "        word_index[entry] = i\n",
    "        index_word[i] = entry\n",
    "    return (word_index,index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_vocab_file = True\n",
    "\n",
    "if use_vocab_file:\n",
    "    en_vocab = open(\"en_vocab_.txt\",\"r\").read().strip(\"[]\").replace(\"'\", \"\").replace(\" \", \"\").split(\",\")\n",
    "    en_word_index,en_index_word = make_word_index(en_vocab)\n",
    "    \n",
    "else:\n",
    "    all_smiles = quantmap_data[\"Smiles\"].to_list()\n",
    "\n",
    "    en_vocab = [\"<PAD>\",\"<UNK>\"]\n",
    "    en_vocab.extend(make_vocabulary(all_smiles))\n",
    "    del all_smiles\n",
    "\n",
    "    ###\n",
    "    en_word_index,en_index_word = make_word_index(en_vocab)\n",
    "\n",
    "    vocab_output = open(\"en_vocab_.txt\",\"w\")\n",
    "    vocab_output.write(str(en_vocab))\n",
    "    vocab_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/anaconda3/envs/molpmofit/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "/home/jovyan/anaconda3/envs/molpmofit/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Smiles\n",
       "Label        \n",
       "0        4569\n",
       "1        4680"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing unbalanced data and shuffling\n",
    "balanced_data = quantmap_data [quantmap_data.Label != 0][quantmap_data.Label != 1][quantmap_data.Label != 2]\n",
    "balanced_data = balanced_data.sample(frac=1).reset_index(drop=True)\n",
    "balanced_data[\"Label\"].replace({3: 0,4:1}, inplace=True)\n",
    "balanced_data.groupby('Label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not trial:\n",
    "    log_file.write(\"Class distribution after balanced dataset\\n\")\n",
    "    log_file.write(str(balanced_data.groupby('Label').count()) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count_list = np.array([entry for entry in balanced_data.groupby('Label').count()[\"Smiles\"]])\n",
    "class_weight = np.max(class_count_list)/class_count_list\n",
    "class_weight = torch.FloatTensor(class_weight).cuda()\n",
    "\n",
    "if not trial:\n",
    "    log_file.write(\"Class weight for loss (balancing weights)= \" + str(class_weight) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_smiles_to_tokens(df):\n",
    "    \n",
    "    if output_label != \"fingerprint\": # Maintain the y from the data as label\n",
    "        labels = []\n",
    "        for label in df.groupby('Label'):\n",
    "            labels.append(label[0])\n",
    "            \n",
    "        x = []\n",
    "        y = []\n",
    "        p = Pool(Number_of_workers)\n",
    "        for label in labels:\n",
    "            smiles_list = df[df['Label'] == label]['Smiles'].to_list()\n",
    "            \n",
    "            \n",
    "            func = partial(tok.tokenizer, None)\n",
    "            tokens = list(tqdm.tqdm(p.imap(func, smiles_list), total=len(smiles_list),leave=False))\n",
    "            \n",
    "            #p = Pool(Number_of_workers)\n",
    "            #tokens = list(tqdm.tqdm(p.imap(tok.tokenizer, smiles_list), total=len(smiles_list),leave=False))\n",
    "            #p.close()\n",
    "            #if len(tokens) < 100:\n",
    "            for entry in tokens:\n",
    "                if  5 < len(entry) <= 150:\n",
    "                #break\n",
    "                    x.append(entry)\n",
    "                    y.append(label)\n",
    "            #x.extend(tokens)\n",
    "            #y.extend([label for i in range(len(tokens))])\n",
    "        p.close()\n",
    "            \n",
    "    else: # Return fingerprint as label for each object\n",
    "        x = []\n",
    "        y = []\n",
    "        smiles_list = df['Smiles'].to_list()\n",
    "        \n",
    "        func = partial(tok.tokenizer, output_label)\n",
    "        \n",
    "        for entry in smiles_list:\n",
    "            xout,yout = (func(entry))\n",
    "            if xout != None:\n",
    "                x.append(xout)\n",
    "                y.append([int(entry) for entry in yout])\n",
    "        \n",
    "        print (str(len(smiles_list)-len(x)) + \" incorrect smiles detected and deleted\"  )\n",
    "        \n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    }
   ],
   "source": [
    "x,y= convert_smiles_to_tokens(balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenthwise_x = [len(entry) for entry in x if len(entry)]\n",
    "if not trial:\n",
    "    log_file.write(\"Data point with (5 < len(sequence) <= 150) = \" + str(len(lenthwise_x)) +\"/\"+ str(sum(class_count_list)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(lenthwise_x, density=True, bins=30)  # density=False would make counts\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Data');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_token_to_index(molecule):\n",
    "    idxs = []\n",
    "    for ch in molecule:\n",
    "        if ch in en_word_index:\n",
    "            idxs.append(en_word_index[ch])\n",
    "        else:\n",
    "            idxs.append(en_word_index[\"<UNK>\"])\n",
    "    return torch.tensor(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    }
   ],
   "source": [
    "x_indexed_token = []\n",
    "loop = tqdm.tqdm(x, total=len(x),leave=False)\n",
    "for entry in loop:\n",
    "    x_indexed_token.append(convert_token_to_index(entry))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_test_percentage = (1 - train_percentage)/2\n",
    "\n",
    "data_to_use = balanced_data\n",
    "# Ratios\n",
    "train_ratio = int (len(data_to_use) * train_percentage)\n",
    "valid_ratio = train_ratio + int(len(data_to_use)*valid_test_percentage)\n",
    "test_ratio = valid_ratio + int(len(data_to_use)*valid_test_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make index to split into train and val set\n",
    "def make_index(len_data,train_ratio,valid_ratio,test_ratio):\n",
    "    \n",
    "    index = np.random.permutation(len_data)\n",
    "    \n",
    "    # Train index and val index\n",
    "    return (index[:train_ratio],index[train_ratio:valid_ratio],index[valid_ratio:test_ratio])\n",
    "\n",
    "train_index ,valid_index,test_index = make_index(len(data_to_use),train_ratio,valid_ratio,test_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders by padding the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_padded = pad_sequence(x_indexed_token,batch_first=True, padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, TensorDataset, SubsetRandomSampler\n",
    "\n",
    "train_sample = SubsetRandomSampler(train_index)\n",
    "valid_sample = SubsetRandomSampler(valid_index)\n",
    "test_sample = SubsetRandomSampler(test_index)\n",
    "batch_size = 512\n",
    "\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(x_padded,torch.tensor(y))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                        sampler=train_sample)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                        sampler=valid_sample)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                        sampler=test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data without padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(data):\n",
    "    \n",
    "    index = np.random.permutation(len(data))\n",
    "    \n",
    "    output_shuffled = []\n",
    "    for i in index:\n",
    "        output_shuffled.append(data[i])\n",
    "        \n",
    "    return (output_shuffled)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = shuffle_data([(entry,y[i]) for i,entry in enumerate(x_indexed_token) if i in train_index])\n",
    "valid_data = shuffle_data([(entry,y[i]) for i,entry in enumerate(x_indexed_token) if i in valid_index])\n",
    "test_data = shuffle_data([(entry,y[i]) for i,entry in enumerate(x_indexed_token) if i in test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset class for loading data.\n",
    "      This is where the data parsing happens.\n",
    "      This class is built with reusability in mind.\n",
    "      Arguments:\n",
    "      path (:obj:`str`):\n",
    "      Path to the data partition.\n",
    "      \"\"\"\n",
    "    \n",
    "    def __init__(self, data_tuple):\n",
    "\n",
    "        # Check if path exists.\n",
    "        #if not os.path.isdir(path):\n",
    "          # Raise error if path is invalid.\n",
    "          #raise ValueError('Invalid `path` variable! Needs to be a directory')\n",
    "    \n",
    "        self.texts = []\n",
    "        self.labels = []\n",
    "        # Since the labels are defined by folders with data we loop \n",
    "        # through each label.\n",
    "        '''for label  in ['pos', 'neg']:\n",
    "            sentiment_path = os.path.join(path, label)\n",
    "\n",
    "            # Get all files from path.\n",
    "            files_names = os.listdir(sentiment_path)#[:10] # Sample for debugging.\n",
    "            # Go through each file and read its content.\n",
    "            for file_name in tqdm(files_names, desc=f'{label} Files'):\n",
    "                file_path = os.path.join(sentiment_path, file_name)\n",
    "\n",
    "                # Read content.\n",
    "                content = io.open(file_path, mode='r', encoding='utf-8').read()\n",
    "                # Fix any unicode issues.\n",
    "                content = fix_text(content)\n",
    "                # Save content.\n",
    "                self.texts.append(content)\n",
    "                # Save labels.\n",
    "                self.labels.append(label)'''\n",
    "        for entry in data_tuple:\n",
    "            self.texts.append(entry[0])\n",
    "            self.labels.append(entry[1])\n",
    "        # Number of examples.\n",
    "        self.n_examples = len(self.labels)\n",
    "        return\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"When used `len` return the number of examples.\"\"\"\n",
    "        return self.n_examples\n",
    "\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \"\"\"Given an index return an example from the position.\n",
    "        Arguments:\n",
    "          item (:obj:`int`):\n",
    "              Index position to pick an example to return.\n",
    "        Returns:\n",
    "          :obj:`Dict[str, str]`: Dictionary of inputs that are used to feed \n",
    "          to a model.\n",
    "        \"\"\"\n",
    "        return {'text':self.texts[item], 'label':self.labels[item]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MakeDataset(train_data)\n",
    "valid_dataset = MakeDataset(valid_data)\n",
    "test_dataset = MakeDataset(test_data)\n",
    "\n",
    "from torchtext import data\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_iterator = data.BucketIterator(\n",
    "    train_dataset,\n",
    "    sort = False,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x['text']),\n",
    "    batch_size = batch_size,\n",
    "    device = device)\n",
    "\n",
    "valid_iterator = data.BucketIterator(\n",
    "    valid_dataset,\n",
    "    sort = False,\n",
    "    shuffle=True,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x['text']),\n",
    "    batch_size = batch_size,\n",
    "    device = device)\n",
    "\n",
    "test_iterator = data.BucketIterator(\n",
    "    test_dataset,\n",
    "    sort = False,\n",
    "    shuffle=True,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x['text']),\n",
    "    batch_size = batch_size,\n",
    "    device = device)\n",
    "\n",
    "if not trial:\n",
    "    log_file.write(\"Batch size = \" + str(batch_size) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size) #,padding_idx=0)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p,batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (N,seq_length) where N is batch size\n",
    "        \n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (N,seq_length, embedding_size)\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (N,seq_length, hidden_size)\n",
    "        \n",
    "        #cat = torch.cat(hidden[0],hidden[1],hidden[2],dim=2)\n",
    "        #print (hidden.view(1,-1).shape)\n",
    "        #print (hidden[2].shape)\n",
    "        return hidden[2]\n",
    "        #return hidden.view(-1,hidden[2].shape[1]*3)\n",
    "\n",
    "\n",
    "class FC_layer(nn.Module):\n",
    "    def __init__(\n",
    "        self, hidden_size, output_size,p):\n",
    "        super(FC_layer, self).__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size, 1024)\n",
    "        #self.bn1 = nn.BatchNorm1d(1024)\n",
    "        \n",
    "        #self.fc2 = nn.Linear(1024, 512)\n",
    "        #self.bn2 = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.fc3 = nn.Linear(1024, output_size)\n",
    "\n",
    "    def forward(self, hidden):\n",
    "        fc_out = self.relu(self.dropout(self.fc1(hidden)))\n",
    "        #fc_out = self.relu(self.dropout(self.fc2(fc_out)))\n",
    "        #fc_out = self.dropout(self.fc2(fc_out))\n",
    "        fc_out = self.fc3(fc_out)\n",
    "        \n",
    "        return fc_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs to be the same for both RNN's\n",
    "hidden_size = 1024  \n",
    "num_layers = 3\n",
    "\n",
    "\n",
    "\n",
    "input_size_encoder = len(en_vocab)\n",
    "en_embedding_size = 400\n",
    "en_dropout = 0.4\n",
    "\n",
    "encoder_net = Encoder(\n",
    "    input_size_encoder, \n",
    "    en_embedding_size, \n",
    "    hidden_size, \n",
    "    num_layers, \n",
    "    en_dropout).to(device)\n",
    "\n",
    "de_dropout = 0.4\n",
    "\n",
    "output_size = len(set(y))\n",
    "\n",
    "FC_layer = FC_layer(hidden_size, \n",
    "                   output_size,\n",
    "                   de_dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, FC_layer):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.FC_layer = FC_layer\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[0]\n",
    "\n",
    "        hidden = self.encoder(source)\n",
    "        outputs = self.FC_layer(hidden)\n",
    "        \n",
    "        #outputs = self.softmax(outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "# Training hyperparameters\n",
    "#epochs = 10\n",
    "#learning_rate = 0.00005\n",
    "\n",
    "model = Seq2Seq(encoder_net, FC_layer).to(device)\n",
    "model.load_state_dict(torch.load(\"test_model.pth\"), strict=False)\n",
    "model.to(device)\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched = False\n",
    "\n",
    "def validate(val_dl):\n",
    "    model.eval()\n",
    "    total_loss = []\n",
    "    accuracy = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        val_dl.create_batches()\n",
    "        loop = tqdm.tqdm(enumerate(val_dl.batches), total=len(val_dl),leave=False)\n",
    "        for i,batch in loop:\n",
    "            batch_text = [example[\"text\"] for example in batch]\n",
    "            batch_label = torch.tensor([example[\"label\"] for example in batch])\n",
    "            x_padded = pad_sequence(batch_text,batch_first=True, padding_value=0)\n",
    "            xvalc = x_padded.to(device)\n",
    "            yvalc = batch_label.to(device)\n",
    "            \n",
    "            '''loop = tqdm.tqdm(enumerate(val_dl), total=len(val_dl),leave=False)\n",
    "            for i, (xval,yval) in loop:\n",
    "            xval = xval.view(1,-1)\n",
    "            yval = yval.view(1,-1)\n",
    "            xvalc = xval.to(device)\n",
    "            yvalc = yval.to(device)'''\n",
    "\n",
    "            # Forward prop\n",
    "            output_val = model(xvalc.long(),yvalc)\n",
    "\n",
    "            #print (output_train.shape,ybc.shape)\n",
    "\n",
    "            accuracy.append(get_accuracy(output_val,yvalc))\n",
    "\n",
    "            loss_val = criterion(output_val, yvalc)\n",
    "            #loss_val = criterion(output_val, yvalc)\n",
    "\n",
    "            total_loss.append(loss_val.item())\n",
    "            \n",
    "            loop.set_postfix(loss = sum(total_loss)/(i+1),acc = sum(accuracy)/(len(accuracy)))\n",
    "    return (sum(total_loss)/(i+1),sum(accuracy)/(len(accuracy)))\n",
    "    \n",
    "def train(train_dl):\n",
    "    model.train()\n",
    "    total_loss = []\n",
    "    accuracy = []\n",
    "    \n",
    "    \n",
    "    train_dl.create_batches()\n",
    "    loop = tqdm.tqdm(enumerate(train_dl.batches), total=len(train_dl),leave=False)\n",
    "    \n",
    "    for i,batch in loop:\n",
    "        batch_text = [example[\"text\"] for example in batch]\n",
    "        batch_label = torch.tensor([example[\"label\"] for example in batch])\n",
    "        \n",
    "        x_padded = pad_sequence(batch_text,batch_first=True, padding_value=0)\n",
    "        \n",
    "        xbc = x_padded.to(device)\n",
    "        ybc = batch_label.to(device)\n",
    "        \n",
    "        '''loop = tqdm.tqdm(enumerate(train_dl), total=len(train_dl),leave=False)\n",
    "        for i, (xb,yb) in loop:\n",
    "    \n",
    "        xb = xb.view(1,-1)\n",
    "        yb = yb.view(1,-1)\n",
    "        xbc = xb.to(device)\n",
    "        ybc = yb.to(device)'''\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward prop\n",
    "        output_train = model(xbc.long(),ybc)\n",
    "\n",
    "        accuracy.append(get_accuracy(output_train,ybc))\n",
    "        \n",
    "        \n",
    "        loss_train = criterion(output_train, ybc)\n",
    "        \n",
    "        # Back prop\n",
    "        loss_train.backward()\n",
    "        \n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss.append(loss_train.item())\n",
    "        loop.set_postfix(loss = sum(total_loss)/(i+1),acc = sum(accuracy)/(len(accuracy)))\n",
    "        #if i % 1000 == 0:\n",
    "        #    print (\"Batch \" + str(i) + \" train loss = \" + str(sum(total_loss)/(i+1)) )\n",
    "\n",
    "        gc.collect()\n",
    "    return (sum(total_loss)/(i+1),sum(accuracy)/(len(accuracy)))\n",
    "\n",
    "\n",
    "def get_accuracy(yhat,y): #  FOR BCE ERROR\n",
    "    \n",
    "    if batched:\n",
    "        batch_accuracy = []\n",
    "        for batch in range(yhat.shape[0]):\n",
    "            accuracy_list = []\n",
    "            \n",
    "            for i,entry in enumerate(yhat[batch]):\n",
    "                softmax = torch.exp(entry.float())\n",
    "                prob = list(softmax.cpu().detach().numpy())\n",
    "                predictions = np.argmax(prob, axis=0)\n",
    "                accuracy_list.append(np.argmax(y[batch][i].cpu().detach().numpy(), axis=0) == predictions != 0)\n",
    "            batch_accuracy.append((np.sum(np.array(accuracy_list))*1.0)/len(accuracy_list))\n",
    "            \n",
    "        return np.sum(batch_accuracy)/len(batch_accuracy)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        accuracy_list = []\n",
    "        #print (yhat.shape[0])\n",
    "        for i,entry in enumerate(yhat):\n",
    "            #if y[i].cpu().detach().numpy() != 0:\n",
    "                #print (entry.shape)\n",
    "            softmax = torch.exp(entry.float())\n",
    "            prob = list(softmax.cpu().detach().numpy())\n",
    "            predictions = np.argmax(prob, axis=0)\n",
    "                #if random.random() > 0.99:\n",
    "                #    print (predictions,y[i],y[i].cpu().detach().numpy())\n",
    "            #print (yhat,predictions,y[i].cpu().detach().numpy())\n",
    "            accuracy_list.append(y[i].cpu().detach().numpy() == predictions)\n",
    "            \n",
    "        return (np.sum(np.array(accuracy_list))*1.0)/len(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Seq2Seq(\n",
       "   (encoder): Encoder(\n",
       "     (dropout): Dropout(p=0.4, inplace=False)\n",
       "     (embedding): Embedding(153, 400)\n",
       "     (rnn): LSTM(400, 1024, num_layers=3, batch_first=True, dropout=0.4)\n",
       "   )\n",
       "   (FC_layer): FC_layer(\n",
       "     (dropout): Dropout(p=0.4, inplace=False)\n",
       "     (relu): ReLU()\n",
       "     (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "     (fc3): Linear(in_features=1024, out_features=2, bias=True)\n",
       "   )\n",
       "   (softmax): Softmax(dim=None)\n",
       " ),\n",
       " odict_keys(['encoder.embedding.weight', 'encoder.rnn.weight_ih_l0', 'encoder.rnn.weight_hh_l0', 'encoder.rnn.bias_ih_l0', 'encoder.rnn.bias_hh_l0', 'encoder.rnn.weight_ih_l1', 'encoder.rnn.weight_hh_l1', 'encoder.rnn.bias_ih_l1', 'encoder.rnn.bias_hh_l1', 'encoder.rnn.weight_ih_l2', 'encoder.rnn.weight_hh_l2', 'encoder.rnn.bias_ih_l2', 'encoder.rnn.bias_hh_l2', 'FC_layer.fc1.weight', 'FC_layer.fc1.bias', 'FC_layer.fc3.weight', 'FC_layer.fc3.bias']))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = model.state_dict()\n",
    "model,params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing layers except FC\n",
    "model.encoder.embedding.weight.requires_grad = False\n",
    "\n",
    "'''\n",
    "lstm_list = [model.encoder.rnn.parameters()]\n",
    "\n",
    "for entry in lstm_list:\n",
    "    for param in entry:\n",
    "        param.requires_grad = False'''\n",
    "\n",
    "model.encoder.rnn.bias_hh_l2.requires_grad = False\n",
    "model.encoder.rnn.bias_ih_l2.requires_grad = False\n",
    "model.encoder.rnn.weight_hh_l2.requires_grad = False\n",
    "model.encoder.rnn.weight_ih_l2.requires_grad = False\n",
    "\n",
    "model.encoder.rnn.bias_hh_l1.requires_grad = False\n",
    "model.encoder.rnn.bias_ih_l1.requires_grad = False\n",
    "model.encoder.rnn.weight_hh_l1.requires_grad = False\n",
    "model.encoder.rnn.weight_ih_l1.requires_grad = False\n",
    "\n",
    "model.encoder.rnn.bias_hh_l0.requires_grad = False\n",
    "model.encoder.rnn.bias_ih_l0.requires_grad = False\n",
    "model.encoder.rnn.weight_hh_l0.requires_grad = False\n",
    "model.encoder.rnn.weight_ih_l0.requires_grad = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store values\n",
    "train_loss_list = []\n",
    "train_accu_list = []\n",
    "val_loss_list = []\n",
    "val_accu_list = []\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:04,  8.03it/s, acc=0.719, loss=0.617]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 \t LOSS train: 0.677619184152438  val: 0.6610576695409315 \tACCU train: 0.5755791083916084  val: 0.5754310344827587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/520 [00:00<01:16,  6.78it/s, acc=0.812, loss=0.588]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 \t LOSS train: 0.6673664428866827  val: 0.6468578762021558 \tACCU train: 0.5885489510489511  val: 0.6170977011494252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<00:56,  9.19it/s, acc=0.562, loss=0.682]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 \t LOSS train: 0.6622495639209564  val: 0.6411881200198469 \tACCU train: 0.5996066433566434  val: 0.6106321839080461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/520 [00:00<00:56,  9.15it/s, acc=0.75, loss=0.572]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4 \t LOSS train: 0.6590420904067846  val: 0.6333003784048146 \tACCU train: 0.6049497377622377  val: 0.6278735632183909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5 \t LOSS train: 0.6574995993421628  val: 0.6385497882448393 \tACCU train: 0.6058457167832169  val: 0.6149425287356322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "#loop = tqdm.tqdm(range(epochs), total=epochs,leave=False)\n",
    "epochs = 5\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate,weight_decay=1e-4)\n",
    "\n",
    "if not trial:\n",
    "    log_file.write(\"model = \" + str(model) + \"\\n\")\n",
    "    log_file.write(\"\\nEmbedding layer and LSTM frozen\\n\")\n",
    "    log_file.write(\"learning_rate = \" + str(learning_rate) + \"\\n\")\n",
    "    log_file.write(\"epochs = \" + str(epochs) + \"\\n\")\n",
    "    log_file.write(\"Epoch\\tLOSStrain\\tLOSSval\\tACCUtrain\\tACCUval\\n\") \n",
    "    \n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #print (\"EPOCH \" + str(epoch))\n",
    "    \n",
    "    train_loss, train_accu = train(train_iterator)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accu_list.append(train_accu)\n",
    "    \n",
    "    val_loss,val_accu = validate(valid_iterator)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_accu_list.append(val_accu)\n",
    "    \n",
    "    if not trial:\n",
    "        log_file.write(str(epoch+1) + \"\\t\" + str(train_loss) + \"\\t\" + str(val_loss) + \"\\t\" + str(train_accu) + \"\\t\" + str(val_accu)  + \"\\n\")\n",
    "        torch.save(model.state_dict(), \"pretrained_model_epoch\" + str(epoch) + \".pth\")\n",
    "    print (\"Epoch :\",epoch+1,\"\\t\",\"LOSS train:\",train_loss,\" val:\",val_loss, \"\\tACCU train:\",train_accu,\" val:\",val_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing layers except FC and lstm last layer\n",
    "model.encoder.rnn.bias_hh_l2.requires_grad = True\n",
    "model.encoder.rnn.bias_ih_l2.requires_grad = True\n",
    "model.encoder.rnn.weight_hh_l2.requires_grad = True\n",
    "model.encoder.rnn.weight_ih_l2.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/520 [00:00<00:57,  9.01it/s, acc=0.562, loss=0.717]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 \t LOSS train: 0.6514123562436838  val: 0.6336196486292214 \tACCU train: 0.6118662587412588  val: 0.6214080459770115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/520 [00:00<01:12,  7.10it/s, acc=0.656, loss=0.651]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 \t LOSS train: 0.6470954046799586  val: 0.6216289041371181 \tACCU train: 0.618597027972028  val: 0.6472701149425287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 \t LOSS train: 0.63937422604515  val: 0.6210185864876057 \tACCU train: 0.6298186188811189  val: 0.6515804597701149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "#loop = tqdm.tqdm(range(epochs), total=epochs,leave=False)\n",
    "epochs = 3\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate,weight_decay=1e-4)\n",
    "\n",
    "if not trial:\n",
    "    log_file.write(\"\\nEmbedding layer and LSTM frozen (except last layer)\\n\")\n",
    "    log_file.write(\"learning_rate = \" + str(learning_rate) + \"\\n\")\n",
    "    log_file.write(\"epochs = \" + str(epochs) + \"\\n\")\n",
    "    log_file.write(\"Epoch\\tLOSStrain\\tLOSSval\\tACCUtrain\\tACCUval\\n\") \n",
    "    \n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #print (\"EPOCH \" + str(epoch))\n",
    "    \n",
    "    train_loss, train_accu = train(train_iterator)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accu_list.append(train_accu)\n",
    "    \n",
    "    val_loss,val_accu = validate(valid_iterator)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_accu_list.append(val_accu)\n",
    "    \n",
    "    if not trial:\n",
    "        log_file.write(str(epoch+1) + \"\\t\" + str(train_loss) + \"\\t\" + str(val_loss) + \"\\t\" + str(train_accu) + \"\\t\" + str(val_accu)  + \"\\n\")\n",
    "        torch.save(model.state_dict(), \"pretrained_model_epoch\" + str(epoch) + \".pth\")\n",
    "    print (\"Epoch :\",epoch+1,\"\\t\",\"LOSS train:\",train_loss,\" val:\",val_loss, \"\\tACCU train:\",train_accu,\" val:\",val_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing layers except FC and lstm last layer\n",
    "model.encoder.rnn.bias_hh_l1.requires_grad = True\n",
    "model.encoder.rnn.bias_ih_l1.requires_grad = True\n",
    "model.encoder.rnn.weight_hh_l1.requires_grad = True\n",
    "model.encoder.rnn.weight_ih_l1.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:19,  6.51it/s, acc=0.438, loss=0.729]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 \t LOSS train: 0.6263489783383333  val: 0.613587171866976 \tACCU train: 0.6433020104895104  val: 0.6688218390804599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:07,  7.66it/s, acc=0.719, loss=0.598]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 \t LOSS train: 0.6162190901545378  val: 0.6124323555107775 \tACCU train: 0.6508631993006992  val: 0.6681034482758621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 \t LOSS train: 0.6040388411627367  val: 0.5890353784478944 \tACCU train: 0.6668487762237763  val: 0.6989942528735633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "#loop = tqdm.tqdm(range(epochs), total=epochs,leave=False)\n",
    "epochs = 3\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate,weight_decay=1e-4)\n",
    "\n",
    "if not trial:\n",
    "    log_file.write(\"\\nEmbedding layer and LSTM frozen (except last two layers)\\n\")\n",
    "    log_file.write(\"learning_rate = \" + str(learning_rate) + \"\\n\")\n",
    "    log_file.write(\"epochs = \" + str(epochs) + \"\\n\")\n",
    "    log_file.write(\"Epoch\\tLOSStrain\\tLOSSval\\tACCUtrain\\tACCUval\\n\") \n",
    "    \n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #print (\"EPOCH \" + str(epoch))\n",
    "    \n",
    "    train_loss, train_accu = train(train_iterator)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accu_list.append(train_accu)\n",
    "    \n",
    "    val_loss,val_accu = validate(valid_iterator)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_accu_list.append(val_accu)\n",
    "    \n",
    "    if not trial:\n",
    "        log_file.write(str(epoch+1) + \"\\t\" + str(train_loss) + \"\\t\" + str(val_loss) + \"\\t\" + str(train_accu) + \"\\t\" + str(val_accu)  + \"\\n\")\n",
    "        torch.save(model.state_dict(), \"pretrained_model_epoch\" + str(epoch) + \".pth\")\n",
    "    print (\"Epoch :\",epoch+1,\"\\t\",\"LOSS train:\",train_loss,\" val:\",val_loss, \"\\tACCU train:\",train_accu,\" val:\",val_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing layers except FC and lstm last layer\n",
    "model.encoder.rnn.bias_hh_l0.requires_grad = True\n",
    "model.encoder.rnn.bias_ih_l0.requires_grad = True\n",
    "model.encoder.rnn.weight_hh_l0.requires_grad = True\n",
    "model.encoder.rnn.weight_ih_l0.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:23,  6.20it/s, acc=0.75, loss=0.606]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 \t LOSS train: 0.6374462656103648  val: 0.5932341690721183 \tACCU train: 0.6386145104895105  val: 0.6774425287356322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:14,  6.97it/s, acc=0.562, loss=0.656]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 \t LOSS train: 0.6000019593880727  val: 0.528925743082474 \tACCU train: 0.6755572552447553  val: 0.7262931034482759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:03,  8.13it/s, acc=0.812, loss=0.569]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 \t LOSS train: 0.5920068011260949  val: 0.5850647307675461 \tACCU train: 0.6833697552447553  val: 0.6889367816091954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:10,  7.33it/s, acc=0.875, loss=0.478]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4 \t LOSS train: 0.5678613154934002  val: 0.5203346147619444 \tACCU train: 0.7023710664335665  val: 0.7550287356321839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:20,  6.45it/s, acc=0.875, loss=0.457]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5 \t LOSS train: 0.5578434590536815  val: 0.5215047012115347 \tACCU train: 0.7087194055944056  val: 0.7370689655172413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:05,  7.92it/s, acc=0.812, loss=0.568]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6 \t LOSS train: 0.5483577998498311  val: 0.5539858341217041 \tACCU train: 0.7137784090909092  val: 0.723419540229885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:24,  6.16it/s, acc=0.875, loss=0.42]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7 \t LOSS train: 0.5387556134508207  val: 0.5048558187895807 \tACCU train: 0.7223666958041958  val: 0.7521551724137931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:15,  6.91it/s, acc=0.875, loss=0.381]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8 \t LOSS train: 0.5241187972231554  val: 0.5147424946571219 \tACCU train: 0.7271743881118881  val: 0.7248563218390806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:04,  8.08it/s, acc=0.844, loss=0.357]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9 \t LOSS train: 0.5189967742906167  val: 0.506795659661293 \tACCU train: 0.7284418706293707  val: 0.7420977011494254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:33,  5.56it/s, acc=0.688, loss=0.598]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10 \t LOSS train: 0.5146350994992714  val: 0.4905610891251728 \tACCU train: 0.7340799825174825  val: 0.7528735632183907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/520 [00:00<?, ?it/s, acc=0.688, loss=0.629]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 11 \t LOSS train: 0.5048244185745716  val: 0.48801088744196397 \tACCU train: 0.7432255244755245  val: 0.7636494252873564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:10,  7.37it/s, acc=0.875, loss=0.409]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 12 \t LOSS train: 0.506979607231915  val: 0.4734951699602193 \tACCU train: 0.7364947552447553  val: 0.7629310344827587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/520 [00:00<01:17,  6.65it/s, acc=0.688, loss=0.596]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 13 \t LOSS train: 0.48866608346310947  val: 0.4610421184835763 \tACCU train: 0.7554851398601399  val: 0.7679597701149427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:10,  7.33it/s, acc=0.875, loss=0.323]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 14 \t LOSS train: 0.47728865009087784  val: 0.45295621660248986 \tACCU train: 0.7598666958041957  val: 0.7636494252873562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/520 [00:00<01:13,  7.02it/s, acc=0.844, loss=0.389]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 15 \t LOSS train: 0.47171982747430985  val: 0.442360182774478 \tACCU train: 0.7637237762237762  val: 0.7744252873563218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/520 [00:00<01:14,  6.93it/s, acc=0.75, loss=0.464]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 16 \t LOSS train: 0.4534945137798786  val: 0.42988265074532606 \tACCU train: 0.7744208916083916  val: 0.7658045977011494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:10,  7.40it/s, acc=0.688, loss=0.517]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 17 \t LOSS train: 0.4468595835022055  val: 0.4247615548043415 \tACCU train: 0.7786166958041958  val: 0.7679597701149425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/520 [00:00<01:09,  7.48it/s, acc=0.719, loss=0.544]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 18 \t LOSS train: 0.44231504421824447  val: 0.43458142568325175 \tACCU train: 0.7779611013986014  val: 0.7816091954022989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:15,  6.87it/s, acc=0.938, loss=0.394]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 19 \t LOSS train: 0.43064362610905216  val: 0.4573107485113473 \tACCU train: 0.7804960664335665  val: 0.7866379310344828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 20 \t LOSS train: 0.42320901341736317  val: 0.4289981995163293 \tACCU train: 0.7886691433566434  val: 0.7880747126436781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "#loop = tqdm.tqdm(range(epochs), total=epochs,leave=False)\n",
    "epochs = 20\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate,weight_decay=1e-4)\n",
    "\n",
    "if not trial:\n",
    "    log_file.write(\"\\nOnly embedding layer frozen\\n\")\n",
    "    log_file.write(\"learning_rate = \" + str(learning_rate) + \"\\n\")\n",
    "    log_file.write(\"epochs = \" + str(epochs) + \"\\n\")\n",
    "    log_file.write(\"Epoch\\tLOSStrain\\tLOSSval\\tACCUtrain\\tACCUval\\n\") \n",
    "    \n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #print (\"EPOCH \" + str(epoch))\n",
    "    \n",
    "    train_loss, train_accu = train(train_iterator)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accu_list.append(train_accu)\n",
    "    \n",
    "    val_loss,val_accu = validate(valid_iterator)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_accu_list.append(val_accu)\n",
    "    \n",
    "    if not trial:\n",
    "        log_file.write(str(epoch+1) + \"\\t\" + str(train_loss) + \"\\t\" + str(val_loss) + \"\\t\" + str(train_accu) + \"\\t\" + str(val_accu)  + \"\\n\")\n",
    "        torch.save(model.state_dict(), \"pretrained_model_epoch\" + str(epoch) + \".pth\")\n",
    "    print (\"Epoch :\",epoch+1,\"\\t\",\"LOSS train:\",train_loss,\" val:\",val_loss, \"\\tACCU train:\",train_accu,\" val:\",val_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:23,  6.21it/s, acc=0.812, loss=0.253]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 \t LOSS train: 0.31512501918209285  val: 0.39088885614584234 \tACCU train: 0.8366258741258742  val: 0.8204022988505748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<00:59,  8.72it/s, acc=0.781, loss=0.314]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 \t LOSS train: 0.31563146561384203  val: 0.4061099624839322 \tACCU train: 0.8390187937062937  val: 0.7880747126436782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:09,  7.48it/s, acc=1, loss=0.179]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 \t LOSS train: 0.3186023582525265  val: 0.3982318259518722 \tACCU train: 0.8333697552447553  val: 0.7801724137931034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:27,  5.91it/s, acc=0.938, loss=0.272]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4 \t LOSS train: 0.3168234354458176  val: 0.36420507305141153 \tACCU train: 0.8393793706293706  val: 0.8211206896551724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/520 [00:00<?, ?it/s, acc=0.75, loss=0.331]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5 \t LOSS train: 0.32459930955217436  val: 0.41633708980576745 \tACCU train: 0.8311953671328672  val: 0.790948275862069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:40,  5.15it/s, acc=0.875, loss=0.295]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6 \t LOSS train: 0.3162833709341402  val: 0.3963014379400632 \tACCU train: 0.838472465034965  val: 0.790948275862069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:28,  5.85it/s, acc=0.938, loss=0.139]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7 \t LOSS train: 0.314437922551028  val: 0.4128953629526599 \tACCU train: 0.8379370629370629  val: 0.790948275862069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:32,  5.62it/s, acc=1, loss=0.135]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8 \t LOSS train: 0.31117537273944784  val: 0.4059164996804862 \tACCU train: 0.8394886363636365  val: 0.790948275862069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:27,  5.90it/s, acc=0.938, loss=0.181]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9 \t LOSS train: 0.31407110521999687  val: 0.3952156058673201 \tACCU train: 0.8374453671328672  val: 0.7902298850574713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:35,  5.41it/s, acc=0.875, loss=0.273]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10 \t LOSS train: 0.30603140079452157  val: 0.4130141020848833 \tACCU train: 0.8438811188811188  val: 0.8117816091954022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:25,  6.08it/s, acc=0.625, loss=0.427]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 11 \t LOSS train: 0.30653475317029427  val: 0.3791852332651615 \tACCU train: 0.8419580419580419  val: 0.807471264367816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:24,  6.12it/s, acc=0.938, loss=0.097]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 12 \t LOSS train: 0.3178971120514549  val: 0.40543072876231423 \tACCU train: 0.8346263111888111  val: 0.7945402298850575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:54,  4.51it/s, acc=0.938, loss=0.227]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 13 \t LOSS train: 0.3152752238791436  val: 0.41142597023783056 \tACCU train: 0.8358937937062938  val: 0.7816091954022988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:26,  5.98it/s, acc=1, loss=0.00706]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 14 \t LOSS train: 0.3084281558887317  val: 0.4126210957765579 \tACCU train: 0.8338505244755245  val: 0.8017241379310345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:26,  5.99it/s, acc=0.812, loss=0.437]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 15 \t LOSS train: 0.31350152152411354  val: 0.3920144120167042 \tACCU train: 0.8387784090909092  val: 0.817528735632184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/520 [00:00<01:03,  8.21it/s, acc=0.938, loss=0.247]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 16 \t LOSS train: 0.30869038878725125  val: 0.44184485630228604 \tACCU train: 0.8400240384615385  val: 0.80316091954023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:19,  6.54it/s, acc=0.688, loss=1.04]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 17 \t LOSS train: 0.3091850136926111  val: 0.4059544285309726 \tACCU train: 0.8423732517482518  val: 0.7923850574712643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:24,  6.13it/s, acc=0.625, loss=0.548]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 18 \t LOSS train: 0.312427469711894  val: 0.4323579198841391 \tACCU train: 0.8390078671328672  val: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/520 [00:00<01:31,  5.68it/s, acc=1, loss=0.04]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 19 \t LOSS train: 0.31612018327264546  val: 0.41752036558143024 \tACCU train: 0.8418378496503497  val: 0.8096264367816091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 20 \t LOSS train: 0.3042068015963126  val: 0.4664981795860262 \tACCU train: 0.8408872377622377  val: 0.7931034482758621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "#loop = tqdm.tqdm(range(epochs), total=epochs,leave=False)\n",
    "epochs = 20\n",
    "if not trial:\n",
    "    log_file.write(\"\\nOnly embedding layer frozen\\n\")\n",
    "    log_file.write(\"learning_rate = \" + str(learning_rate) + \"\\n\")\n",
    "    log_file.write(\"epochs = \" + str(epochs) + \"\\n\")\n",
    "    log_file.write(\"Epoch\\tLOSStrain\\tLOSSval\\tACCUtrain\\tACCUval\\n\") \n",
    "    \n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #print (\"EPOCH \" + str(epoch))\n",
    "    \n",
    "    train_loss, train_accu = train(train_iterator)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accu_list.append(train_accu)\n",
    "    \n",
    "    val_loss,val_accu = validate(valid_iterator)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_accu_list.append(val_accu)\n",
    "    \n",
    "    if not trial:\n",
    "        log_file.write(str(epoch+1) + \"\\t\" + str(train_loss) + \"\\t\" + str(val_loss) + \"\\t\" + str(train_accu) + \"\\t\" + str(val_accu)  + \"\\n\")\n",
    "        torch.save(model.state_dict(), \"pretrained_model_epoch\" + str(epoch) + \".pth\")\n",
    "    print (\"Epoch :\",epoch+1,\"\\t\",\"LOSS train:\",train_loss,\" val:\",val_loss, \"\\tACCU train:\",train_accu,\" val:\",val_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_list, label='Training loss')\n",
    "plt.plot(val_loss_list, label='Validation loss')\n",
    "plt.legend()\n",
    "if not trial:\n",
    "    plt.savefig(log_file_name[:-4] + \".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(yhat,y): #  FOR BCE ERROR\n",
    "    \n",
    "    if batched:\n",
    "        batch_accuracy = []\n",
    "        for batch in range(yhat.shape[0]):\n",
    "            accuracy_list = []\n",
    "            \n",
    "            for i,entry in enumerate(yhat[batch]):\n",
    "                softmax = torch.exp(entry.float())\n",
    "                prob = list(softmax.cpu().detach().numpy())\n",
    "                predictions = np.argmax(prob, axis=0)\n",
    "                accuracy_list.append(np.argmax(y[batch][i].cpu().detach().numpy(), axis=0) == predictions != 0)\n",
    "            batch_accuracy.append((np.sum(np.array(accuracy_list))*1.0)/len(accuracy_list))\n",
    "            \n",
    "        return np.sum(batch_accuracy)/len(batch_accuracy)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        accuracy_list = []\n",
    "        #print (yhat.shape[0])\n",
    "        for i,entry in enumerate(yhat):\n",
    "            #if y[i].cpu().detach().numpy() != 0:\n",
    "                #print (entry.shape)\n",
    "            softmax = torch.exp(entry.float())\n",
    "            prob = list(softmax.cpu().detach().numpy())\n",
    "            predictions = np.argmax(prob, axis=0)\n",
    "                #if random.random() > 0.99:\n",
    "                #    print (predictions,y[i],y[i].cpu().detach().numpy())\n",
    "            #print (yhat,predictions,y[i].cpu().detach().numpy())\n",
    "            accuracy_list.append(y[i].cpu().detach().numpy() == predictions)\n",
    "            \n",
    "        return (np.sum(np.array(accuracy_list))*1.0)/len(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "def get_predictions(yhat):\n",
    "    predictions_list = []\n",
    "    for i,entry in enumerate(yhat):\n",
    "        softmax = torch.exp(entry.float())\n",
    "        prob = list(softmax.cpu().detach().numpy())\n",
    "        predictions = np.argmax(prob, axis=0)\n",
    "        predictions_list.append(predictions)\n",
    "    return predictions_list\n",
    "\n",
    "def confusion_matrix(y,yhat):\n",
    "    #print (y,yhat)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y,yhat)\n",
    "    #cm_val = sklearn.metrics.confusion_matrix(y,yhat)\n",
    "    #tn, fp, fn, tp = cm_val.ravel()\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    return roc_auc, fpr, tpr\n",
    "\n",
    "def test(val_dl,show_predictions=False):\n",
    "    real_and_predictions = []\n",
    "    model.eval()\n",
    "    total_loss = []\n",
    "    accuracy = []\n",
    "    \n",
    "    prediction_list = []\n",
    "    y_ground_truth = []\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        val_dl.create_batches()\n",
    "        loop = tqdm.tqdm(enumerate(val_dl.batches), total=len(val_dl),leave=False)\n",
    "        for i,batch in loop:\n",
    "            batch_text = [example[\"text\"] for example in batch]\n",
    "            batch_label = torch.tensor([example[\"label\"] for example in batch])\n",
    "            x_padded = pad_sequence(batch_text,batch_first=True, padding_value=0)\n",
    "            #y_padded = pad_sequence(batch_label,batch_first=True, padding_value=0)\n",
    "            xvalc = x_padded.to(device)\n",
    "            yvalc = batch_label.to(device)\n",
    "            y_ground_truth.extend(batch_label.cpu().detach().numpy())\n",
    "            '''loop = tqdm.tqdm(enumerate(val_dl), total=len(val_dl),leave=False)\n",
    "            for i, (xval,yval) in loop:\n",
    "            xval = xval.view(1,-1)\n",
    "            yval = yval.view(1,-1)\n",
    "            xvalc = xval.to(device)\n",
    "            yvalc = yval.to(device)'''\n",
    "\n",
    "            # Forward prop\n",
    "            output_val = model(xvalc.long(),yvalc)\n",
    "            prediction_list.extend(get_predictions(output_val))\n",
    "        \n",
    "            accuracy.append(get_accuracy(output_val,yvalc))\n",
    "\n",
    "            loss_val = criterion(output_val, yvalc)\n",
    "            total_loss.append(loss_val.item())\n",
    "            \n",
    "            #print (one_hot_to_index(yvalc)[0],one_hot_to_index(output_val)[0])\n",
    "            if show_predictions:\n",
    "                if batched:\n",
    "                    compound_list_original = index_to_word(yval_reshapedc.cpu().detach().numpy())\n",
    "                    \n",
    "                    compound_list_predicted = []\n",
    "                    for i,entry in enumerate(output_val.view(len(yval_reshaped),-1,len(vocab))):\n",
    "                        softmax = torch.exp(entry.float())\n",
    "                        prob = list(softmax.cpu().detach().numpy())\n",
    "                        predictions = np.argmax(prob, axis=1)\n",
    "                        #print (predictions.shape,output_val.shape,len(compound_list_original[i]))\n",
    "                        pred = \"\"\n",
    "                        for i,entry in enumerate(predictions):\n",
    "                            pred += index_word[entry]\n",
    "                        compound_list_predicted.append(pred) \n",
    "                        \n",
    "                    for i in range(len(compound_list_original)):\n",
    "                        real_and_predictions.append((compound_list_original[i],compound_list_predicted[i]))\n",
    "                else:\n",
    "                    pred = \"\"\n",
    "                    real = \"\"\n",
    "                    softmax = torch.exp(output_val.float())\n",
    "                    prob = list(softmax.cpu().detach().numpy())\n",
    "                    predictions = np.argmax(prob, axis=1)\n",
    "                    for i,entry in enumerate(predictions):\n",
    "                        pred += en_index_word[entry]\n",
    "                        #print (i)\n",
    "                        real += en_index_word[yvalc.cpu().detach().numpy()[i]]\n",
    "                    real_and_predictions.append((real,pred))\n",
    "                    \n",
    "    roc_auc, fpr, tpr = confusion_matrix(y_ground_truth,prediction_list)\n",
    "    return (sum(total_loss)/(i+1),sum(accuracy)/(len(accuracy)),real_and_predictions,roc_auc, fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    }
   ],
   "source": [
    "loss,accuracy,prediction_list,roc_auc, fpr, tpr = test(test_iterator,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5039357869275685, 0.817528735632184)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA9CElEQVR4nO3dd3hUZfbA8e+R3gQFbCCINBEFhAjqoqKsFAXLYsG6urrY62LX1RW7roprL7vYfpiIgtgAFbGxrqCiNAWkhiZNqpQk5/fHuSGTOEmGkJk75XyeZ55MuTNz5ia5Z+5bziuqinPOOVeaXcIOwDnnXHLzROGcc65Mniicc86VyROFc865MnmicM45VyZPFM4558rkicLtEBGZLiI9wo4jWYjILSLyQkjvPUxE7g7jvSubiJwtIuMq+Fz/m4wzTxQpTETmi8hvIrJBRJYFB4668XxPVW2vqhPi+R6FRKSGiNwnIguDzzlbRK4XEUnE+0eJp4eI5Ebep6r3qupFcXo/EZGrRGSaiGwUkVwReUNEDo7H+1WUiNwpIq/uzGuo6muq2iuG9/pdckzk32Sm8kSR+vqral2gE3AIcHO44ew4EalaykNvAD2B44F6wLnAIGBoHGIQEUm2/4ehwNXAVcDuQBtgFHBCZb9RGb+DuAvzvV2MVNUvKXoB5gN/jLj9IPBexO3DgInAr8D3QI+Ix3YH/gMsAdYAoyIe6wdMCZ43EehQ8j2BfYDfgN0jHjsEWAlUC27/BZgZvP5YoHnEtgpcDswG5kX5bD2BzcC+Je7vBuQDrYLbE4D7gK+BtcDbJWIqax9MAO4Bvgw+SyvggiDm9cBc4OJg2zrBNgXAhuCyD3An8GqwzX7B5/ozsDDYF7dGvF8t4KVgf8wEbgByS/ndtg4+Z9cyfv/DgCeB94J4/we0jHh8KLAIWAd8AxwZ8didwAjg1eDxi4CuwH+DfbUUeAKoHvGc9sCHwGpgOXAL0AfYCmwL9sn3wbb1gReD11kM3A1UCR47P9jnjwavdXdw3xfB4xI89kvwO/0BOAj7krAteL8NwDsl/w+AKkFcPwf75BtK/A35pQLHmrAD8MtO/PKK/4M0BaYCQ4PbTYBV2LfxXYDjgtuNg8ffA7KB3YBqwNHB/Z2Df9BuwT/dn4P3qRHlPccDf42I5yHgmeD6ycAcoB1QFbgNmBixrQYHnd2BWlE+2/3Ap6V87gUUHcAnBAeig7CD+ZsUHbjL2wcTsAN6+yDGati39ZbBwepoYBPQOdi+ByUO7ERPFM9jSaEjsAVoF/mZgn3eFDsAlpYoLgEWlPP7H4YdaLsG8b8GvB7x+DlAw+CxvwHLgJoRcW8Lfk+7BPF2wRJr1eCzzASuCbavhx30/wbUDG53K7kPIt57FPBs8DvZA0vkhb+z84E84MrgvWpRPFH0xg7wDYLfQztg74jPfHcZ/wfXY/8HbYPndgQahv2/muqX0APwy0788uwfZAP2zUmBj4EGwWM3Aq+U2H4sduDfG/tmvFuU13waGFLivp8oSiSR/5QXAeOD64J9ez0quP0BcGHEa+yCHXSbB7cVOLaMz/ZC5EGvxGNfEXxTxw7290c8diD2jbNKWfsg4rl3lbOPRwFXB9d7EFuiaBrx+NfAwOD6XKB3xGMXlXy9iMduBb4qJ7ZhwAsRt48Hfixj+zVAx4i4Pyvn9a8BRgbXzwS+K2W77fsguL0nliBrRdx3JvBJcP18YGGJ1zifokRxLDALS1q7RPnMZSWKn4CTdvZ/yy/FL8nWJut23MmqWg87iB0ANArubw6cJiK/Fl6A7liS2BdYraprorxec+BvJZ63L9bMUtII4HAR2Qc4CjtIfh7xOkMjXmM1lkyaRDx/URmfa2UQazR7B49He50F2JlBI8reB1FjEJG+IvKViKwOtj+eon0aq2UR1zcBhQMM9inxfmV9/lWU/vljeS9E5G8iMlNE1gafpT7FP0vJz95GRN4NBkasA+6N2H5frDknFs2x38HSiP3+LHZmEfW9I6nqeKzZ60lguYg8JyK7xvjeOxKni5EnijShqp9i37YeDu5ahH2bbhBxqaOq9weP7S4iDaK81CLgnhLPq62qw6O856/AOOB04CxguAZf64LXubjE69RS1YmRL1HGR/oI6CYi+0beKSJdsYPB+Ii7I7dphjWprCxnH/wuBhGpgTVdPQzsqaoNgPexBFdevLFYijU5RYu7pI+BpiKSVZE3EpEjsTOq07EzxwZYe3/kiLGSn+dp4EegtaruirX1F26/CGuSi6bk6yzCzigaRez3XVW1fRnPKf6Cqo+rahesWbAN1qRU7vPKidNVkCeK9PIYcJyIdMI6KfuLSG8RqSIiNYPhnU1VdSnWNPSUiOwmItVE5KjgNZ4HLhGRbsFIoDoicoKI1CvlPf8POA8YEFwv9Axws4i0BxCR+iJyWqwfRFU/wg6Wb4pI++AzHIa1wz+tqrMjNj9HRA4UkdrAXcAIVc0vax+U8rbVgRrACiBPRPoCkUM2lwMNRaR+rJ+jhBxsn+wmIk2AK0rbMPh8TwHDg5irB/EPFJGbYnivelg/wAqgqoj8HSjvW3k9rGN7g4gcAFwa8di7wF4ick0wbLmeiHQLHlsO7Fc4aiz4+xoH/FNEdhWRXUSkpYgcHUPciMihwd9fNWAjNqghP+K99i/j6S8AQ0SkdfD320FEGsbyvq50nijSiKquAF4GblfVRcBJ2LfCFdg3resp+p2fi33z/hHrvL4meI3JwF+xU/81WIf0+WW87WhshM5yVf0+IpaRwAPA60EzxjSg7w5+pAHAJ8AYrC/mVWwkzZUltnsFO5tahnW0XhXEUN4+KEZV1wfPzcE++1nB5yt8/EdgODA3aFKJ1hxXlruAXGAedsY0AvvmXZqrKGqC+RVrUjkFeCeG9xqLfRmYhTXHbabspi6AwdhnXo99YcgufCDYN8cB/bH9PBs4Jnj4jeDnKhH5Nrh+HpZ4Z2D7cgSxNaWBJbTng+ctwJrhCs+UXwQODPb/qCjPfQT7/Y3Dkt6LWGe52wlS1FLgXOoRkQlYR2oos6N3hohcinV0x/RN27mw+BmFcwkiInuLyB+Cppi22FDTkWHH5Vx54pYoROTfIvKLiEwr5XERkcdFZI6I/CAineMVi3NJojo2+mc91hn/NtYP4VxSi1vTU9A5ugF4WVUPivL48Vhb8/HY5K6hqtqt5HbOOefCFbczClX9DBs7X5qTsCSiqvoV0EBEYu3scs45lyBhFuNqQvFRGLnBfUtLbigig7A6L9SpU6fLAQcckJAAnXMu2anCli122by56OfmzbBtG+zFUvZmGd9RsFJVG1fkPcJMFNFKRUdtB1PV54DnALKysnTy5MnxjMs555JKQQHk5sKsWXaZPbvo+rx5kJ9ftO3uu0P79tC6ldKmrdBj3WjaLhjHHjlPLqjo+4eZKHIpPjO1KVbJ1DnnMo4q/PJL8SRQeH3OHDtDKFS7NrRpA507wxln2PU2baB1a2i4yxoYPBj23x9uvRU40S45T1Y4tjATxWjgChF5HevMXhvM6HTOubS1dm3xZBCZENatK9quWjVo2dISQO/eRcmgTRvYe2+IunzXyJFw2WWwYgXcdlulxRy3RCEiw7FCdY3EVgW7AysUhqo+g9XQOR6b+bsJWwfAOedS3m+/2VlAtLODX34p2k4Emje3g/9559kZQWEyaNYMqsZ6hF6+HK68Et54Azp1gvfes9ONShK3RKGqZ5bzuGIL1zjnXMrZtg3mz/99n8Hs2bBwYfFt997bksCJJxY1EbVpY61DNWtWQjCLFllyuOceuP56Ox2pRL4EoXPOlaKgABYvjp4M5s6FvLyibRs0sIP/UUcVTwatW0O90kpq7owFC+Cdd+CKKyAry7JTw/jUP/RE4ZzLaKqwcmX0EUVz5lgzUqFatezg36EDnHpq8YTQsGEp/QaVraAAnn4abgqKCA8YYKcscUoS4InCOZch1q2L3mcwa5Z1MBeqWtU6kVu3huOOKz6iaJ99YJcwK+T99BNcdBF88YX1cD/7rCWJOPNE4ZxLG5s3w88/R08Gy5cXbSdincVt2sDZZxdPBvvttwOdyIm0aRN0726TJoYNs97vhJzCeKJwzqWYvDzrRI52drBwoTUlFdpzT0sAJ5xQPBm0bGnNSClh1iwLunZteOUVG9W0114JDcEThXMu6ahaJ3K0ZDB3ro04KlS/viWA7t2LDy9t3Rp2jXWl7WS0eTMMGQIPPGBnEOecA336hBKKJwrnXChUYdWq6COKZs+2lpZCNWvagf+gg+CUU4pPPmvUKGEtMInz5Zdw4YXWJ3HBBXZKFCJPFM65uFq/vujgX3I28po1RdtVrQotWtjB/9hji58dNGkScidyIg0ZAnfcYZ0oY8dCr17lPyfOPFE453bali1Fncglzw6WlijM06yZJYGBA4sPL91vv0qfJ5ZaVO3UqFMnm2V9zz1Qt27YUQGeKJxzMcrPtzleJZNBYSdyQUHRtnvsYQmgT5/iyaBlS+uTdRFWr4Zrr4VWreD226F/f7skEU8UzrntVO0MINrw0rlzYevWom133dUSwOGHw5//XJQQWre2WcouBiNGwOWXW7K4/fawoymVJwrnMtDq1dGrl86eDRs3Fm1Xo4Yd+Nu1g5NOKn52sMceadiJnChLl1rpjbfegi5dYNw46Ngx7KhK5YnCuTS1YYOVoIh2drA6YpHiKlWKOpGPPrr48NJ9982gTuREWrLEOqofeACuuy5JZ/gVSe7onHNl2rLFmoSizTdYUmIZsKZNLQGcdlrxZNCiBVSvHk78GWX+fCvid+WVdhaxaBHstlvYUcXEE4VzSS4/3zqLoyWD+fOLdyI3amQJoFev4sNLW7XyTuTQ5OfDk0/CLbfY6dlpp9nM6hRJEuCJwrmkoArLlkUfXjpnTvFO5Lp17eDftatN1o0sZ51Cx57MMHOmFfGbONGGgD37bMLLb1QGTxTOJdCaNdH7DGbPtj6FQtWr21lAmzbQr1/xs4M99/RO5JSwaZMtTlFQAC+/bFk9RX9xniicq2QbNxZ1IpdMBitXFm23yy42yaxNGzjyyOLJYN99rZPZpaAff4S2ba2t77XXbDTTnnuGHdVO8UThXAVs3Qrz5kU/O1i8uPi2TZpYEvjTn36/DKZ3IqeR336DO++Ehx+Gl16yM4gkKL9RGTxROFeKggIbmBItGcyfb32UhRo2tATQs2fxEUWtWiVNFQYXT599Zn0Rs2fbz379wo6oUnmicBlNFX75JfrkszlzbPhpoTp1LAF06QJnnll8JnIcV6F0ye4f/7AziRYt4KOP7NtCmvFE4TLCr7+Wvgzm+vVF21WrVtSJ3Ldv8bODvfdO2b5IFw+FRfyysqxW05Ah9m0iDXmicGlj0yY7C4iWEFasKNpOpKgT+fDDiyeD5s29E9mVY+VKSwytW8Pf/25rRYS8XkS8eaJwKWXbNutEjpYMFi0qvu3ee1sCOPnk4iOK9t/fahg5t0NU4Y03rEbTmjW2ZkSG8EThkk5BAeTmRh9eOndu8U7k3Xazg3+PHr+fiVyvXmgfwaWbJUvgssvg7betqemjj6BDh7CjShhPFC4UqtYcFK3PYM4cWy64UO3algQ6dYLTTy+eELwT2SXEsmUwfjw89BBcc03SF/GrbJn1aV3CrV1bvIR1ZGJYu7Zou2rVrEmoTRvo3bt4MthnH+9EdiGYOxdGj7bE0LmzFdzK0IU2PFG4nfbbb0XLYJZMCL/8UrSdiHUWt25tc5EiJ581b55xX9JcssrPh8cfh1tvtW8wAwdafaYMTRLgicLFKC/PJplFSwaLFllTUqG99rIE0L9/8RFFLVtCzZqhfQTnyjd9Olx4IfzvfzaS6ZlnUrKIX2XzROG2Kyiw8hPRRhTNnWvJolD9+lbO5sgjiyeD1q1tiUznUs6mTbZykwj83//ZmYS3eQKeKDKOqg0Dj9ZnMHu2NSMVqlXLDvwHHwwDBhRvKmrUyP+HXJqYMcPWeq1dG15/3Yr4NW4cdlRJxRNFmlq3rujgX/Ls4Ndfi7arWrWoE7lknaImTXwZTJfGNm2yuRCPPALDhsG558If/xh2VEnJE0UK27y5qBO5ZEJYtqz4ts2aWQIorFFUeGne3PrrnMsoEybAX/9qY7EvvhhOPDHsiJKaJ4okl5cHCxb8PhnMmmWj9SI7kffYww7+xx9ffHhpy5bWjOScw84i7rrL/jHGj4djjgk7oqTniSKJ/eUv8OqrVrai0K672sH/D3+ACy4ovgxm/frhxepc0iss4te1K/ztb5YsfCHxmIhGfiWt7BcX6QMMBaoAL6jq/SUerw+8CjTDktbDqvqfsl4zKytLJ0+eHKeIk8eyZTbRrG/foo7kNm2sj807kZ3bAStWwNVX2zC9DKrPVJKIfKOqWRV5btzOKESkCvAkcByQC0wSkdGqOiNis8uBGaraX0QaAz+JyGuqujXKS2aUESPsC9CDD0L79mFH41wKUoXhw+Gqq2x0xz/+EXZEKSueY1q6AnNUdW5w4H8dOKnENgrUExEB6gKrgTwcOTmWIDxJOFcBubnWQX322VYh8rvv4Oabw44qZcUzUTQBIgs/5wb3RXoCaAcsAaYCV6tqQckXEpFBIjJZRCaviFxYIE0tXgxffAFnnBF2JM6lqBUrbHnSRx6BL7/0b1w7KZ6JIlpLeskOkd7AFGAfoBPwhIj8bl6vqj6nqlmqmtU4AybCFDY7nX562JE4l0LmzIFHH7XrhxxitWWuvdZXoqoE8UwUucC+EbebYmcOkS4A3lIzB5gHHBDHmFJCTo5NDm3bNuxInEsBeXnw8MNWQuAf/4Dly+1+ryVTaeKZKCYBrUWkhYhUBwYCo0tssxDoCSAiewJtgblxjCnpLVoEEyf62YRzMZk6FY44Aq6/Hnr1sqJ+e+4ZdlRpJ26jnlQ1T0SuAMZiw2P/rarTReSS4PFngCHAMBGZijVV3aiqK+MVUyp44w376YnCuXJs2mST5XbZxWo0nX66jx2Pk7jOo4iHdJ9H0a2bnUl/803YkTiXpKZNs85pEfj4Y2unbdQo7KiS3s7Mo/CSb0lk/nz4+ms/m3Auqo0b4brrbK3qV1+1+3r29CSRAF7CI4l4s5Nzpfj4YyviN28eXHYZnFRySpaLJz+jSCLZ2XDoodCiRdiROJdEbr/dyn9XrQqffgpPPukjmhLME0WS+Pln65fwSXbOBQqCubdHHAE33ADffw9HHRVuTBnKE0WSyMmxn6eeGm4czoXul19sGdLC2kx9+8IDD3it/BB5okgSOTlw2GG2kJBzGUnVOqnbtYORI70EeBLxRJEEZs2CKVO82cllsEWLoF8/W460bVsr4nfjjWFH5QKeKJKANzu5jLdqlRXvGzoUPv8cDjww7IhcBB8emwRycqB7d2jaNOxInEugWbNg9GgYPBg6dbKzinr1wo7KReFnFCGbOdPK1fjcCZcx8vKsc7pDB7jnnqIifp4kkpYnipDl5FglggEDwo7EuQT4/nurU3PTTXD88TBjhhfxSwHe9BQiVZtkd9RRtj62c2lt0yYruVG1qi264t+OUoafUYRo+nRrevJmJ5fWfvjBvhXVrm11ambM8CSRYjxRhCgnxyok+/+MS0sbNsDVV1tH9Suv2H3HHAO77x5qWG7HedNTSAqbnXr08CZal4Y+/BAGDbKSyFdcAaecEnZEbif4GUVIfvjBRgd6s5NLO7feaqvN1ahhcyL+9S8f0ZTiYk4UIlInnoFkmuxsW/P9T38KOxLnKklhEb/u3eHmm63cQPfuoYbkKke5iUJEjhCRGcDM4HZHEXkq7pGlMVXrnzj2WGjcOOxonNtJy5ZZWYE777TbffvCvfdCzZqhhuUqTyxnFI8CvYFVAKr6PeC1fnfCt99aWXGv7eRSmioMG2blNt5919eISGMxdWar6iIpvmh5fnzCyQw5OTaU3Pv3XMpasMA6q8eNs+alF16wYn4uLcVyRrFIRI4AVESqi8hggmYot+MKm52OO85HCboU9uuvMGkSPPGErTrnSSKtxZIoLgEuB5oAuUAn4LI4xpTWJk2yEYM+2smlnJ9+gocesusdO8LChXD55TYZyKW1WH7DbVX1bFXdU1X3UNVzgHbxDixd5eRAtWq+NrxLIdu2wX33WXK4/35bgQ6gbt1w43IJE0ui+FeM97lyFBRYoujdG3bbLexonIvBd99ZEb9bboH+/a38xh57hB2VS7BSO7NF5HDgCKCxiFwX8dCuQJV4B5aO/vc/K7l/zz1hR+JcDDZtss60atXgzTd90k8GK2vUU3WgbrBN5LTKdYCvxVYBOTk2WdWbnVxS++47q89Uu7ZVee3Y0U+BM1ypiUJVPwU+FZFhqroggTGlpYICK5zZp48PN3dJav16m1H95JPw0ktw3nlWjMxlvFjmUWwSkYeA9sD2qZaqemzcokpDEyfC4sXw4INhR+JcFGPGwMUXW9vo1Vd7M5MrJpbO7NeAH4EWwD+A+cCkOMaUlrKzraJB//5hR+JcCTffbGU36tSBL7+Exx7zEU2umFjOKBqq6osicnVEc9Sn8Q4sneTnW1Pv8cd7EU2XRPLzrTJljx5WKuC226wTzbkSYkkU24KfS0XkBGAJ0DR+IaWfL76wumle28klhaVLbaJc+/YwZIiN1+7dO+yoXBKLpenpbhGpD/wNGAy8AFwTz6DSTXY21KoFJ5wQdiQuo6nCf/5jRfw++MBHMrmYlXtGoarvBlfXAscAiMgf4hlUOsnLsyHo/fpZE7BzoZg/H/76V/joIzjySCvi16ZN2FG5FFHWhLsqwOlYjacxqjpNRPoBtwC1gEMSE2Jq+/RTq3jgzU4uVGvXWn37p56y0U1en8ntgLL+Wl4ELgIaAo+LyH+Ah4EHVTWmJCEifUTkJxGZIyI3lbJNDxGZIiLT07GTPCfHziT69g07EpdxZsyw2kxQVMTv0ks9SbgdVlbTUxbQQVULRKQmsBJoparLYnnh4IzkSeA4rOrsJBEZraozIrZpADwF9FHVhSKSVkVktm2zZqcTT7RJrs4lxNatNmFnyBAbZveXv1h9Jm/7dBVU1leLrapaAKCqm4FZsSaJQFdgjqrOVdWtwOtAyeIVZwFvqerC4H1+2YHXT3qffAKrVnlJcZdAkyfDoYfC7bfbpDkv4ucqQVlnFAeIyA/BdQFaBrcFUFXtUM5rNwEWRdzOBbqV2KYNUE1EJmD1pIaq6sslX0hEBgGDAJo1a1bO2yaPnBz7QtenT9iRuIywcaMNc61ZE95+205lnasEZSWKnV1zQqLcp1HevwvQE+sg/6+IfKWqs4o9SfU54DmArKyskq+RlLZuhbfesgKAvsa8i6tvv7UifnXqwMiR0KEDNGgQdlQujZTa9KSqC8q6xPDaucC+EbebYpP1Sm4zRlU3qupK4DOg445+iGT08cewZo03O7k4WrcOLrsMunSBV1+1+446ypOEq3TxHP4wCWgtIi1EpDowEBhdYpu3gSNFpKqI1MaaptJiPe7sbKhfH3r1CjsSl5bef99mVj/7LFx3HQwYEHZELo3FUsKjQlQ1T0SuAMZiCx39W1Wni8glwePPqOpMERkD/AAUAC+o6rR4xZQoW7bAqFFw8sleOsfFwY032qimAw+0ImLdSnb9OVe5YkoUIlILaKaqP+3Ii6vq+8D7Je57psTth4CHduR1k92HH9r8Jp9k5yqNqi1qUqUK9OxpHV+33OLfRFxClNv0JCL9gSnAmOB2JxEp2YTkImRnWxmdnj3DjsSlhcWL7fT0jjvsdq9e8I9/eJJwCRNLH8Wd2JyIXwFUdQqwX7wCSnWbN9vIxFNOgerVw47GpTRVeP55a2IaNw4aNQo7IpehYml6ylPVtSLRRru6ksaMsRUlvdnJ7ZR58+DCC23WZo8eljBatQo7KpehYkkU00TkLKCKiLQGrgImxjes1JWTAw0bwjHHhB2JS2kbNsAPP9ioposu8vpMLlSx/PVdia2XvQX4P6zc+DVxjCllbdoEo0fbSMVq1cKOxqWcadPg3nvt+sEHWxG/QYM8SbjQxfIX2FZVb1XVQ4PLbUHtJ1fCBx9YFQWfZOd2yNat1jnduTM8+qjVpQevJOmSRiyJ4hER+VFEhohI+7hHlMJycqBxYzj66LAjcSlj0iSbWX3nnXDaaV7EzyWlchOFqh4D9ABWAM+JyFQRuS3egaWajRvh3Xfh1FNtnXrnyrVxo1WMXLPG2ixfe82+aTiXZGJq/FTVZar6OHAJNqfi7/EMKhW99571UXizkyvX5Mk2ea5OHRtLPX069O8fdlTOlSqWCXftROROEZkGPIGNeGoa98hSTHY27LWXLUfsXFRr19oypIceWlTEr3t3KwrmXBKLpZHkP8BwoJeqlqz+6rB5E++/b6MYq1QJOxqXlN55By65BJYtg8GDrY3SuRRRbqJQ1cMSEUgqe/ddm5Htk+xcVNdfDw8/bENeR42yMwrnUkipiUJEclT1dBGZSvEFh2Jd4S5jZGfDPvvAEUeEHYlLGqqQn28jG3r1gl13taqvXtfFpaCyziiuDn72S0QgqWrdOps/cemlPi/KBXJz7Q+iQwe45x447ji7OJeiylrhbmlw9bIoq9tdlpjwkt/bb9t8KW92chQUWMmNAw+E8eNtdINzaSCW78DRvgr1rexAUlVODuy7r68dk/HmzoVjj7UO665dYepUuPLKsKNyrlKU1UdxKXbmsL+I/BDxUD3gy3gHlgrWrIGxY+Gqq7zZKeNt3Gizql94Af7yF/Bqyy6NlNVH8X/AB8B9wE0R969X1dVxjSpFvP02bNvmk+wy1tSp9kdw2202omnBAqhVK+yonKt0ZX0PVlWdD1wOrI+4ICK7xz+05JeTA/vt56MdM86WLfD3v1sRv8cfLyri50nCpanyzij6Ad9gw2Mjz6UV2D+OcSW9VatsbezrrvNWhozy1Ve2oNCMGXDuuVbttWHDsKNyLq5KTRSq2i/42SJx4aSOUaMgL8+bnTLKxo1wwglWo+n996Gvj+lwmSGWWk9/EJE6wfVzROQREWkW/9CSW3Y2tGxprQ8uzf3vf0VF/N55x4r4eZJwGSSWsTpPA5tEpCNwA7AAeCWuUSW5FStsmPzpp3uzU1r79Vcr4HXYYUVF/I44AurVCzUs5xItlkSRp6oKnAQMVdWh2BDZjDVypFVn8GanNDZqlE2cGzbMSm+cdlrYETkXmliqx64XkZuBc4EjRaQKkNErQmdnQ5s20LFj2JG4uLjuOuuk7tjRmpq6dAk7IudCFUuiOAM4C/iLqi4L+iceim9YyWv5cpgwAW65xZud0kpkEb/jj7eRTDfcANUy+juRc0BsS6EuA14D6otIP2Czqr4c98iS1JtvWr+m13ZKIwsX2mimO+6w23/8I9x6qycJ5wKxjHo6HfgaOA04HfifiGTsqis5OdCuHbRvH3YkbqcVFMBTT9kv89NPrVa8c+53Yml6uhU4VFV/ARCRxsBHwIh4BpaMli6Fzz6zL57e7JTi5syxmkyff24lwJ97zqbZO+d+J5ZEsUthkgisIrbRUmlnxAhryvYBMGlg82aYNQv+8x/485898ztXhlgSxRgRGYutmw3Wuf1+/EJKXjk5cNBBNmrSpaApU6yI3x132C9y/nyoWTPsqJxLerF0Zl8PPAt0ADoCz6nqjfEOLNnk5sIXX3gndkravNk6p7Oy4Omni4r4eZJwLiZlrUfRGngYaAlMBQar6uJEBZZsRgQ9Mj7JLsVMnGhF/H780ZqYHnkEdvfix87tiLLOKP4NvAsMwCrI/ishESWp7Gzo1Mkm2rkUsXEj9O8PmzbBmDE2y9qThHM7rKw+inqq+nxw/ScR+TYRASWjBQusuvS994YdiYvJf/9ra9PWqQPvvmv9EV6fybkKK+uMoqaIHCIinUWkM1CrxO1yiUgfEflJROaIyE1lbHeoiOQn6/wMb3ZKEWvW2JDXI46AV4K6lYcf7knCuZ1U1hnFUuCRiNvLIm4rcGxZLxzUhHoSOA7IBSaJyGhVnRFluweAsTsWeuJkZ1u5n5Ytw47Eleqtt+Dyy6207803+6gD5ypRWQsXHbOTr90VmKOqcwFE5HWsAu2MEttdCbwJJOWCovPmwaRJ8MADYUfiSnXttfDYY9aJ9P77cMghYUfkXFqJZR5FRTUBFkXczgW6RW4gIk2AU7Czk1IThYgMAgYBNGuW2DWTcnLspzc7JZnIIn79+sEee8DgwV6fybk4iOcM62hTXbXE7ceAG1U1v6wXUtXnVDVLVbMaN25cWfHFJCcHunb16g5JZf586NMHbr/dbvfsac1NniSci4t4JopcYN+I202BJSW2yQJeF5H5wKnAUyJychxj2iFz5sC33/rZRNIoKIB//ctGMU2cCM2bhx2Rcxmh3KYnERHgbGB/Vb0rWI9iL1X9upynTgJai0gLYDEwEFvXYjtVbRHxPsOAd1V11A59gjgqbHby2k5JYPZsuOAC+PJLO5t45hlPFM4lSCxnFE8BhwNnBrfXY6OZyqSqecAV2GimmUCOqk4XkUtE5JIKxptQOTk2ujLB3SIumq1b4eef4eWXrcPak4RzCRNLZ3Y3Ve0sIt8BqOoaEakey4ur6vuUKCCoqs+Usu35sbxmovz0E3z/vQ2mcSH57jsr4nfnnbZmxPz5UKNG2FE5l3FiOaPYFsx1UNi+HkVBXKNKAjk5Vnn61KScApjmNm+2zulDD4Vnn7W5EeBJwrmQxJIoHgdGAnuIyD3AF0DaF7PIzobu3aFJk7AjyTBffAEdO8L998N558GMGZDgkW7OueLKbXpS1ddE5BugJzbk9WRVnRn3yEI0fbpd/pXRZRBDsGEDnHQS7LorjBtnK88550IXy6inZsAm4J3I+1R1YTwDC9Mbb1iz04ABYUeSIb74wuoz1a0L771nw1/r1g07KudcIJamp/ewcuPvAR8Dc4EP4hlUmFSt2enoo2HvvcOOJs2tWmXNS0ceWVTE77DDPEk4l2RiaXo6OPJ2UDn24rhFFLJp02yNm6uuCjuSNKZqJXmvuAJWr7YZ1gMHhh2Vc64UO1zrSVW/FZGkLOBXGbKzYZddvNkprq69FoYOtZK848ZZ57VzLmnF0kdxXcTNXYDOwIq4RRQiVRsWe8wxVmPOVSJVyMuzekwnngj77APXXWdF/ZxzSS2WPop6EZcaWF/FSfEMKizff2+VIry2UyWbNw969Soq4nfssXDDDZ4knEsRZf6nBhPt6qrq9QmKJ1TZ2VClCvzpT2FHkiby8+GJJ+CWW2zHetEs51JSqYlCRKqqal6sy56musJmp549oVGjsKNJA7Nmwfnn2/rVffvaDOt99y33ac655FPWGcXXWH/EFBEZDbwBbCx8UFXfinNsCfXNNzB3Ltx6a9iRpIm8PFiwAF59Fc46yyamOOdSUiyNxLsDq7BV6BSbna1AWiWKnBxrMj/55LAjSWGTJ1sRvyFD4MADLfN6fSbnUl5ZiWKPYMTTNIoSRKGSK9WltMJmp+OOg913DzuaFPTbb3DHHfDPf8Jee9kklMaNPUk4lybKGvVUBagbXOpFXC+8pI2vv7ZWkjPOCDuSFPTpp9ChAzz0EFx4oRXJ8iJ+zqWVss4olqrqXQmLJEQ5OVC9utWjcztgwwYbItagAXz8sQ17dc6lnbISRUb0PhYUWKLo3duOdy4Gn38Of/iD1WT64ANbVKhOnbCjcs7FSVlNTz0TFkWIvvoKcnN9kl1MVq6Ec86Bo44qKuLXtasnCefSXKlnFKq6OpGBhCU72/pcTzwx7EiSWGFv/5VXwpo11nHtRfycyxgZXUOhoMDWnujb19bKcaW4+mpbxenQQ60v4uCDy3+Ocy5tZHSi+PJLWLrUm52iUoVt26yX/5RToHlzuOYaK8XhnMsosRQFTFvZ2VCzJvTvH3YkSebnn62WyW232e1jjoG//c2ThHMZKmMTRX6+rZ1zwgm+oNp2+fnwyCPWtPTNN9C2bdgROeeSQMY2PX32GSxf7pPstvvxR/jzn232Yf/+8PTT0KRJ2FE555JAxiaKnByoXRuOPz7sSJJEQQEsWQLDh1v29CJ+zrlARiaKvDx4803o1y/DpwB8/bUV8bvnHivi9/PP1nntnHMRMrKPYsIEWLEig5udNm2CwYPh8MPhpZdsZ4AnCedcVBmZKHJyrAO7b9+wIwnBJ59YZ/U//wl//asX8XPOlSvjmp62bbNmpxNPhFq1wo4mwTZssOVIGzSwhNGjR9gROedSQMadUYwfD6tXZ9gkuwkTrLO6sIjfDz94knDOxSzjEkV2tpXr6N077EgSYMUKOPNMmzD36qt236GH2nAv55yLUUY1PW3dCiNH2roTNWuGHU0cqdow16uugvXrbWlSL+LnnKugjEoUH30Ev/6aAc1OV14JTz4Jhx0GL75oQ1+dc66CMipRZGdD/frQq1fYkcRBQYFNEKleHU49FVq1soTh9Zmcczsprn0UItJHRH4SkTkiclOUx88WkR+Cy0QR6RivWLZsgVGjrBBq2k0XmD3bliG99Va73aOHV3p1zlWauCUKEakCPAn0BQ4EzhSRkm0g84CjVbUDMAR4Ll7xjB0L69al2SS7vDx4+GHo0AGmTIF27cKOyDmXhuLZ9NQVmKOqcwFE5HXgJGBG4QaqOjFi+6+ApvEKJicHdtvNqmenhZkz4bzzYPJk651/6inYZ5+wo3LOpaF4Nj01ARZF3M4N7ivNhcAH0R4QkUEiMllEJq8oLDexA377zUoa/elPUK3aDj89eS1fbh0vI0d6knDOxU08E0W08qMadUORY7BEcWO0x1X1OVXNUtWsxhUoNzFmjE1KTvlmp6++gptvtuvt2lkRv9NP90qvzrm4imeiyAX2jbjdFFhSciMR6QC8AJykqqviEUhODjRqZPPOUtLGjXDttXDEEfDaa0VF/NLq9Mg5l6zimSgmAa1FpIWIVAcGAqMjNxCRZsBbwLmqOiseQWzaBO+8AwMGQNVUHAz80Udw0EHw2GNw2WVexM85l3BxO3Sqap6IXAGMBaoA/1bV6SJySfD4M8DfgYbAU2LNJ3mqmlWZcbz/vn0hT8lJdhs22Izq3Xe3JfmOPDLsiJxzGUhUo3YbJK2srCydPHlyzNufdpodYxcvTqEzivHj4eijbR7EN9/YzOqMK3XrnKtMIvJNRb+Ip3VRwA0b4L33bKJySiSJ5cvt1Kdnz6Iifl26eJJwzoUqrRPFe+/Z0Nikb3ZShVdesTOHwqVJzzor7Kiccw5I81pP2dmw997QvXvYkZTj8svh6adtadIXX/QZ1s65pJK2iWL9euvIHjQoSUseFRTYcns1atgEj3btbFRTUgbrnMtkadv0NHq0FQJMymann36yzurCIn5HH+2VXp1zSSttE0VODjRpYnPUksa2bXD//dCxI0ybBgcfHHZEzjlXrrRselq71sp2XHYZ7JIsqXD6dDj3XPjuOys69eSTsNdeYUflnHPlSstE8fbbtuxpUtV2qlIFVq+GESNsmrhzzqWIZPm+XalycqBZM+jWLeRAJk6EG4M6hwccAHPmeJJwzqWctEsUa9bAuHEhF1XdsAGuusrG5WZnw8qVdn9KzPpzzrni0i5RjBplfcahjXYaN86K+D3xBFxxhXVaN2oUUjDOObfz0u4rbnY2tGgBWZVaWjBGGzbA2WdDw4bw+efwhz+EEIRzzlWutDqjWLXKqnInvNnpww8hPx/q1rUziilTPEk459JGWiWKkSPteJ2wZqelS61zulcvW1AI4JBDoGbNBAXgnHPxl1aJIjsbWrWyY3VcqcKwYVbE7733bBKdF/FzzqWptOmjWLHClnG46aYENDtdeik8+6yNanrhBWjbNs5v6Fxq2rZtG7m5uWzevDnsUDJGzZo1adq0KdUqcanktEkUb75pdfbi1uwUWcTvrLOgQwe45JIkmvrtXPLJzc2lXr167Lfffkho49Uzh6qyatUqcnNzadGiRaW9btoc5XJy7It9hw5xePGZM20Z0ltusdtHHZVk9UGcS06bN2+mYcOGniQSRERo2LBhpZ/BpcWRbtky+PTTOIx22rYN7r0XOnWCH39MQOeHc+nHk0RixWN/p0XTU2GzU6XWdpo+Hc45x4a6nnYa/OtfsOeelfgGzjmXGtLijCInxwYgtW9fiS9ataqVoX3rLXsDTxLOpayRI0ciIvz444/b75swYQL9+vUrtt3555/PiBEjAOuIv+mmm2jdujUHHXQQXbt25YMPPtjpWO677z5atWpF27ZtGTt2bNRtpkyZwmGHHUanTp3Iysri66+/BuDDDz+kS5cuHHzwwXTp0oXx48fvdDyxSPlEsWSJTYKulE7szz+HwYPtetu2MGsWnHJKJbywcy5Mw4cPp3v37rz++usxP+f2229n6dKlTJs2jWnTpvHOO++wfv36nYpjxowZvP7660yfPp0xY8Zw2WWXkZ+f/7vtbrjhBu644w6mTJnCXXfdxQ033ABAo0aNeOedd5g6dSovvfQS55577k7FE6uUb3oaMcKmNexUoli/3sbVPvWU1f+46Sarz+RF/JyrNNdcYy25lalTJ3jssbK32bBhA19++SWffPIJJ554InfeeWe5r7tp0yaef/555s2bR40aNQDYc889OX0nv5G+/fbbDBw4kBo1atCiRQtatWrF119/zeGHH15sOxFh3bp1AKxdu5Z99tkHgEMi+knbt2/P5s2b2bJly/YY4yXlj4Q5ObZQXLt2FXyBDz6Aiy+G3Fz7S777bqhTpzJDdM6FaNSoUfTp04c2bdqw++678+2339K5c+cynzNnzhyaNWvGrrvuWu7rX3vttXzyySe/u3/gwIHcdNNNxe5bvHgxhx122PbbTZs2ZfHixb977mOPPUbv3r0ZPHgwBQUFTJw48XfbvPnmmxxyyCFxTxKQ4oli0SL48ks7tlfI+vVw3nmwxx62dkTEL9A5V7nK++YfL8OHD+eaa64B7OA9fPhwOnfuXOrooB0dNfToo4/GvK2qxvR+Tz/9NI8++igDBgwgJyeHCy+8kI8++mj749OnT+fGG29k3LhxOxRrRaV0ogj6nHas2UkVxo6F446DevWsiuABB9hEOudcWlm1ahXjx49n2rRpiAj5+fmICA8++CANGzZkzZo1xbZfvXo1jRo1olWrVixcuJD169dTr169Mt9jR84omjZtyqJFi7bfzs3N3d6sFOmll15i6NChAJx22mlcdNFFxZ5zyimn8PLLL9OyZcvyd0JlUNWUunTp0kULdeumesghGrslS1RPPlkVVF96aQee6JyriBkzZoT6/s8884wOGjSo2H1HHXWUfvbZZ7p582bdb7/9tsc4f/58bdasmf7666+qqnr99dfr+eefr1u2bFFV1SVLlugrr7yyU/FMmzZNO3TooJs3b9a5c+dqixYtNC8v73fbHXDAAfrJJ5+oqupHH32knTt3VlXVNWvWaIcOHXTEiBFlvk+0/Q5M1goed0M/8O/opTBRzJtn0d93X5n7yxQUqL74omr9+qo1a6o++KDqtm0xPNE5tzPCThRHH320fvDBB8XuGzp0qF5yySWqqvrFF19ot27dtGPHjpqVlaXjxo3bvt2WLVv0+uuv15YtW2r79u21a9euOmbMmJ2O6e6779b9999f27Rpo++///72+y+88EKdNGmSqqp+/vnn2rlzZ+3QoYN27dpVJ0+erKqqQ4YM0dq1a2vHjh23X5YvX/6796jsRCEapc0smWVlZenkyZN56CG44Qb4+WfYf/9ynnTxxfDcc1Z644UXoHXrhMTqXKabOXMm7So80sRVVLT9LiLfqGqFlnRL2T6KnBxbxa7UJJGfbyU4ata0GdaHHAKDBnl9Juec20EpedScOxcmTy6jE3v6dFthrrCI35FHeqVX55yroJQ8cubk2M/fJYqtW2HIEDt7mDMHDj004bE554pLtebtVBeP/Z2STU85OdCtGzRvHnHn1Klw9tn2c+BAePxxaNw4tBidc7aIzqpVq7zUeIJosB5FzUpejjnlEsWWLTBtGvzznyUeqF4dNm2Ct9+GE08MJTbnXHFNmzYlNzeXFStWhB1Kxihc4a4ypdyopyZNsnTJksksXAj7zv0URo8uyhr5+VClSrgBOudcEtqZUU9x7aMQkT4i8pOIzBGRm6I8LiLyePD4DyJSdgEWYM0a+GPXdex776XQoweMGgUrV9qDniScc67SxS1RiEgV4EmgL3AgcKaIHFhis75A6+AyCHi6vNet9tta3prV3uZFXHed9Uk0alTJ0TvnnCsUzz6KrsAcVZ0LICKvAycBMyK2OQl4OZg1+JWINBCRvVV1aWkv2oL51NyzLYwZYT3azjnn4iqeiaIJsCjidi5Q8sgebZsmQLFEISKDsDMOgC3Vf5o+zSu9AtAIWBl2EEnC90UR3xdFfF8UaVvRJ8YzUUQbC1ey5zyWbVDV54DnAERkckU7ZNKN74sivi+K+L4o4vuiiIhMruhz49mZnQvsG3G7KbCkAts455wLUTwTxSSgtYi0EJHqwEBgdIltRgPnBaOfDgPWltU/4ZxzLvHi1vSkqnkicgUwFqgC/FtVp4vIJcHjzwDvA8cDc4BNwAUxvPRzcQo5Ffm+KOL7oojviyK+L4pUeF+k3IQ755xziZWSRQGdc84ljicK55xzZUraRBGP8h+pKoZ9cXawD34QkYki0jGMOBOhvH0Rsd2hIpIvIqcmMr5EimVfiEgPEZkiItNF5NNEx5goMfyP1BeRd0Tk+2BfxNIfmnJE5N8i8ouITCvl8YodNyu6hmo8L1jn98/A/kB14HvgwBLbHA98gM3FOAz4X9hxh7gvjgB2C673zeR9EbHdeGywxKlhxx3i30UDrBJCs+D2HmHHHeK+uAV4ILjeGFgNVA879jjsi6OAzsC0Uh6v0HEzWc8otpf/UNWtQGH5j0jby3+o6ldAAxHZO9GBJkC5+0JVJ6rqmuDmV9h8lHQUy98FwJXAm8AviQwuwWLZF2cBb6nqQgBVTdf9Ecu+UKCe2KIYdbFEkZfYMONPVT/DPltpKnTcTNZEUVppjx3dJh3s6Oe8EPvGkI7K3Rci0gQ4BXgmgXGFIZa/izbAbiIyQUS+EZHzEhZdYsWyL54A2mETeqcCV6tqQWLCSyoVOm4m68JFlVb+Iw3E/DlF5BgsUXSPa0ThiWVfPAbcqKr5ab6iWiz7oirQBegJ1AL+KyJfqeqseAeXYLHsi97AFOBYoCXwoYh8rqrr4hxbsqnQcTNZE4WX/ygS0+cUkQ7AC0BfVV2VoNgSLZZ9kQW8HiSJRsDxIpKnqqMSEmHixPo/slJVNwIbReQzoCOQbokiln1xAXC/WkP9HBGZBxwAfJ2YEJNGhY6bydr05OU/ipS7L0SkGfAWcG4afluMVO6+UNUWqrqfqu4HjAAuS8MkAbH9j7wNHCkiVUWkNla9eWaC40yEWPbFQuzMChHZE6ukOjehUSaHCh03k/KMQuNX/iPlxLgv/g40BJ4KvknnaRpWzIxxX2SEWPaFqs4UkTHAD0AB8IKqRh02mcpi/LsYAgwTkalY88uNqpp25cdFZDjQA2gkIrnAHUA12LnjppfwcM45V6ZkbXpyzjmXJDxROOecK5MnCuecc2XyROGcc65Mniicc86VyROFS0pB5dcpEZf9yth2QyW83zARmRe817cicngFXuMFETkwuH5Liccm7myMwesU7pdpQTXUBuVs30lEjq+M93aZy4fHuqQkIhtUtW5lb1vGawwD3lXVESLSC3hYVTvsxOvtdEzlva6IvATMUtV7ytj+fCBLVa+o7Fhc5vAzCpcSRKSuiHwcfNufKiK/qxorInuLyGcR37iPDO7vJSL/DZ77hoiUdwD/DGgVPPe64LWmicg1wX11ROS9YG2DaSJyRnD/BBHJEpH7gVpBHK8Fj20IfmZHfsMPzmQGiEgVEXlIRCaJrRNwcQy75b8EBd1EpKvYWiTfBT/bBrOU7wLOCGI5I4j938H7fBdtPzr3O2HXT/eLX6JdgHysiNsUYCRWRWDX4LFG2MzSwjPiDcHPvwG3BterAPWCbT8D6gT33wj8Pcr7DSNYuwI4DfgfVlBvKlAHK009HTgEGAA8H/Hc+sHPCdi39+0xRWxTGOMpwEvB9epYJc9awCDgtuD+GsBkoEWUODdEfL43gD7B7V2BqsH1PwJvBtfPB56IeP69wDnB9QZY3ac6Yf++/ZLcl6Qs4eEc8Juqdiq8ISLVgHtF5CisHEUTYE9gWcRzJgH/DrYdpapTRORo4EDgy6C8SXXsm3g0D4nIbcAKrApvT2CkWlE9ROQt4EhgDPCwiDyANVd9vgOf6wPgcRGpAfQBPlPV34Lmrg5StCJffaA1MK/E82uJyBRgP+Ab4MOI7V8SkdZYNdBqpbx/L+BEERkc3K4JNCM9a0C5SuKJwqWKs7GVybqo6jYRmY8d5LZT1c+CRHIC8IqIPASsAT5U1TNjeI/rVXVE4Q0R+WO0jVR1loh0wWrm3Cci41T1rlg+hKpuFpEJWNnrM4DhhW8HXKmqY8t5id9UtZOI1AfeBS4HHsdqGX2iqqcEHf8TSnm+AANU9adY4nUOvI/CpY76wC9BkjgGaF5yAxFpHmzzPPAitiTkV8AfRKSwz6G2iLSJ8T0/A04OnlMHazb6XET2ATap6qvAw8H7lLQtOLOJ5nWsGNuRWCE7gp+XFj5HRNoE7xmVqq4FrgIGB8+pDywOHj4/YtP1WBNcobHAlRKcXonIIaW9h3OFPFG4VPEakCUik7Gzix+jbNMDmCIi32H9CENVdQV24BwuIj9gieOAWN5QVb/F+i6+xvosXlDV74CDga+DJqBbgbujPP054IfCzuwSxmFrG3+ktnQn2FoiM4BvRWQa8CzlnPEHsXyPldV+EDu7+RLrvyj0CXBgYWc2duZRLYhtWnDbuTL58FjnnHNl8jMK55xzZfJE4ZxzrkyeKJxzzpXJE4VzzrkyeaJwzjlXJk8UzjnnyuSJwjnnXJn+HxAlQxE7pjFdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molpmofit",
   "language": "python",
   "name": "molpmofit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
