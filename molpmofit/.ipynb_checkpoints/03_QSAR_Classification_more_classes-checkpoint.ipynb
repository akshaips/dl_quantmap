{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QSAR/QSPR Models Fine-Tuning 1: Classification \n",
    "\n",
    "This notebook is an example of a classification task on BBBP dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import tqdm\n",
    "import sqlite3\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "from SmilesPE.pretokenizer import atomwise_tokenizer\n",
    "from SmilesPE.pretokenizer import kmer_tokenizer\n",
    "from SmilesPE.spe2vec import Corpus\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from utils import *\n",
    "import torch\n",
    "print (torch.__version__)\n",
    "\n",
    "torch.cuda.set_device(0) #change to 0 if you only has one GPU \n",
    "\n",
    "Number_of_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda'), True)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device,torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('results')\n",
    "name = 'classification_new'\n",
    "path = data_path/name\n",
    "path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove rdkit and other warning\n",
    "\n",
    "from rdkit import RDLogger\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: (4982, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCOP(=S)(CC)SC1=CC=CC=C1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC[N+]1=C(C(=C(C(=C1C)C(=O)OC(C)C)C2=CC=CC=C2C...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1=CC(=C(C=C1C(CNCCCCCCNCC(C2=CC(=C(C=C2)O)O)O...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1=CC=C2C(=C1)C=CC=C2N=C=S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC1=NC=C(C(=C1O)CN)CO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Smiles  Label\n",
       "0                           CCOP(=S)(CC)SC1=CC=CC=C1      2\n",
       "1  CC[N+]1=C(C(=C(C(=C1C)C(=O)OC(C)C)C2=CC=CC=C2C...      2\n",
       "2  C1=CC(=C(C=C1C(CNCCCCCCNCC(C2=CC(=C(C=C2)O)O)O...      1\n",
       "3                         C1=CC=C2C(=C1)C=CC=C2N=C=S      2\n",
       "4                              CC1=NC=C(C(=C1O)CN)CO      0"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantmap_data = pd.read_csv('data/ML_input_5338_out.txt',sep=\" \",names=[\"Smiles\", \"Label\"]).sample(frac=1).reset_index(drop=True) #,header=None)\n",
    "print('Dataset:', quantmap_data.shape)\n",
    "quantmap_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Smiles\n",
       "Label        \n",
       "0         714\n",
       "1        1887\n",
       "2        1894\n",
       "3         259\n",
       "4         228"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantmap_data.groupby('Label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Smiles\n",
       "Label        \n",
       "0         259\n",
       "1         228"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing unbalanced data and shuffling\n",
    "balanced_data = quantmap_data[quantmap_data.Label != 0][quantmap_data.Label != 1][quantmap_data.Label != 2]\n",
    "balanced_data = balanced_data.sample(frac=1).reset_index(drop=True)\n",
    "balanced_data[\"Label\"].replace({3: 0,4:1}, inplace=True)\n",
    "balanced_data.groupby('Label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sample:\n",
      "        Smiles\n",
      "Label        \n",
      "0         196\n",
      "1         193        Smiles\n",
      "Label        \n",
      "0          31\n",
      "1          17        Smiles\n",
      "Label        \n",
      "0          32\n",
      "1          16\n"
     ]
    }
   ],
   "source": [
    "train_percentage = 0.8\n",
    "valid_test_percentage = (1 - train_percentage)/2\n",
    "\n",
    "data_to_use = balanced_data\n",
    "# Ratios\n",
    "train_ratio = int (len(data_to_use) * train_percentage)\n",
    "valid_ratio = train_ratio + int(len(data_to_use)*valid_test_percentage)\n",
    "test_ratio = valid_ratio + int(len(data_to_use)*valid_test_percentage)\n",
    "\n",
    "train = data_to_use.iloc[:train_ratio,:]\n",
    "valid = data_to_use.iloc[train_ratio:valid_ratio,:]\n",
    "test = data_to_use.iloc[valid_ratio:test_ratio,:]\n",
    "print('Positive Sample:\\n',train.groupby('Label').count(),valid.groupby('Label').count(),test.groupby('Label').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def randomize_smiles(smiles,random_smiles=[],iteration=5):\n",
    "    try:\n",
    "        m = Chem.MolFromSmiles(smiles)\n",
    "        ans = list(range(m.GetNumAtoms()))\n",
    "        np.random.shuffle(ans)\n",
    "        nm = Chem.RenumberAtoms(m,ans)\n",
    "        out_smiles = (Chem.MolToSmiles(nm, canonical=False, isomericSmiles=True, kekuleSmiles=False))\n",
    "    except:\n",
    "        return (False)\n",
    "    \n",
    "    if out_smiles not in random_smiles:\n",
    "        return out_smiles\n",
    "    else:\n",
    "        iteration -= 1\n",
    "        if iteration > 0:\n",
    "            out_smiles = randomize_smiles(smiles,random_smiles,iteration)\n",
    "            return out_smiles\n",
    "        return (False)\n",
    "    \n",
    "def augment_smiles(count,iteration,smiles):\n",
    "    random_smiles = []\n",
    "    for i in range(count):\n",
    "        if smiles != None:\n",
    "            out_smiles = randomize_smiles(smiles,random_smiles,iteration=iteration)\n",
    "            if out_smiles:\n",
    "                random_smiles.append(out_smiles)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "    return random_smiles\n",
    "\n",
    "def unpack_and_write_list(smiles,label,filename):\n",
    "    for entry in smiles:\n",
    "        if type(entry) == list:\n",
    "            unpack_and_write_list(entry,label,filename)\n",
    "        else:\n",
    "            filename.write(entry + \",\" + str(label) + \"\\n\")\n",
    "    \n",
    "def smiles_augmentation(df, N_rounds=1,iteration=5,data_set_type=\"train\"):\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(\"data/classification/\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    filename = \"data/classification/\" + str(data_set_type) + \"_aug_canonical_smiles.csv\"\n",
    "\n",
    "    aug_out = open(filename,\"w\")\n",
    "\n",
    "    aug_out.write(\"Smiles,Label\\n\")\n",
    "        \n",
    "    labels = []\n",
    "    for label in df.groupby('Label'):\n",
    "        labels.append(label[0])\n",
    "    \n",
    "    augmentation_list = []\n",
    "    if type(N_rounds) == list:\n",
    "        assert(len(N_rounds) == len(labels))\n",
    "        augmentation_list = N_rounds\n",
    "    else:\n",
    "        for i in range(len(labels)):\n",
    "            augmentation_list.append(N_rounds)\n",
    "        \n",
    "    for label,augmentation in zip(labels,augmentation_list):\n",
    "    \n",
    "        canonical_smiles = df[df['Label'] == label]['Smiles'].to_list()\n",
    "\n",
    "        p = Pool(Number_of_workers)\n",
    "        func = partial(augment_smiles, augmentation, iteration)\n",
    "        augmented_smiles = list(tqdm.tqdm(p.imap(func, canonical_smiles), total=len(canonical_smiles)))\n",
    "        p.close()\n",
    "    \n",
    "        print (\"Saving data for label = \" + str(label))\n",
    "\n",
    "        unpack_and_write_list(augmented_smiles,label,filename=aug_out)\n",
    "\n",
    "        unpack_and_write_list(canonical_smiles,label,filename=aug_out)\n",
    "        \n",
    "        print (\"Saved data for label = \" + str(label))\n",
    "        \n",
    "    aug_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count_df = train.groupby('Label').count()\n",
    "label_count_list = []\n",
    "for entry in range(len(label_count_df)):\n",
    "    label_count_list.append(label_count_df.iloc[entry][0])\n",
    "\n",
    "augmentation_list = []\n",
    "max_value = max(label_count_list)\n",
    "for entry in label_count_list:\n",
    "    augmentation_list.append(int(max_value/entry))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the dataset is not balanced. For training data, we generated 10 and 30 randomized SMILES for molecules belong to the positive and negative classes, respectively. The numbers can be changed based on different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:00<00:00, 5741.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data for label = 0\n",
      "Saved data for label = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 193/193 [00:00<00:00, 10728.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data for label = 1\n",
      "Saved data for label = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 31/31 [00:00<00:00, 4183.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data for label = 0\n",
      "Saved data for label = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 17/17 [00:00<00:00, 2835.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data for label = 1\n",
      "Saved data for label = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 32/32 [00:00<00:00, 5561.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data for label = 0\n",
      "Saved data for label = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 1555.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data for label = 1\n",
      "Saved data for label = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_augmentation = 1\n",
    "\n",
    "###\n",
    "augmentation_list = [entry*number_of_augmentation for entry in augmentation_list]\n",
    "iteration = 10000\n",
    "# Augmentation for training data\n",
    "train_data = smiles_augmentation(train,N_rounds=augmentation_list,iteration=iteration,data_set_type=\"train\")\n",
    "\n",
    "# Augmentation for validation data\n",
    "val_data = smiles_augmentation(valid,N_rounds=augmentation_list,iteration=iteration,data_set_type=\"valid\")\n",
    "\n",
    "# Augmentation for test data\n",
    "test_data = smiles_augmentation(test,N_rounds=augmentation_list,iteration=iteration,data_set_type=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug = pd.read_csv(\"data/classification/train_aug_canonical_smiles.csv\", header=0).sample(frac=1).reset_index(drop=True)\n",
    "valid_aug = pd.read_csv(\"data/classification/valid_aug_canonical_smiles.csv\", header=0).sample(frac=1).reset_index(drop=True)\n",
    "test_aug = pd.read_csv(\"data/classification/test_aug_canonical_smiles.csv\", header=0).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       Smiles\n",
       " Label        \n",
       " 0         392\n",
       " 1         386,\n",
       "        Smiles\n",
       " Label        \n",
       " 0          62\n",
       " 1          34,\n",
       "        Smiles\n",
       " Label        \n",
       " 0          64\n",
       " 1          32)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aug.groupby('Label').count(),valid_aug.groupby('Label').count(),test_aug.groupby('Label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adpot the Encoder of MSPM According to the Target Dataset.\n",
    "\n",
    "In order to fine-tuning the pre-trained MSPM on the QSAR datasets of interest, we need to prepare the data:\n",
    "\n",
    "- Tokenize the SMILES of the QSAR dataset.\n",
    "- Align the token IDs of the QSAR dataset to the token IDs pre-trained MSPM. \n",
    "\n",
    "Often, the vocab size of the QSAR dataset is different from that of the pre-trained strcuture prediction model, which means the QSAR model will have a different input size from that of pre-trained model. Here, we need to change the input size of the pre-trained model to the vocab size of the QSAR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolTokenizer(BaseTokenizer):\n",
    "    def __init__(self, lang = 'en'):\n",
    "        self.lang = lang\n",
    "        \n",
    "    def tokenizer(self, smiles):        \n",
    "        smiles = \"[BOS]\" + smiles\n",
    "        tokens = atomwise_tokenizer(smiles)\n",
    "        return tokens\n",
    "    \n",
    "    def add_special_cases(self, toks):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "tok = Tokenizer(partial(MolTokenizer), n_cpus=8, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 48\n"
     ]
    }
   ],
   "source": [
    "qsar_vocab = TextLMDataBunch.from_df(path, train_aug, valid_aug, bs=bs, tokenizer=tok, \n",
    "                              chunksize=50000, text_cols=0,label_cols=1, max_vocab=60000, include_bos=False)\n",
    "\n",
    "print(f'Vocab Size: {len(qsar_vocab.vocab.itos)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_path = Path('results/pretraining_new/models')\n",
    "\n",
    "pretrained_fnames = ['pretraining_new_wt', 'pretraining_new_vocab']\n",
    "fnames = [pretrained_model_path/f'{fn}.{ext}' for fn,ext in zip(pretrained_fnames, ['pth', 'pkl'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_learner = language_model_learner(qsar_vocab, AWD_LSTM, drop_mult=1.0)\n",
    "lm_learner = lm_learner.load_pretrained(*fnames)\n",
    "lm_learner.freeze()\n",
    "lm_learner.save_encoder(f'lm_encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databunch for QSAR Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to change the `text_cols` and `label_col` based on your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas = TextClasDataBunch.from_df(path, train_aug, valid_aug, bs=bs, tokenizer=tok, \n",
    "                                          chunksize=50000, text_cols='Smiles',label_cols='Label', \n",
    "                                          vocab=qsar_vocab.vocab, max_vocab=60000, include_bos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>[BOS] C [N+] 1 = C C = C ( C = C 1 ) C 2 = C 3 C = C C ( = C ( C 4 = C C = C ( N 4 ) C ( = C 5 C = C C ( = N 5 ) C ( = C 6 C = C C 2 = N 6 ) C 7 =</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[BOS] C 1 = N C 2 = C ( N 1 C 3 C ( C ( C ( O 3 ) C O P ( = O ) ( O ) O P ( = O ) ( O ) O P ( = O ) ( O ) O P ( = O ) ( O ) O C C 4 C ( C ( C (</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[BOS] N c 1 [nH] c 2 n ( C 3 O C ( C O P ( O ) ( = O ) O P ( O ) ( = O ) O P ( O ) ( O P ( = O ) ( O ) O C C 4 C ( O ) C ( O ) C ( n 5 c 6 c ( n c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[BOS] C C C 1 C = C ( C ( C ( C C ( C 2 C ( C C ( C ( O 2 ) ( C ( = O ) C ( = O ) N 3 C C C C C 3 C ( = O ) O C ( C ( C ( C C 1 = O ) O ) C ) C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[BOS] O C 1 C ( C ) = C C ( C C ) C ( = O ) C C ( O ) C ( C ) C ( C ( = C C 2 C C C ( O ) C ( O C ) C 2 ) C ) O C ( = O ) C 2 N ( C ( = O ) C (</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUROC(Callback):\n",
    "    _order = -20 #Needs to run before the recorder\n",
    "\n",
    "    def __init__(self, learn, **kwargs): self.learn = learn\n",
    "    def on_train_begin(self, **kwargs): self.learn.recorder.add_metric_names(['AUROC'])\n",
    "    def on_epoch_begin(self, **kwargs): self.output, self.target = [], []\n",
    "    \n",
    "    def on_batch_end(self, last_target, last_output, train, **kwargs):\n",
    "        if not train:\n",
    "            self.output.append(last_output)\n",
    "            self.target.append(last_target)\n",
    "                \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        if len(self.output) > 0:\n",
    "            output = torch.cat(self.output)\n",
    "            target = torch.cat(self.target)\n",
    "            preds = F.softmax(output, dim=1)\n",
    "            metric = auroc_score(preds, target)\n",
    "            return add_metrics(last_metrics, [metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_learner = text_classifier_learner(data_clas, AWD_LSTM, pretrained=False, drop_mult=0.2)\n",
    "cls_learner.load_encoder(f'lm_encoder')\n",
    "cls_learner.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(48, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(48, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.08000000000000002, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_learner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.650228</td>\n",
       "      <td>0.681211</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.482701</td>\n",
       "      <td>0.645533</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.380646</td>\n",
       "      <td>0.628124</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.325025</td>\n",
       "      <td>0.582642</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_learner.fit_one_cycle(4, 3e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.238771</td>\n",
       "      <td>0.578381</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.266326</td>\n",
       "      <td>0.382529</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.217244</td>\n",
       "      <td>0.432686</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.172607</td>\n",
       "      <td>0.415987</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_learner.freeze_to(-2)\n",
    "cls_learner.fit_one_cycle(4, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.087045</td>\n",
       "      <td>0.424461</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.095922</td>\n",
       "      <td>0.421304</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.086082</td>\n",
       "      <td>0.416386</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.092283</td>\n",
       "      <td>0.435109</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_learner.freeze_to(-3)\n",
    "cls_learner.fit_one_cycle(4, slice(5e-4/(2.6**4),5e-4), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.068385</td>\n",
       "      <td>0.422301</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.075419</td>\n",
       "      <td>0.435164</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.074571</td>\n",
       "      <td>0.426764</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.069021</td>\n",
       "      <td>0.429549</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.068134</td>\n",
       "      <td>0.420946</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.071122</td>\n",
       "      <td>0.427485</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_learner.unfreeze()\n",
    "cls_learner.fit_one_cycle(6, slice(5e-5/(2.6**4),5e-5), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_type = \"two_class\"\n",
    "split_id = \"trial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_learner.save(f'{split_type}_{split_id}_clas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Test only on Canoicial SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data_clas = TextClasDataBunch.from_df(path, train, test, bs=bs, tokenizer=tok, \n",
    "                              chunksize=50000, text_cols='Smiles',label_cols='Label', vocab=qsar_vocab.vocab, max_vocab=60000,\n",
    "                                              include_bos=False)\n",
    "\n",
    "learner = text_classifier_learner(test_data_clas, AWD_LSTM, pretrained=False, drop_mult=0.2)\n",
    "learner.load(f'{split_type}_{split_id}_clas', purge=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(48, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(48, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.08000000000000002, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (389 items)\n",
       "x: TextList\n",
       "[BOS] C 1 C ( C ( O C 1 N 2 C = C C ( = N C 2 = O ) N ) C O P ( = O ) ( O ) O P ( = O ) ( O ) O ) O,[BOS] C C N ( C C C C 1 = C C = C C = C 1 ) C C C C 2 = C C = C C = C 2,[BOS] C C 1 2 C C C ( = O ) C = C 1 C C C 3 C 2 C C C 4 ( C 3 C C C 4 ( C ) O ) C,[BOS] C C N ( C C ) C C C 1 = C N C 2 = C 1 C = C C ( = C 2 ) F . Cl,[BOS] C N 1 C C C C ( C 1 ) C C 2 C 3 = C C = C C = C 3 S C 4 = C C = C C = C 2 4\n",
       "y: CategoryList\n",
       "1,0,1,0,0\n",
       "Path: results/classification_new;\n",
       "\n",
       "Valid: LabelList (48 items)\n",
       "x: TextList\n",
       "[BOS] C [N+] 1 ( C C C ( C 1 ) O C ( = O ) C ( C 2 C C C C 2 ) ( C 3 = C C = C C = C 3 ) O ) C,[BOS] C O C 1 = C C = C C = C 1 N 2 C C N C C 2,[BOS] C C 1 ( O C 2 C C 3 C 4 C C ( C 5 = C C ( = O ) C = C C 5 ( C 4 C ( C C 3 ( C 2 ( O 1 ) C ( = O ) C O ) C ) O ) C ) F ) C,[BOS] C N S ( = O ) ( = O ) C C C 1 = C C 2 = C ( C = C 1 ) N C = C 2 C 3 C C N ( C C 3 ) C,[BOS] xxpad . [OH-]\n",
       "y: CategoryList\n",
       "0,0,1,0,0\n",
       "Path: results/classification_new;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 48 molecues\n",
      "Accuracy: 0.833\n",
      "False Positives: 0.146\n",
      "False Negatives: 0.021\n",
      "Recall: 0.938\n",
      "Precision: 0.682\n",
      "Sensitivity: 0.938\n",
      "Specificity: 0.781\n",
      "MCC: 0.680\n",
      "ROCAUC: 0.939\n"
     ]
    }
   ],
   "source": [
    "test_get_scores(learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Test on averaging prediction of canoicial and randomized SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_smiles_augmentation(df):\n",
    "    dist_aug = {col_name: [] for col_name in df}\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        dist_aug['Smiles'].append(randomize_smiles(df.iloc[i]['Smiles']))\n",
    "        dist_aug['Label'].append(df.iloc[i]['Label'])\n",
    "                     \n",
    "    return pd.DataFrame.from_dict(dist_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = torch.tensor(test['Label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "# Randomized SMILES Predictions\n",
    "for i in range(4):\n",
    "    np.random.seed(12*i)    \n",
    "    test_aug = test_smiles_augmentation(test)\n",
    "    \n",
    "    # model\n",
    "    test_data_clas = TextClasDataBunch.from_df(path, train, test_aug, bs=bs, tokenizer=tok, \n",
    "                              chunksize=50000, text_cols='Smiles',label_cols='Label', vocab=qsar_vocab.vocab, max_vocab=60000,\n",
    "                                              include_bos=False)\n",
    "    learner = text_classifier_learner(test_data_clas, AWD_LSTM, pretrained=False, drop_mult=0.2)\n",
    "    learner.load(f'{split_type}_{split_id}_clas', purge=False);\n",
    "    \n",
    "    \n",
    "    #get predictions\n",
    "    pred,lbl = learner.get_preds(ordered=True)\n",
    "    \n",
    "    preds.append(pred)\n",
    "\n",
    "# Canonical SMILES Predictions\n",
    "\n",
    "test_data_clas = TextClasDataBunch.from_df(path, train, test, bs=bs, tokenizer=tok, \n",
    "                              chunksize=50000, text_cols='Smiles',label_cols='Label', vocab=qsar_vocab.vocab, max_vocab=60000,\n",
    "                                              include_bos=False)\n",
    "\n",
    "learner = text_classifier_learner(test_data_clas, AWD_LSTM, pretrained=False, drop_mult=0.2)\n",
    "learner.load(f'{split_type}_{split_id}_clas', purge=False);\n",
    "\n",
    "\n",
    "pred,lbl = learner.get_preds(ordered=True)\n",
    "\n",
    "\n",
    "preds.append(pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum(preds)/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Averaging Predictions of Canoicial and Randomized SMILES: 0.908\n"
     ]
    }
   ],
   "source": [
    "avg_preds = sum(preds)/len(preds)\n",
    "print(f'Performance of Averaging Predictions of Canoicial and Randomized SMILES: {roc_auc_score(lbl, avg_preds[:,1], multi_class=\"ovo\"):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molpmofit",
   "language": "python",
   "name": "molpmofit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
