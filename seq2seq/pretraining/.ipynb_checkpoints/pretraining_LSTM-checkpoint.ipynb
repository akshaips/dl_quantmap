{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import custom script CNN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(device(type='cuda'), True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import codecs\n",
    "from SmilesPE.pretokenizer import atomwise_tokenizer\n",
    "from SmilesPE.pretokenizer import kmer_tokenizer\n",
    "from SmilesPE.learner import *\n",
    "from SmilesPE.tokenizer import *\n",
    "\n",
    "sys.path.append('/scratch-shared/akshai/Publication/supp_scripts/')\n",
    "import supp_utils as su\n",
    "\n",
    "# set gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device,torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [\"model_\" + str(number) + \".pth\" for number in range(10,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_10.pth',\n",
       " 'model_11.pth',\n",
       " 'model_12.pth',\n",
       " 'model_13.pth',\n",
       " 'model_14.pth',\n",
       " 'model_15.pth',\n",
       " 'model_16.pth',\n",
       " 'model_17.pth',\n",
       " 'model_18.pth',\n",
       " 'model_19.pth',\n",
       " 'model_20.pth',\n",
       " 'model_21.pth',\n",
       " 'model_22.pth',\n",
       " 'model_23.pth',\n",
       " 'model_24.pth',\n",
       " 'model_25.pth',\n",
       " 'model_26.pth',\n",
       " 'model_27.pth',\n",
       " 'model_28.pth',\n",
       " 'model_29.pth',\n",
       " 'model_30.pth',\n",
       " 'model_31.pth',\n",
       " 'model_32.pth',\n",
       " 'model_33.pth',\n",
       " 'model_34.pth',\n",
       " 'model_35.pth',\n",
       " 'model_36.pth',\n",
       " 'model_37.pth',\n",
       " 'model_38.pth',\n",
       " 'model_39.pth',\n",
       " 'model_40.pth',\n",
       " 'model_41.pth',\n",
       " 'model_42.pth',\n",
       " 'model_43.pth',\n",
       " 'model_44.pth',\n",
       " 'model_45.pth',\n",
       " 'model_46.pth',\n",
       " 'model_47.pth',\n",
       " 'model_48.pth',\n",
       " 'model_49.pth',\n",
       " 'model_50.pth',\n",
       " 'model_51.pth',\n",
       " 'model_52.pth',\n",
       " 'model_53.pth',\n",
       " 'model_54.pth',\n",
       " 'model_55.pth',\n",
       " 'model_56.pth',\n",
       " 'model_57.pth',\n",
       " 'model_58.pth',\n",
       " 'model_59.pth',\n",
       " 'model_60.pth',\n",
       " 'model_61.pth',\n",
       " 'model_62.pth',\n",
       " 'model_63.pth',\n",
       " 'model_64.pth',\n",
       " 'model_65.pth',\n",
       " 'model_66.pth',\n",
       " 'model_67.pth',\n",
       " 'model_68.pth',\n",
       " 'model_69.pth',\n",
       " 'model_70.pth',\n",
       " 'model_71.pth',\n",
       " 'model_72.pth',\n",
       " 'model_73.pth',\n",
       " 'model_74.pth',\n",
       " 'model_75.pth',\n",
       " 'model_76.pth',\n",
       " 'model_77.pth',\n",
       " 'model_78.pth',\n",
       " 'model_79.pth',\n",
       " 'model_80.pth',\n",
       " 'model_81.pth',\n",
       " 'model_82.pth',\n",
       " 'model_83.pth',\n",
       " 'model_84.pth',\n",
       " 'model_85.pth',\n",
       " 'model_86.pth',\n",
       " 'model_87.pth',\n",
       " 'model_88.pth',\n",
       " 'model_89.pth',\n",
       " 'model_90.pth',\n",
       " 'model_91.pth',\n",
       " 'model_92.pth',\n",
       " 'model_93.pth',\n",
       " 'model_94.pth',\n",
       " 'model_95.pth',\n",
       " 'model_96.pth',\n",
       " 'model_97.pth',\n",
       " 'model_98.pth',\n",
       " 'model_99.pth']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# To remove rdkit warning\n",
    "from rdkit import RDLogger\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_filename = \"parameters.json\" \n",
    "\n",
    "parameter_file = open(parameter_filename)\n",
    "parameters = json.load(parameter_file)\n",
    "parameter_file.close()\n",
    "\n",
    "# User inputs\n",
    "input_file = parameters[\"input_file\"] #\"/scratch-shared/akshai/Publication/initial_models/ML_input_5338.txt\" # input file\n",
    "\n",
    "trial = parameters[\"trial\"] # setting False saves the output files else not saved\n",
    "\n",
    "# Sequence length to be considered\n",
    "lower_cutoff = int(parameters[\"sequence_length_cutoff\"][\"lower_cutoff\"])\n",
    "upper_cutoff = int(parameters[\"sequence_length_cutoff\"][\"upper_cutoff\"])\n",
    "\n",
    "number_of_augmentation = int(parameters[\"augmentation\"][\"number_of_augmentation\"])\n",
    "iteration = int(parameters[\"augmentation\"][\"iteration\"])\n",
    "\n",
    "tokenization = parameters[\"tokens\"][\"tokenization\"] # options are SPE,atomwise,vocab_file\n",
    "if tokenization == \"SPE\":\n",
    "    spe_min_frequency = int(parameters[\"tokens\"][\"spe_min_frequency\"])\n",
    "sos_eos_tokens = parameters[\"tokens\"][\"sos_eos_tokens\"]\n",
    "\n",
    "\n",
    "#####################\n",
    "# Network parameters#\n",
    "#####################\n",
    "load_model = parameters[\"pretrained_model\"][\"load_model\"]\n",
    "#if load_model is True set the path for pretrained_model_path\n",
    "pretrained_model_path = parameters[\"pretrained_model\"][\"pretrained_model_path\"]\n",
    "\n",
    "hidden_size = int(parameters[\"lstm_parameters\"][\"hidden_size\"])\n",
    "num_layers = int(parameters[\"lstm_parameters\"][\"num_layers\"])\n",
    "en_embedding_size = int(parameters[\"lstm_parameters\"][\"en_embedding_size\"])\n",
    "en_dropout = float(parameters[\"lstm_parameters\"][\"en_dropout\"])\n",
    "\n",
    "fc_size = int(parameters[\"fc_layer_parameters\"][\"fc_size\"])\n",
    "fc_dropout = float(parameters[\"fc_layer_parameters\"][\"fc_dropout\"]) # fully connected layer dropout\n",
    "\n",
    "epochs = int(parameters[\"network_parameters\"][\"epochs\"])\n",
    "batch_size = int(parameters[\"network_parameters\"][\"batch_size\"])\n",
    "learning_rate = float(parameters[\"network_parameters\"][\"learning_rate\"])\n",
    "\n",
    "Number_of_workers = int(parameters[\"Number_of_workers\"])\n",
    "\n",
    "##################\n",
    "### Do not edit###\n",
    "##################\n",
    "os.system(\"mkdir run_files\")\n",
    "\n",
    "atomwise_tokenization = False\n",
    "train_SPE = False\n",
    "use_vocab_file = False\n",
    "\n",
    "if tokenization == \"SPE\":\n",
    "    train_SPE = True\n",
    "elif tokenization == \"atomwise\":\n",
    "    atomwise_tokenization = True\n",
    "elif tokenization == \"vocab_file\":\n",
    "    use_vocab_file = True\n",
    "else:\n",
    "    atomwise_tokenization = True\n",
    "    print (\"Tokenization not provided/incorrect. Using atomwise tokenization\")\n",
    "\n",
    "if not trial:\n",
    "    network_parameter_output = open(\"run_files/network_parameters.txt\",\"w\",1)\n",
    "    log_file = open(\"run_files/model.log\",\"w\")\n",
    "    for parameter in parameters:\n",
    "        network_parameter_output.write(str(parameter) + \" = \" + str(parameters[parameter]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smiles_label,label_count = su.get_data_within_cutoff(input_file,sanitize=True,canonical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    }
   ],
   "source": [
    "smiles = [line.split()[1] for line in open(input_file,\"r\").readlines()]\n",
    "sanitized_smiles = su.sanity_check(smiles,output_type = \"canonical\",Number_of_workers = Number_of_workers)\n",
    "train_data,valid_data,test_data = su.split_data_without_label(smiles,train_percentage=0.8,valid_percentage=None)\n",
    "\n",
    "if not trial:\n",
    "    log_file.write(\"Training : Data point = \" + str(len(train_data)) + \"\\n\")\n",
    "    log_file.write(\"Valid : Data point = \" + str(len(valid_data)) + \"\\n\")\n",
    "    log_file.write(\"Test : Data point = \" + str(len(test_data)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "if number_of_augmentation > 0:\n",
    "    train_data = su.smiles_augmentation(train_data,\n",
    "                                        N_rounds=number_of_augmentation,\n",
    "                                        iteration=iteration,\n",
    "                                        data_set_type=\"train_data\",\n",
    "                                        Number_of_workers=Number_of_workers)     \n",
    "    \n",
    "    valid_data = su.smiles_augmentation(valid_data,\n",
    "                                        N_rounds=number_of_augmentation,\n",
    "                                        iteration=iteration,\n",
    "                                        data_set_type=\"train_data\",\n",
    "                                        Number_of_workers=Number_of_workers)     \n",
    "            \n",
    "        \n",
    "    test_data = su.smiles_augmentation(test_data,\n",
    "                                        N_rounds=number_of_augmentation,\n",
    "                                        iteration=iteration,\n",
    "                                        data_set_type=\"test_data\",\n",
    "                                        Number_of_workers=Number_of_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not trial:\n",
    "    log_file.write(\"Data points after augmentation\\n\")\n",
    "    log_file.write(\"Training : Data point = \" + str(len(train_data)) + \"\\n\")\n",
    "    log_file.write(\"Valid : Data point = \" + str(len(valid_data)) + \"\\n\")\n",
    "    log_file.write(\"Test : Data point = \" + str(len(test_data)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    }
   ],
   "source": [
    "# train spe\n",
    "if train_SPE:\n",
    "    all_smiles = train_data['Smiles'].to_list()\n",
    "    token_path = \"run_files/tokens.txt\"\n",
    "    su.seq2seq.train_spe_tokenizer(all_smiles,token_path,min_frequency=spe_min_frequency,augmentation=0)\n",
    "    \n",
    "    \n",
    "# create or use vocab\n",
    "if use_vocab_file:\n",
    "    word_index,index_word = su.seq2seq.read_vocab_file(\"run_files/vocab\" + str(fold) + \".txt\")\n",
    "else:\n",
    "    output_vocab_path = \"run_files/vocab.txt\"\n",
    "    if train_SPE:\n",
    "        word_index,index_word = su.seq2seq.create_vocab_file_spe(train_data,\n",
    "                                                                token_path,\n",
    "                                                                Number_of_workers,\n",
    "                                                                output_vocab_path,\n",
    "                                                                sos_eos_tokens)\n",
    "    else:\n",
    "        token_path = \"\"\n",
    "        word_index,index_word = su.seq2seq.create_vocab_file_atomwise(train_data,\n",
    "                                                                    Number_of_workers,\n",
    "                                                                    output_vocab_path,\n",
    "                                                                    sos_eos_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    }
   ],
   "source": [
    "# convert to tokens\n",
    "x_train= su.seq2seq.convert_smiles_to_tokens(train_data,\n",
    "                                                        lower_cutoff=lower_cutoff,\n",
    "                                                         upper_cutoff=upper_cutoff,\n",
    "                                                         Number_of_workers=Number_of_workers,\n",
    "                                                         token_path=token_path,\n",
    "                                                         sos_eos_tokens=sos_eos_tokens,\n",
    "                                                         tokenization=tokenization)\n",
    "\n",
    "x_valid= su.seq2seq.convert_smiles_to_tokens(valid_data,\n",
    "                                                       lower_cutoff=lower_cutoff,\n",
    "                                                       upper_cutoff=upper_cutoff,\n",
    "                                                       Number_of_workers=Number_of_workers,\n",
    "                                                       token_path=token_path,\n",
    "                                                       sos_eos_tokens=sos_eos_tokens,\n",
    "                                                       tokenization=tokenization)\n",
    "    \n",
    "x_test= su.seq2seq.convert_smiles_to_tokens(test_data,\n",
    "                                                       lower_cutoff=lower_cutoff,\n",
    "                                                       upper_cutoff=upper_cutoff,\n",
    "                                                       Number_of_workers=Number_of_workers,\n",
    "                                                       token_path=token_path,\n",
    "                                                       sos_eos_tokens=sos_eos_tokens,\n",
    "                                                       tokenization=tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    }
   ],
   "source": [
    "# convert to index\n",
    "x_train_indexed = su.seq2seq.convert_token_to_index_multi(x_train,word_index)\n",
    "x_valid_indexed = su.seq2seq.convert_token_to_index_multi(x_valid,word_index)\n",
    "x_test_indexed = su.seq2seq.convert_token_to_index_multi(x_test,word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create iterator x_indexed,y=None,batch_size=32,device=\"cpu\"\n",
    "train_iterator =  su.seq2seq.make_bucket_iterator(x_indexed=x_train_indexed,y=None,batch_size=batch_size,device=device)\n",
    "valid_iterator =  su.seq2seq.make_bucket_iterator(x_indexed=x_valid_indexed,y=None,batch_size=batch_size,device=device)\n",
    "test_iterator =  su.seq2seq.make_bucket_iterator(x_indexed=x_test_indexed,y=None,batch_size=batch_size,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, n_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size) #,padding_idx=0)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, n_layers, dropout=p,batch_first=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (N,seq_length) where N is batch size\n",
    "        \n",
    "        pack_pad_list = x.shape[0] - (np.array(x.cpu()) == 0).sum(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (N,seq_length, embedding_size)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedding, \n",
    "                                                                lengths = torch.as_tensor(pack_pad_list, dtype=torch.int64).cpu(),\n",
    "                                                                batch_first = False,\n",
    "                                                                enforce_sorted=False)\n",
    "        \n",
    "        lstm_out, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        \n",
    "        return (lstm_out, (hidden, cell))\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size,output_size, n_layers, p):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.output_dim = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size) #,padding_idx=0)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, n_layers, dropout=p,batch_first=False)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
    "        # is 1 here because we are sending in a single word and not a sentence\n",
    "\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1,seq_length, embedding_size)\n",
    "\n",
    "        #print (embedding.shape,hidden.shape,cell.shape)\n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "\n",
    "        # predictions shape: (1, N, length_target_vocabulary) to send it to\n",
    "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
    "        # just gonna remove the first dim\n",
    "\n",
    "        predictions = self.fc_out(outputs.squeeze(0))\n",
    "\n",
    "        return predictions, (hidden, cell)\n",
    "    \n",
    "class seq2seq(nn.Module):\n",
    "    def __init__(self, encoder_net,decoder_net,decoder_output_size):\n",
    "        super(seq2seq,self).__init__()\n",
    "        self.encoder = encoder_net\n",
    "        self.decoder = decoder_net\n",
    "        self.output_size = decoder_output_size\n",
    "        \n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        \n",
    "        target_vocab_size = self.output_size\n",
    "        \n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "        \n",
    "        lstm_out,(hidden,cell) = self.encoder(source)\n",
    "        \n",
    "        x = target[0,:]\n",
    "        #start_time = time.time()\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            predictions, (hidden, cell) = self.decoder(x, hidden, cell)\n",
    "            # Store next output prediction\n",
    "            outputs[t] = predictions\n",
    "            \n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = predictions.argmax(1)\n",
    "            \n",
    "            # With probability of teacher_force_ratio we take the actual next word\n",
    "            # otherwise we take the word that the Decoder predicted it to be.\n",
    "            # Teacher Forcing is used so that the model gets used to seeing\n",
    "            # similar inputs at training and testing time, if teacher forcing is 1\n",
    "            # then inputs at test time might be completely different than what the\n",
    "            # network is used to. This was a long comment.\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "        #print (\"each DECODER time: \" + str(time.time() - start_time))\n",
    "        return outputs\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "input_size_encoder = len(word_index)\n",
    "#output_size = len(set(y_train))\n",
    "\n",
    "encoder_net = Encoder(\n",
    "        input_size_encoder, \n",
    "        en_embedding_size, \n",
    "        hidden_size, \n",
    "        num_layers, \n",
    "        en_dropout)\n",
    "\n",
    "#encoder_net.to(device)\n",
    "\n",
    "\n",
    "input_size_decoder = len(word_index)\n",
    "de_embedding_size = en_embedding_size\n",
    "de_num_layers = num_layers\n",
    "de_dropout = en_dropout\n",
    "hidden_size = hidden_size\n",
    "\n",
    "decoder_output_size = len(word_index)\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    de_embedding_size,\n",
    "    hidden_size,\n",
    "    decoder_output_size,\n",
    "    num_layers,\n",
    "    de_dropout)\n",
    "\n",
    "#decoder_net.to(device)\n",
    "\n",
    "model = seq2seq(encoder_net,decoder_net,decoder_output_size)\n",
    "model.to(device)\n",
    "print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSS train:0.8837851196376556 val:0.44732441054387934 \tACCU train:0.7135280652172589 val:0.8421734143456504:  10%|█         | 1/10 [43:36<6:32:24, 2616.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train:0.8837851196376556 val:0.44732441054387934 \tACCU train:0.7135280652172589 val:0.8421734143456504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSS train:0.391883027455996 val:0.28442707085562063 \tACCU train:0.8590421008606934 val:0.893509974282865:  20%|██        | 2/10 [1:27:10<5:48:42, 2615.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train:0.391883027455996 val:0.28442707085562063 \tACCU train:0.8590421008606934 val:0.893509974282865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSS train:0.31667708962358 val:0.25170321306052235 \tACCU train:0.8832841247973893 val:0.9032421578780203:  30%|███       | 3/10 [2:10:25<5:03:59, 2605.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train:0.31667708962358 val:0.25170321306052235 \tACCU train:0.8832841247973893 val:0.9032421578780203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSS train:0.2871308442940277 val:0.23817312475724545 \tACCU train:0.8931107461609387 val:0.9087853322388229:  40%|████      | 4/10 [2:53:56<4:20:48, 2608.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train:0.2871308442940277 val:0.23817312475724545 \tACCU train:0.8931107461609387 val:0.9087853322388229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSS train:0.2808645539831988 val:0.21730516560784827 \tACCU train:0.8956822691943288 val:0.9151491820785027:  50%|█████     | 5/10 [3:37:16<3:37:06, 2605.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train:0.2808645539831988 val:0.21730516560784827 \tACCU train:0.8956822691943288 val:0.9151491820785027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSS train:0.2851272860208759 val:0.21464051262642433 \tACCU train:0.8946370489120051 val:0.9169691292199321:  60%|██████    | 6/10 [4:20:37<2:53:34, 2603.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train:0.2851272860208759 val:0.21464051262642433 \tACCU train:0.8946370489120051 val:0.9169691292199321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSS train:0.28668153905110133 val:0.21939429815460235 \tACCU train:0.8945985187978365 val:0.9153472765267056:  70%|███████   | 7/10 [5:04:11<2:10:21, 2607.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train:0.28668153905110133 val:0.21939429815460235 \tACCU train:0.8945985187978365 val:0.9153472765267056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSS train:0.29660394243918914 val:0.30902379328611096 \tACCU train:0.8914468722816329 val:0.886866894014311:  80%|████████  | 8/10 [5:47:40<1:26:55, 2607.63s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train:0.29660394243918914 val:0.30902379328611096 \tACCU train:0.8914468722816329 val:0.886866894014311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOSS train:0.3062697716210921 val:0.26744984963241253 \tACCU train:0.8887087469197756 val:0.9008884648149725:  90%|█████████ | 9/10 [6:31:01<43:25, 2605.53s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train:0.3062697716210921 val:0.26744984963241253 \tACCU train:0.8887087469197756 val:0.9008884648149725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train:0.31447551127096685 val:0.2975445463688172 \tACCU train:0.8863678288732911 val:0.8891735855472418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word_index[\"<PAD>\"])\n",
    "\n",
    "# List to store values\n",
    "train_loss_list = []\n",
    "train_accu_list = []\n",
    "val_loss_list = []\n",
    "val_accu_list = []\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# model training\n",
    "loop = tqdm.tqdm(range(epochs), total=epochs,leave=False)\n",
    "for epoch in loop:\n",
    "\n",
    "    train_loss, train_accu = su.seq2seq.pretrain_train(model,criterion,optimizer,train_iterator,device,padding_value=word_index[\"<PAD>\"],clip=1)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accu_list.append(train_accu)\n",
    "    \n",
    "    val_loss,val_accu = su.seq2seq.pretrain_validate(model,criterion,valid_iterator,device)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_accu_list.append(val_accu)\n",
    "    \n",
    "    if not trial:\n",
    "        log_file.write(str(epoch+1) + \"\\t\" + str(train_loss) + \"\\t\" + str(val_loss) + \"\\t\" + str(train_accu) + \"\\t\" + str(val_accu)  + \"\\n\")\n",
    "            \n",
    "    torch.save(model.state_dict(), \"run_files/model_\" + str(epoch) + \".pth\")\n",
    "    loop.set_description(\"LOSS train:\" + str(train_loss) + \" val:\" + str(val_loss) + \" \\tACCU train:\" + str(train_accu) + \" val:\" + str(val_accu))\n",
    "    print (\"LOSS train:\" + str(train_loss) + \" val:\" + str(val_loss) + \" \\tACCU train:\" + str(train_accu) + \" val:\" + str(val_accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy,prediction_list = su.seq2seq.pretrain_test(model,criterion,train_iterator,index_word_dict=index_word,get_prediction_list=True,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not trial:\n",
    "    log_file.write(\"\\n\\n\\nTest set analysis\\n\")\n",
    "    log_file.write(\"Loss = \" + str(loss) + \"\\n\")\n",
    "    log_file.write(\"accuracy = \" + str(accuracy) + \"\\n\")\n",
    "    #log_file.write(\"prediction_list = \" + str(prediction_list) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction_list,loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
